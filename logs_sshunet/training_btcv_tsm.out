------------------------------TRAINING OF MODEL 1------------------------------
You are using the following device: cuda
Batch size is: 2 epochs 5000
--------------------Folder 0-------------------

Cross Entropy Dice Loss
Total parameters count 6480142
Filters: [32, 64, 128, 256, 320],
Kernels: [[1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3], [1, 3, 3]]
Strides: [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]
GateDynUNet(
  (input_block): GateUnetResBlock(
    (conv1): Convolution(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (conv2): Convolution(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (shift): Tsm()
    (conv3): Convolution(
      (conv): Conv3d(1, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (norm3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
  )
  (downsamples): ModuleList(
    (0): GateUnetResBlock(
      (conv1): Convolution(
        (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv2): Convolution(
        (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (shift): Tsm()
      (conv3): Convolution(
        (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (1): GateUnetResBlock(
      (conv1): Convolution(
        (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv2): Convolution(
        (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (shift): Tsm()
      (conv3): Convolution(
        (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (2): GateUnetResBlock(
      (conv1): Convolution(
        (conv): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv2): Convolution(
        (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
      (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (shift): Tsm()
      (conv3): Convolution(
        (conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (norm3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (bottleneck): GateUnetResBlock(
    (conv1): Convolution(
      (conv): Conv3d(256, 320, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (conv2): Convolution(
      (conv): Conv3d(320, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (shift): Tsm()
    (conv3): Convolution(
      (conv): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (norm3): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
  )
  (upsamples): ModuleList(
    (0): GateUnetUpBlock(
      (transp_conv): Convolution(
        (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv_block): GateUnetResBlock(
        (conv1): Convolution(
          (conv): Conv3d(512, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv2): Convolution(
          (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (shift): Tsm()
        (conv3): Convolution(
          (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (norm3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (1): GateUnetUpBlock(
      (transp_conv): Convolution(
        (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv_block): GateUnetResBlock(
        (conv1): Convolution(
          (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv2): Convolution(
          (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (shift): Tsm()
        (conv3): Convolution(
          (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): GateUnetUpBlock(
      (transp_conv): Convolution(
        (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv_block): GateUnetResBlock(
        (conv1): Convolution(
          (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv2): Convolution(
          (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (shift): Tsm()
        (conv3): Convolution(
          (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (3): GateUnetUpBlock(
      (transp_conv): Convolution(
        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv_block): GateUnetResBlock(
        (conv1): Convolution(
          (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv2): Convolution(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (conv3): Convolution(
          (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (norm3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
  )
  (output_block): GateUnetOutBlock(
    (conv1): Convolution(
      (conv): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
    (act): LeakyReLU(negative_slope=0.01)
    (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (conv): Convolution(
      (conv): Conv3d(32, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      (adn): ADN(
        (D): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (skip_layers): DynUNetSkipLayer(
    (downsample): GateUnetResBlock(
      (conv1): Convolution(
        (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv2): Convolution(
        (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (shift): Tsm()
      (conv3): Convolution(
        (conv): Conv3d(1, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (norm3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (next_layer): DynUNetSkipLayer(
      (downsample): GateUnetResBlock(
        (conv1): Convolution(
          (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv2): Convolution(
          (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (shift): Tsm()
        (conv3): Convolution(
          (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (next_layer): DynUNetSkipLayer(
        (downsample): GateUnetResBlock(
          (conv1): Convolution(
            (conv): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (conv2): Convolution(
            (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (shift): Tsm()
          (conv3): Convolution(
            (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
        (next_layer): DynUNetSkipLayer(
          (downsample): GateUnetResBlock(
            (conv1): Convolution(
              (conv): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (conv2): Convolution(
              (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
            (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (shift): Tsm()
            (conv3): Convolution(
              (conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (norm3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (next_layer): GateUnetResBlock(
            (conv1): Convolution(
              (conv): Conv3d(256, 320, kernel_size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (conv2): Convolution(
              (conv): Conv3d(320, 320, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
            (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (shift): Tsm()
            (conv3): Convolution(
              (conv): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (norm3): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
          (upsample): GateUnetUpBlock(
            (transp_conv): Convolution(
              (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (conv_block): GateUnetResBlock(
              (conv1): Convolution(
                (conv): Conv3d(512, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
                (adn): ADN(
                  (D): Dropout(p=0.0, inplace=False)
                )
              )
              (conv2): Convolution(
                (conv): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
                (adn): ADN(
                  (D): Dropout(p=0.0, inplace=False)
                )
              )
              (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
              (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (shift): Tsm()
              (conv3): Convolution(
                (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
                (adn): ADN(
                  (D): Dropout(p=0.0, inplace=False)
                )
              )
              (norm3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            )
          )
        )
        (upsample): GateUnetUpBlock(
          (transp_conv): Convolution(
            (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (conv_block): GateUnetResBlock(
            (conv1): Convolution(
              (conv): Conv3d(256, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (conv2): Convolution(
              (conv): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
            (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (shift): Tsm()
            (conv3): Convolution(
              (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
              (adn): ADN(
                (D): Dropout(p=0.0, inplace=False)
              )
            )
            (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (upsample): GateUnetUpBlock(
        (transp_conv): Convolution(
          (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv_block): GateUnetResBlock(
          (conv1): Convolution(
            (conv): Conv3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (conv2): Convolution(
            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (shift): Tsm()
          (conv3): Convolution(
            (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (adn): ADN(
              (D): Dropout(p=0.0, inplace=False)
            )
          )
          (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
    )
    (upsample): GateUnetUpBlock(
      (transp_conv): Convolution(
        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (adn): ADN(
          (D): Dropout(p=0.0, inplace=False)
        )
      )
      (conv_block): GateUnetResBlock(
        (conv1): Convolution(
          (conv): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (conv2): Convolution(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (conv3): Convolution(
          (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (adn): ADN(
            (D): Dropout(p=0.0, inplace=False)
          )
        )
        (norm3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
  )
)
Writing Tensorboard logs to  /data/vision_group/medical/btcv/results_tsm/logs
Final training  0/4999 loss: 3.8432 time 23.08s
Final training  1/4999 loss: 3.3578 time 22.91s
Final training  2/4999 loss: 3.0931 time 22.62s
Final training  3/4999 loss: 2.9289 time 23.21s
Final training  4/4999 loss: 2.7393 time 22.85s
Final training  5/4999 loss: 2.6121 time 22.89s
Final training  6/4999 loss: 2.5314 time 22.61s
Final training  7/4999 loss: 2.4488 time 23.02s
Final training  8/4999 loss: 2.4284 time 23.14s
Final training  9/4999 loss: 2.3301 time 22.95s
Final training  10/4999 loss: 2.2684 time 23.23s
Final training  11/4999 loss: 2.2447 time 22.81s
Final training  12/4999 loss: 2.1963 time 23.28s
Final training  13/4999 loss: 2.1313 time 23.22s
Final training  14/4999 loss: 2.0975 time 23.25s
Final training  15/4999 loss: 2.0515 time 23.11s
Final training  16/4999 loss: 2.0290 time 23.15s
Final training  17/4999 loss: 2.0124 time 23.24s
Final training  18/4999 loss: 1.9583 time 22.85s
Final training  19/4999 loss: 1.9334 time 23.00s
Final training  20/4999 loss: 1.8430 time 23.11s
Final training  21/4999 loss: 1.8819 time 23.36s
Final training  22/4999 loss: 1.9470 time 23.45s
Final training  23/4999 loss: 1.8686 time 23.25s
Final training  24/4999 loss: 1.8484 time 23.28s
Final training  25/4999 loss: 1.8327 time 23.09s
Final training  26/4999 loss: 1.7893 time 23.10s
Final training  27/4999 loss: 1.7926 time 22.98s
Final training  28/4999 loss: 1.7496 time 22.82s
Final training  29/4999 loss: 1.7328 time 23.05s
Final training  30/4999 loss: 1.7675 time 23.07s
Final training  31/4999 loss: 1.6643 time 23.37s
Final training  32/4999 loss: 1.6457 time 22.94s
Final training  33/4999 loss: 1.7271 time 23.25s
Final training  34/4999 loss: 1.6719 time 23.69s
Final training  35/4999 loss: 1.5591 time 23.53s
Final training  36/4999 loss: 1.6208 time 23.68s
Final training  37/4999 loss: 1.6316 time 23.36s
Final training  38/4999 loss: 1.6421 time 23.65s
Final training  39/4999 loss: 1.6080 time 23.47s
Final training  40/4999 loss: 1.5833 time 23.34s
Final training  41/4999 loss: 1.5548 time 23.29s
Final training  42/4999 loss: 1.6119 time 23.17s
Final training  43/4999 loss: 1.5497 time 22.95s
Final training  44/4999 loss: 1.6508 time 23.00s
Final training  45/4999 loss: 1.5593 time 22.78s
Final training  46/4999 loss: 1.6023 time 22.99s
Final training  47/4999 loss: 1.5551 time 22.88s
Final training  48/4999 loss: 1.6009 time 22.69s
Final training  49/4999 loss: 1.5750 time 23.25s
Final training  50/4999 loss: 1.5855 time 22.98s
Final training  51/4999 loss: 1.5648 time 23.48s
Final training  52/4999 loss: 1.5349 time 23.65s
Final training  53/4999 loss: 1.5372 time 23.79s
Final training  54/4999 loss: 1.5038 time 24.47s
Final training  55/4999 loss: 1.5532 time 23.71s
Final training  56/4999 loss: 1.5306 time 23.89s
Final training  57/4999 loss: 1.6285 time 23.51s
Final training  58/4999 loss: 1.4934 time 23.60s
Final training  59/4999 loss: 1.4651 time 23.69s
Final training  60/4999 loss: 1.6053 time 23.79s
Final training  61/4999 loss: 1.5303 time 23.65s
Final training  62/4999 loss: 1.4429 time 23.87s
Final training  63/4999 loss: 1.4617 time 23.91s
Final training  64/4999 loss: 1.4227 time 23.67s
Final training  65/4999 loss: 1.4334 time 23.57s
Final training  66/4999 loss: 1.5545 time 23.99s
Final training  67/4999 loss: 1.5335 time 23.84s
Final training  68/4999 loss: 1.5408 time 23.91s
Final training  69/4999 loss: 1.5418 time 23.88s
Final training  70/4999 loss: 1.4927 time 23.80s
Final training  71/4999 loss: 1.4734 time 23.95s
Final training  72/4999 loss: 1.3997 time 24.00s
Final training  73/4999 loss: 1.4960 time 23.85s
Final training  74/4999 loss: 1.5167 time 23.74s
Final training  75/4999 loss: 1.4779 time 23.68s
Final training  76/4999 loss: 1.4121 time 23.97s
Final training  77/4999 loss: 1.5031 time 23.75s
Final training  78/4999 loss: 1.4497 time 23.76s
Final training  79/4999 loss: 1.4709 time 23.32s
Final training  80/4999 loss: 1.4400 time 23.76s
Final training  81/4999 loss: 1.4689 time 24.82s
Final training  82/4999 loss: 1.4106 time 25.28s
Final training  83/4999 loss: 1.4070 time 25.34s
Final training  84/4999 loss: 1.4250 time 25.01s
Final training  85/4999 loss: 1.4864 time 25.48s
Final training  86/4999 loss: 1.4388 time 25.24s
Final training  87/4999 loss: 1.3761 time 24.69s
Final training  88/4999 loss: 1.4627 time 24.29s
Final training  89/4999 loss: 1.4790 time 23.68s
Final training  90/4999 loss: 1.4675 time 23.66s
Final training  91/4999 loss: 1.3848 time 23.81s
Final training  92/4999 loss: 1.3484 time 23.70s
Final training  93/4999 loss: 1.3440 time 23.52s
Final training  94/4999 loss: 1.4804 time 23.76s
Final training  95/4999 loss: 1.4518 time 23.88s
Final training  96/4999 loss: 1.4118 time 23.57s
Final training  97/4999 loss: 1.3023 time 23.72s
Final training  98/4999 loss: 1.4842 time 23.74s
Final training  99/4999 loss: 1.3810 time 23.74s
Dice accuracy for each class:  (tensor([9.8322e-01, 4.6551e-06, 2.8217e-01, 2.7852e-05, 0.0000e+00, 0.0000e+00,
        7.1495e-01, 6.5856e-05, 0.0000e+00, 1.1142e-05, 2.1891e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  99/4999 acc [ 0.143] time 118.83s
Reset trigger time to 0
new best (0.000000 --> 0.143120). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  100/4999 loss: 1.3773 time 23.63s
Final training  101/4999 loss: 1.3951 time 23.65s
Final training  102/4999 loss: 1.3221 time 23.48s
Final training  103/4999 loss: 1.3866 time 23.63s
Final training  104/4999 loss: 1.3912 time 23.70s
Final training  105/4999 loss: 1.3143 time 23.44s
Final training  106/4999 loss: 1.4249 time 24.03s
Final training  107/4999 loss: 1.4000 time 23.62s
Final training  108/4999 loss: 1.3855 time 23.48s
Final training  109/4999 loss: 1.3591 time 23.64s
Final training  110/4999 loss: 1.3339 time 23.46s
Final training  111/4999 loss: 1.4009 time 23.80s
Final training  112/4999 loss: 1.4006 time 23.78s
Final training  113/4999 loss: 1.3602 time 23.63s
Final training  114/4999 loss: 1.3741 time 24.00s
Final training  115/4999 loss: 1.3321 time 23.98s
Final training  116/4999 loss: 1.3886 time 23.45s
Final training  117/4999 loss: 1.3771 time 23.65s
Final training  118/4999 loss: 1.4077 time 23.67s
Final training  119/4999 loss: 1.3131 time 23.93s
Final training  120/4999 loss: 1.4461 time 23.66s
Final training  121/4999 loss: 1.3311 time 23.89s
Final training  122/4999 loss: 1.3795 time 23.48s
Final training  123/4999 loss: 1.3796 time 23.80s
Final training  124/4999 loss: 1.3578 time 23.60s
Final training  125/4999 loss: 1.4955 time 23.66s
Final training  126/4999 loss: 1.4287 time 23.66s
Final training  127/4999 loss: 1.3879 time 23.73s
Final training  128/4999 loss: 1.3048 time 23.79s
Final training  129/4999 loss: 1.3757 time 23.71s
Final training  130/4999 loss: 1.3713 time 23.82s
Final training  131/4999 loss: 1.3599 time 23.58s
Final training  132/4999 loss: 1.3300 time 23.61s
Final training  133/4999 loss: 1.3972 time 23.88s
Final training  134/4999 loss: 1.3914 time 23.99s
Final training  135/4999 loss: 1.3512 time 23.79s
Final training  136/4999 loss: 1.3542 time 23.80s
Final training  137/4999 loss: 1.3328 time 23.92s
Final training  138/4999 loss: 1.3146 time 23.86s
Final training  139/4999 loss: 1.3746 time 23.99s
Final training  140/4999 loss: 1.3945 time 23.76s
Final training  141/4999 loss: 1.4235 time 23.60s
Final training  142/4999 loss: 1.3387 time 23.64s
Final training  143/4999 loss: 1.3285 time 23.49s
Final training  144/4999 loss: 1.3116 time 23.81s
Final training  145/4999 loss: 1.4497 time 24.04s
Final training  146/4999 loss: 1.2326 time 23.85s
Final training  147/4999 loss: 1.3051 time 23.94s
Final training  148/4999 loss: 1.3689 time 23.80s
Final training  149/4999 loss: 1.3028 time 23.52s
Final training  150/4999 loss: 1.2628 time 23.68s
Final training  151/4999 loss: 1.3772 time 23.66s
Final training  152/4999 loss: 1.3494 time 23.48s
Final training  153/4999 loss: 1.3865 time 23.75s
Final training  154/4999 loss: 1.3878 time 23.66s
Final training  155/4999 loss: 1.2682 time 23.74s
Final training  156/4999 loss: 1.2024 time 23.96s
Final training  157/4999 loss: 1.2695 time 23.67s
Final training  158/4999 loss: 1.3616 time 23.80s
Final training  159/4999 loss: 1.3520 time 23.65s
Final training  160/4999 loss: 1.3066 time 23.47s
Final training  161/4999 loss: 1.3197 time 23.80s
Final training  162/4999 loss: 1.3291 time 23.76s
Final training  163/4999 loss: 1.3202 time 23.92s
Final training  164/4999 loss: 1.2571 time 23.65s
Final training  165/4999 loss: 1.2755 time 23.72s
Final training  166/4999 loss: 1.3312 time 23.80s
Final training  167/4999 loss: 1.2447 time 23.76s
Final training  168/4999 loss: 1.3215 time 23.74s
Final training  169/4999 loss: 1.3101 time 23.95s
Final training  170/4999 loss: 1.2923 time 23.86s
Final training  171/4999 loss: 1.3466 time 23.93s
Final training  172/4999 loss: 1.3266 time 23.84s
Final training  173/4999 loss: 1.2843 time 23.61s
Final training  174/4999 loss: 1.2977 time 23.70s
Final training  175/4999 loss: 1.3327 time 23.93s
Final training  176/4999 loss: 1.2867 time 24.22s
Final training  177/4999 loss: 1.2631 time 23.68s
Final training  178/4999 loss: 1.2699 time 24.18s
Final training  179/4999 loss: 1.2560 time 23.89s
Final training  180/4999 loss: 1.2762 time 23.85s
Final training  181/4999 loss: 1.2554 time 23.84s
Final training  182/4999 loss: 1.2482 time 23.88s
Final training  183/4999 loss: 1.2324 time 23.72s
Final training  184/4999 loss: 1.2527 time 24.07s
Final training  185/4999 loss: 1.1823 time 23.97s
Final training  186/4999 loss: 1.2630 time 23.98s
Final training  187/4999 loss: 1.2274 time 23.81s
Final training  188/4999 loss: 1.3196 time 23.94s
Final training  189/4999 loss: 1.2917 time 23.48s
Final training  190/4999 loss: 1.2481 time 23.36s
Final training  191/4999 loss: 1.2401 time 23.31s
Final training  192/4999 loss: 1.2340 time 23.20s
Final training  193/4999 loss: 1.2689 time 23.71s
Final training  194/4999 loss: 1.1888 time 23.77s
Final training  195/4999 loss: 1.2393 time 23.93s
Final training  196/4999 loss: 1.2039 time 23.74s
Final training  197/4999 loss: 1.2250 time 23.85s
Final training  198/4999 loss: 1.2047 time 23.75s
Final training  199/4999 loss: 1.2485 time 23.87s
Dice accuracy for each class:  (tensor([0.9887, 0.2086, 0.6189, 0.2356, 0.0000, 0.0000, 0.7360, 0.4652, 0.0056,
        0.0987, 0.4440, 0.0149, 0.0000, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  199/4999 acc [ 0.276] time 121.16s
Reset trigger time to 0
new best (0.143120 --> 0.276171). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  200/4999 loss: 1.2394 time 23.52s
Final training  201/4999 loss: 1.2080 time 23.85s
Final training  202/4999 loss: 1.2348 time 23.57s
Final training  203/4999 loss: 1.1843 time 23.78s
Final training  204/4999 loss: 1.2225 time 23.69s
Final training  205/4999 loss: 1.2286 time 23.85s
Final training  206/4999 loss: 1.1894 time 23.64s
Final training  207/4999 loss: 1.1916 time 23.91s
Final training  208/4999 loss: 1.2684 time 23.71s
Final training  209/4999 loss: 1.1509 time 23.61s
Final training  210/4999 loss: 1.2044 time 24.09s
Final training  211/4999 loss: 1.1875 time 23.73s
Final training  212/4999 loss: 1.2073 time 23.94s
Final training  213/4999 loss: 1.1793 time 23.72s
Final training  214/4999 loss: 1.2123 time 23.57s
Final training  215/4999 loss: 1.2490 time 23.71s
Final training  216/4999 loss: 1.2716 time 23.74s
Final training  217/4999 loss: 1.2020 time 23.88s
Final training  218/4999 loss: 1.1797 time 23.55s
Final training  219/4999 loss: 1.1623 time 23.71s
Final training  220/4999 loss: 1.2526 time 23.65s
Final training  221/4999 loss: 1.2482 time 23.61s
Final training  222/4999 loss: 1.1866 time 23.99s
Final training  223/4999 loss: 1.2417 time 23.57s
Final training  224/4999 loss: 1.1702 time 23.52s
Final training  225/4999 loss: 1.1289 time 23.70s
Final training  226/4999 loss: 1.1563 time 23.70s
Final training  227/4999 loss: 1.2098 time 23.76s
Final training  228/4999 loss: 1.2037 time 23.86s
Final training  229/4999 loss: 1.2244 time 23.95s
Final training  230/4999 loss: 1.1692 time 24.25s
Final training  231/4999 loss: 1.1800 time 23.69s
Final training  232/4999 loss: 1.1518 time 24.18s
Final training  233/4999 loss: 1.2010 time 23.94s
Final training  234/4999 loss: 1.1687 time 23.90s
Final training  235/4999 loss: 1.1905 time 24.09s
Final training  236/4999 loss: 1.1442 time 24.10s
Final training  237/4999 loss: 1.1238 time 24.72s
Final training  238/4999 loss: 1.1590 time 23.85s
Final training  239/4999 loss: 1.1991 time 23.79s
Final training  240/4999 loss: 1.1866 time 23.76s
Final training  241/4999 loss: 1.1812 time 24.15s
Final training  242/4999 loss: 1.1360 time 24.20s
Final training  243/4999 loss: 1.0995 time 24.15s
Final training  244/4999 loss: 1.1803 time 24.18s
Final training  245/4999 loss: 1.1372 time 23.99s
Final training  246/4999 loss: 1.1571 time 24.01s
Final training  247/4999 loss: 1.1479 time 23.93s
Final training  248/4999 loss: 1.1238 time 23.81s
Final training  249/4999 loss: 1.1015 time 24.01s
Final training  250/4999 loss: 1.1165 time 23.97s
Final training  251/4999 loss: 1.1581 time 23.96s
Final training  252/4999 loss: 1.1437 time 23.98s
Final training  253/4999 loss: 1.1829 time 24.22s
Final training  254/4999 loss: 1.1867 time 24.06s
Final training  255/4999 loss: 1.1182 time 24.02s
Final training  256/4999 loss: 1.0915 time 23.97s
Final training  257/4999 loss: 1.1303 time 24.16s
Final training  258/4999 loss: 1.1609 time 23.94s
Final training  259/4999 loss: 1.1375 time 23.69s
Final training  260/4999 loss: 1.1657 time 24.05s
Final training  261/4999 loss: 1.1670 time 24.01s
Final training  262/4999 loss: 1.1129 time 23.87s
Final training  263/4999 loss: 1.0914 time 24.11s
Final training  264/4999 loss: 1.1257 time 24.00s
Final training  265/4999 loss: 1.1353 time 23.91s
Final training  266/4999 loss: 1.1804 time 24.02s
Final training  267/4999 loss: 1.1958 time 23.95s
Final training  268/4999 loss: 1.1101 time 24.10s
Final training  269/4999 loss: 1.1582 time 24.21s
Final training  270/4999 loss: 1.1355 time 24.16s
Final training  271/4999 loss: 1.1652 time 23.96s
Final training  272/4999 loss: 1.1067 time 24.13s
Final training  273/4999 loss: 1.1047 time 23.97s
Final training  274/4999 loss: 1.1433 time 24.23s
Final training  275/4999 loss: 1.1435 time 24.06s
Final training  276/4999 loss: 1.0912 time 23.92s
Final training  277/4999 loss: 1.1410 time 24.22s
Final training  278/4999 loss: 1.0938 time 23.86s
Final training  279/4999 loss: 1.1504 time 24.12s
Final training  280/4999 loss: 1.0995 time 24.23s
Final training  281/4999 loss: 1.1421 time 24.16s
Final training  282/4999 loss: 1.1064 time 23.95s
Final training  283/4999 loss: 1.1004 time 24.19s
Final training  284/4999 loss: 1.0964 time 23.97s
Final training  285/4999 loss: 1.1662 time 24.12s
Final training  286/4999 loss: 1.1311 time 24.21s
Final training  287/4999 loss: 1.1190 time 24.26s
Final training  288/4999 loss: 1.1208 time 24.17s
Final training  289/4999 loss: 1.0828 time 23.98s
Final training  290/4999 loss: 1.0941 time 23.95s
Final training  291/4999 loss: 1.1342 time 24.09s
Final training  292/4999 loss: 1.0541 time 24.11s
Final training  293/4999 loss: 1.1003 time 23.82s
Final training  294/4999 loss: 1.1250 time 24.12s
Final training  295/4999 loss: 1.1263 time 23.86s
Final training  296/4999 loss: 1.0788 time 23.62s
Final training  297/4999 loss: 1.1363 time 23.89s
Final training  298/4999 loss: 1.0825 time 23.89s
Final training  299/4999 loss: 1.0915 time 24.17s
Dice accuracy for each class:  (tensor([0.9882, 0.7508, 0.7653, 0.8133, 0.2547, 0.0000, 0.7669, 0.5917, 0.7852,
        0.5128, 0.4098, 0.3976, 0.0000, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  299/4999 acc [ 0.505] time 120.91s
Reset trigger time to 0
new best (0.276171 --> 0.505161). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  300/4999 loss: 1.0866 time 24.22s
Final training  301/4999 loss: 1.0858 time 24.04s
Final training  302/4999 loss: 1.0641 time 24.14s
Final training  303/4999 loss: 1.0916 time 23.80s
Final training  304/4999 loss: 1.0901 time 24.21s
Final training  305/4999 loss: 1.1482 time 24.31s
Final training  306/4999 loss: 1.1487 time 23.75s
Final training  307/4999 loss: 1.1578 time 24.24s
Final training  308/4999 loss: 1.0709 time 24.08s
Final training  309/4999 loss: 1.0233 time 23.93s
Final training  310/4999 loss: 1.0857 time 24.19s
Final training  311/4999 loss: 1.1031 time 24.06s
Final training  312/4999 loss: 1.0805 time 24.06s
Final training  313/4999 loss: 1.0909 time 23.93s
Final training  314/4999 loss: 1.1329 time 24.12s
Final training  315/4999 loss: 1.1297 time 23.99s
Final training  316/4999 loss: 1.0825 time 24.08s
Final training  317/4999 loss: 1.0692 time 24.03s
Final training  318/4999 loss: 1.0582 time 23.98s
Final training  319/4999 loss: 1.0562 time 24.38s
Final training  320/4999 loss: 1.0735 time 24.32s
Final training  321/4999 loss: 1.0738 time 24.29s
Final training  322/4999 loss: 1.1338 time 24.36s
Final training  323/4999 loss: 1.1154 time 24.14s
Final training  324/4999 loss: 1.0681 time 24.09s
Final training  325/4999 loss: 1.0889 time 24.00s
Final training  326/4999 loss: 1.0857 time 24.04s
Final training  327/4999 loss: 1.0461 time 23.91s
Final training  328/4999 loss: 1.0336 time 24.01s
Final training  329/4999 loss: 1.0448 time 24.10s
Final training  330/4999 loss: 1.0304 time 24.04s
Final training  331/4999 loss: 1.0671 time 24.14s
Final training  332/4999 loss: 1.0781 time 24.16s
Final training  333/4999 loss: 1.0596 time 24.02s
Final training  334/4999 loss: 1.0497 time 24.03s
Final training  335/4999 loss: 1.0724 time 24.11s
Final training  336/4999 loss: 1.0868 time 24.22s
Final training  337/4999 loss: 1.0536 time 23.98s
Final training  338/4999 loss: 1.1307 time 23.69s
Final training  339/4999 loss: 1.0698 time 24.23s
Final training  340/4999 loss: 1.0353 time 24.29s
Final training  341/4999 loss: 1.0438 time 23.93s
Final training  342/4999 loss: 1.0888 time 24.16s
Final training  343/4999 loss: 1.0422 time 24.08s
Final training  344/4999 loss: 1.0669 time 24.31s
Final training  345/4999 loss: 1.0643 time 24.12s
Final training  346/4999 loss: 1.0654 time 24.00s
Final training  347/4999 loss: 1.1034 time 24.05s
Final training  348/4999 loss: 1.0284 time 24.20s
Final training  349/4999 loss: 1.0577 time 24.35s
Final training  350/4999 loss: 1.0217 time 24.20s
Final training  351/4999 loss: 1.0222 time 24.13s
Final training  352/4999 loss: 1.0690 time 24.21s
Final training  353/4999 loss: 1.0069 time 23.98s
Final training  354/4999 loss: 1.0227 time 24.06s
Final training  355/4999 loss: 1.0073 time 24.06s
Final training  356/4999 loss: 1.0772 time 24.06s
Final training  357/4999 loss: 1.0404 time 24.08s
Final training  358/4999 loss: 1.0532 time 24.16s
Final training  359/4999 loss: 1.0314 time 24.30s
Final training  360/4999 loss: 1.0210 time 24.07s
Final training  361/4999 loss: 1.0530 time 24.23s
Final training  362/4999 loss: 1.0591 time 24.20s
Final training  363/4999 loss: 1.0941 time 24.22s
Final training  364/4999 loss: 1.0268 time 24.29s
Final training  365/4999 loss: 1.0198 time 24.20s
Final training  366/4999 loss: 1.0507 time 24.21s
Final training  367/4999 loss: 1.0350 time 24.22s
Final training  368/4999 loss: 1.0105 time 24.26s
Final training  369/4999 loss: 0.9642 time 24.11s
Final training  370/4999 loss: 1.0028 time 23.74s
Final training  371/4999 loss: 1.0674 time 24.09s
Final training  372/4999 loss: 1.0445 time 24.05s
Final training  373/4999 loss: 1.0322 time 23.99s
Final training  374/4999 loss: 1.0630 time 24.20s
Final training  375/4999 loss: 1.0228 time 24.46s
Final training  376/4999 loss: 1.0716 time 24.30s
Final training  377/4999 loss: 1.0385 time 24.26s
Final training  378/4999 loss: 1.0247 time 24.30s
Final training  379/4999 loss: 1.1167 time 24.32s
Final training  380/4999 loss: 1.0208 time 24.44s
Final training  381/4999 loss: 1.0482 time 24.36s
Final training  382/4999 loss: 1.0050 time 24.25s
Final training  383/4999 loss: 1.0102 time 23.97s
Final training  384/4999 loss: 1.0369 time 24.16s
Final training  385/4999 loss: 1.0875 time 23.99s
Final training  386/4999 loss: 1.0169 time 24.09s
Final training  387/4999 loss: 1.0112 time 24.15s
Final training  388/4999 loss: 0.9920 time 24.17s
Final training  389/4999 loss: 1.0695 time 24.12s
Final training  390/4999 loss: 1.0916 time 23.85s
Final training  391/4999 loss: 1.0341 time 23.87s
Final training  392/4999 loss: 1.0199 time 23.96s
Final training  393/4999 loss: 1.0258 time 24.09s
Final training  394/4999 loss: 1.0660 time 24.01s
Final training  395/4999 loss: 0.9696 time 24.11s
Final training  396/4999 loss: 1.0121 time 23.86s
Final training  397/4999 loss: 1.0240 time 23.85s
Final training  398/4999 loss: 1.0242 time 23.88s
Final training  399/4999 loss: 1.0687 time 23.80s
Dice accuracy for each class:  (tensor([0.9919, 0.9024, 0.6957, 0.4835, 0.5821, 0.0000, 0.8517, 0.4967, 0.8294,
        0.7131, 0.5843, 0.5752, 0.0000, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  399/4999 acc [ 0.549] time 119.62s
Reset trigger time to 0
new best (0.505161 --> 0.549362). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  400/4999 loss: 1.0288 time 24.35s
Final training  401/4999 loss: 1.0698 time 24.53s
Final training  402/4999 loss: 1.0412 time 24.33s
Final training  403/4999 loss: 1.0166 time 24.53s
Final training  404/4999 loss: 1.0595 time 24.30s
Final training  405/4999 loss: 1.0308 time 24.29s
Final training  406/4999 loss: 1.0909 time 24.16s
Final training  407/4999 loss: 1.0704 time 23.73s
Final training  408/4999 loss: 1.0395 time 24.07s
Final training  409/4999 loss: 1.0108 time 23.86s
Final training  410/4999 loss: 0.9851 time 24.09s
Final training  411/4999 loss: 1.0086 time 24.05s
Final training  412/4999 loss: 1.0193 time 24.26s
Final training  413/4999 loss: 1.0033 time 24.03s
Final training  414/4999 loss: 1.0415 time 23.96s
Final training  415/4999 loss: 1.0173 time 24.18s
Final training  416/4999 loss: 0.9883 time 24.19s
Final training  417/4999 loss: 0.9689 time 24.53s
Final training  418/4999 loss: 1.0292 time 24.07s
Final training  419/4999 loss: 0.9879 time 23.88s
Final training  420/4999 loss: 1.0034 time 24.13s
Final training  421/4999 loss: 1.0084 time 24.43s
Final training  422/4999 loss: 1.0072 time 24.36s
Final training  423/4999 loss: 0.9931 time 24.31s
Final training  424/4999 loss: 1.0367 time 23.86s
Final training  425/4999 loss: 0.9815 time 24.14s
Final training  426/4999 loss: 0.9800 time 24.06s
Final training  427/4999 loss: 1.0192 time 23.88s
Final training  428/4999 loss: 0.9979 time 23.80s
Final training  429/4999 loss: 1.0335 time 24.68s
Final training  430/4999 loss: 1.0037 time 24.51s
Final training  431/4999 loss: 1.0391 time 24.51s
Final training  432/4999 loss: 1.0182 time 24.64s
Final training  433/4999 loss: 1.0402 time 24.66s
Final training  434/4999 loss: 1.0198 time 24.72s
Final training  435/4999 loss: 1.0097 time 24.61s
Final training  436/4999 loss: 1.0468 time 24.13s
Final training  437/4999 loss: 0.9946 time 24.11s
Final training  438/4999 loss: 1.0234 time 24.18s
Final training  439/4999 loss: 0.9748 time 24.07s
Final training  440/4999 loss: 0.9802 time 24.19s
Final training  441/4999 loss: 1.0084 time 23.77s
Final training  442/4999 loss: 0.9700 time 23.88s
Final training  443/4999 loss: 1.0404 time 23.80s
Final training  444/4999 loss: 1.0197 time 24.03s
Final training  445/4999 loss: 0.9798 time 24.04s
Final training  446/4999 loss: 1.0064 time 24.04s
Final training  447/4999 loss: 0.9903 time 24.11s
Final training  448/4999 loss: 0.9914 time 24.05s
Final training  449/4999 loss: 0.9833 time 24.06s
Final training  450/4999 loss: 1.0375 time 24.07s
Final training  451/4999 loss: 1.0140 time 24.03s
Final training  452/4999 loss: 1.0370 time 24.15s
Final training  453/4999 loss: 1.0072 time 23.65s
Final training  454/4999 loss: 1.0296 time 24.05s
Final training  455/4999 loss: 1.0054 time 24.16s
Final training  456/4999 loss: 1.0211 time 24.07s
Final training  457/4999 loss: 1.0429 time 24.07s
Final training  458/4999 loss: 1.0025 time 23.94s
Final training  459/4999 loss: 1.0151 time 23.81s
Final training  460/4999 loss: 1.0014 time 24.09s
Final training  461/4999 loss: 0.9625 time 24.16s
Final training  462/4999 loss: 0.9918 time 23.97s
Final training  463/4999 loss: 0.9486 time 24.07s
Final training  464/4999 loss: 1.0163 time 23.86s
Final training  465/4999 loss: 1.0078 time 23.87s
Final training  466/4999 loss: 0.9786 time 24.13s
Final training  467/4999 loss: 0.9738 time 24.04s
Final training  468/4999 loss: 1.0160 time 24.10s
Final training  469/4999 loss: 0.9961 time 23.91s
Final training  470/4999 loss: 0.9971 time 24.10s
Final training  471/4999 loss: 1.0106 time 24.00s
Final training  472/4999 loss: 1.0165 time 24.11s
Final training  473/4999 loss: 1.0052 time 23.96s
Final training  474/4999 loss: 1.0256 time 24.08s
Final training  475/4999 loss: 0.9951 time 23.98s
Final training  476/4999 loss: 1.0464 time 24.16s
Final training  477/4999 loss: 1.0020 time 23.93s
Final training  478/4999 loss: 0.9527 time 24.17s
Final training  479/4999 loss: 0.9973 time 24.07s
Final training  480/4999 loss: 0.9911 time 23.92s
Final training  481/4999 loss: 1.0070 time 23.74s
Final training  482/4999 loss: 1.0027 time 23.97s
Final training  483/4999 loss: 1.0227 time 24.07s
Final training  484/4999 loss: 0.9877 time 24.15s
Final training  485/4999 loss: 0.9705 time 24.25s
Final training  486/4999 loss: 0.9695 time 24.20s
Final training  487/4999 loss: 0.9774 time 23.79s
Final training  488/4999 loss: 0.9871 time 23.94s
Final training  489/4999 loss: 1.0071 time 24.14s
Final training  490/4999 loss: 0.9731 time 23.98s
Final training  491/4999 loss: 0.9891 time 24.00s
Final training  492/4999 loss: 0.9641 time 23.95s
Final training  493/4999 loss: 0.9747 time 24.14s
Final training  494/4999 loss: 0.9415 time 24.08s
Final training  495/4999 loss: 0.9750 time 23.79s
Final training  496/4999 loss: 0.9624 time 24.07s
Final training  497/4999 loss: 0.9806 time 24.00s
Final training  498/4999 loss: 0.9814 time 23.91s
Final training  499/4999 loss: 0.9905 time 24.11s
Dice accuracy for each class:  (tensor([0.9908, 0.9154, 0.8130, 0.7487, 0.6106, 0.0000, 0.8358, 0.5788, 0.8571,
        0.7512, 0.5490, 0.5832, 0.0000, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  499/4999 acc [ 0.587] time 121.05s
Reset trigger time to 0
new best (0.549362 --> 0.587175). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  500/4999 loss: 0.9713 time 23.64s
Final training  501/4999 loss: 0.9433 time 23.99s
Final training  502/4999 loss: 0.9780 time 24.15s
Final training  503/4999 loss: 0.9725 time 24.02s
Final training  504/4999 loss: 1.0120 time 23.85s
Final training  505/4999 loss: 0.9653 time 24.13s
Final training  506/4999 loss: 0.9860 time 24.27s
Final training  507/4999 loss: 0.9438 time 24.31s
Final training  508/4999 loss: 0.9778 time 24.73s
Final training  509/4999 loss: 0.9956 time 24.03s
Final training  510/4999 loss: 0.9884 time 23.71s
Final training  511/4999 loss: 0.9959 time 24.05s
Final training  512/4999 loss: 1.0012 time 23.89s
Final training  513/4999 loss: 0.9823 time 24.05s
Final training  514/4999 loss: 0.9432 time 23.93s
Final training  515/4999 loss: 0.9694 time 23.89s
Final training  516/4999 loss: 0.9946 time 23.85s
Final training  517/4999 loss: 0.9421 time 23.71s
Final training  518/4999 loss: 0.9736 time 23.98s
Final training  519/4999 loss: 0.9799 time 24.02s
Final training  520/4999 loss: 0.9580 time 24.13s
Final training  521/4999 loss: 0.9827 time 24.13s
Final training  522/4999 loss: 0.9455 time 24.02s
Final training  523/4999 loss: 0.9685 time 24.23s
Final training  524/4999 loss: 0.9691 time 23.99s
Final training  525/4999 loss: 0.9912 time 24.04s
Final training  526/4999 loss: 0.9774 time 24.11s
Final training  527/4999 loss: 0.9493 time 24.00s
Final training  528/4999 loss: 0.9548 time 24.10s
Final training  529/4999 loss: 1.0073 time 23.84s
Final training  530/4999 loss: 0.9973 time 24.04s
Final training  531/4999 loss: 0.9776 time 23.61s
Final training  532/4999 loss: 0.9760 time 24.01s
Final training  533/4999 loss: 0.9735 time 23.82s
Final training  534/4999 loss: 1.0007 time 23.99s
Final training  535/4999 loss: 0.9798 time 23.41s
Final training  536/4999 loss: 0.9617 time 24.03s
Final training  537/4999 loss: 0.9604 time 24.00s
Final training  538/4999 loss: 0.9616 time 23.94s
Final training  539/4999 loss: 0.9693 time 24.11s
Final training  540/4999 loss: 0.9720 time 24.33s
Final training  541/4999 loss: 0.9719 time 23.93s
Final training  542/4999 loss: 0.9502 time 24.37s
Final training  543/4999 loss: 0.9595 time 24.70s
Final training  544/4999 loss: 0.9647 time 24.47s
Final training  545/4999 loss: 0.9724 time 24.41s
Final training  546/4999 loss: 0.9322 time 24.45s
Final training  547/4999 loss: 0.9595 time 24.13s
Final training  548/4999 loss: 0.9703 time 23.86s
Final training  549/4999 loss: 0.9752 time 23.96s
Final training  550/4999 loss: 0.9810 time 23.86s
Final training  551/4999 loss: 0.9501 time 24.06s
Final training  552/4999 loss: 0.9363 time 24.01s
Final training  553/4999 loss: 0.9453 time 23.97s
Final training  554/4999 loss: 0.9933 time 24.07s
Final training  555/4999 loss: 0.9802 time 24.29s
Final training  556/4999 loss: 0.9646 time 24.36s
Final training  557/4999 loss: 0.9609 time 24.54s
Final training  558/4999 loss: 0.9635 time 24.33s
Final training  559/4999 loss: 0.9721 time 24.12s
Final training  560/4999 loss: 0.9534 time 24.34s
Final training  561/4999 loss: 0.9682 time 24.37s
Final training  562/4999 loss: 0.9836 time 24.33s
Final training  563/4999 loss: 1.0340 time 24.38s
Final training  564/4999 loss: 0.9639 time 24.21s
Final training  565/4999 loss: 0.9695 time 24.29s
Final training  566/4999 loss: 0.9630 time 24.37s
Final training  567/4999 loss: 0.9789 time 23.97s
Final training  568/4999 loss: 0.9631 time 24.19s
Final training  569/4999 loss: 0.9472 time 24.37s
Final training  570/4999 loss: 0.9930 time 24.26s
Final training  571/4999 loss: 0.9565 time 24.17s
Final training  572/4999 loss: 0.9976 time 24.26s
Final training  573/4999 loss: 0.9437 time 24.32s
Final training  574/4999 loss: 0.9367 time 24.20s
Final training  575/4999 loss: 0.9624 time 24.31s
Final training  576/4999 loss: 0.9602 time 24.06s
Final training  577/4999 loss: 0.9507 time 23.96s
Final training  578/4999 loss: 0.9390 time 23.98s
Final training  579/4999 loss: 1.0078 time 23.97s
Final training  580/4999 loss: 1.0311 time 24.10s
Final training  581/4999 loss: 0.9569 time 24.04s
Final training  582/4999 loss: 0.9522 time 23.79s
Final training  583/4999 loss: 0.9492 time 23.87s
Final training  584/4999 loss: 0.9667 time 23.96s
Final training  585/4999 loss: 0.9323 time 23.85s
Final training  586/4999 loss: 0.9369 time 23.87s
Final training  587/4999 loss: 0.9471 time 24.15s
Final training  588/4999 loss: 0.9544 time 23.66s
Final training  589/4999 loss: 0.9257 time 23.81s
Final training  590/4999 loss: 0.9538 time 24.31s
Final training  591/4999 loss: 0.9690 time 24.29s
Final training  592/4999 loss: 0.9867 time 24.06s
Final training  593/4999 loss: 0.9586 time 24.30s
Final training  594/4999 loss: 1.0410 time 23.97s
Final training  595/4999 loss: 0.9496 time 24.06s
Final training  596/4999 loss: 0.9612 time 24.06s
Final training  597/4999 loss: 0.9409 time 23.76s
Final training  598/4999 loss: 0.9464 time 24.12s
Final training  599/4999 loss: 0.9288 time 24.19s
Dice accuracy for each class:  (tensor([0.9918, 0.9112, 0.8479, 0.8732, 0.6159, 0.0000, 0.8223, 0.7328, 0.8517,
        0.7186, 0.5632, 0.5721, 0.0000, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  599/4999 acc [ 0.606] time 121.16s
Reset trigger time to 0
new best (0.587175 --> 0.606496). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  600/4999 loss: 0.9462 time 24.03s
Final training  601/4999 loss: 0.9503 time 24.16s
Final training  602/4999 loss: 0.9587 time 24.41s
Final training  603/4999 loss: 0.9648 time 24.12s
Final training  604/4999 loss: 0.9556 time 23.96s
Final training  605/4999 loss: 0.9301 time 24.08s
Final training  606/4999 loss: 0.9610 time 24.06s
Final training  607/4999 loss: 0.9483 time 24.10s
Final training  608/4999 loss: 0.9673 time 24.52s
Final training  609/4999 loss: 0.9362 time 24.18s
Final training  610/4999 loss: 0.9179 time 24.13s
Final training  611/4999 loss: 0.9460 time 24.08s
Final training  612/4999 loss: 0.9419 time 23.87s
Final training  613/4999 loss: 0.9385 time 24.15s
Final training  614/4999 loss: 0.9508 time 24.29s
Final training  615/4999 loss: 0.9090 time 24.11s
Final training  616/4999 loss: 0.9110 time 24.16s
Final training  617/4999 loss: 0.9685 time 24.07s
Final training  618/4999 loss: 0.9600 time 24.12s
Final training  619/4999 loss: 0.9471 time 24.16s
Final training  620/4999 loss: 0.9341 time 24.28s
Final training  621/4999 loss: 0.9320 time 23.97s
Final training  622/4999 loss: 0.9863 time 24.08s
Final training  623/4999 loss: 0.9679 time 24.21s
Final training  624/4999 loss: 0.9504 time 24.34s
Final training  625/4999 loss: 0.9406 time 24.31s
Final training  626/4999 loss: 0.9306 time 23.91s
Final training  627/4999 loss: 0.9175 time 24.55s
Final training  628/4999 loss: 0.9306 time 24.35s
Final training  629/4999 loss: 0.9121 time 24.02s
Final training  630/4999 loss: 0.9181 time 24.18s
Final training  631/4999 loss: 0.9213 time 24.27s
Final training  632/4999 loss: 1.0186 time 24.29s
Final training  633/4999 loss: 0.9393 time 24.27s
Final training  634/4999 loss: 0.9762 time 24.11s
Final training  635/4999 loss: 0.9342 time 24.02s
Final training  636/4999 loss: 0.9830 time 24.35s
Final training  637/4999 loss: 0.9694 time 24.19s
Final training  638/4999 loss: 0.9505 time 24.21s
Final training  639/4999 loss: 0.9611 time 24.25s
Final training  640/4999 loss: 0.9431 time 24.09s
Final training  641/4999 loss: 0.9697 time 24.12s
Final training  642/4999 loss: 0.9133 time 24.16s
Final training  643/4999 loss: 0.9446 time 24.05s
Final training  644/4999 loss: 0.9725 time 24.15s
Final training  645/4999 loss: 0.9317 time 24.07s
Final training  646/4999 loss: 0.9336 time 24.09s
Final training  647/4999 loss: 0.9083 time 23.86s
Final training  648/4999 loss: 0.9501 time 24.28s
Final training  649/4999 loss: 0.9285 time 24.09s
Final training  650/4999 loss: 0.9392 time 24.25s
Final training  651/4999 loss: 0.9227 time 23.89s
Final training  652/4999 loss: 0.9304 time 24.07s
Final training  653/4999 loss: 0.9059 time 23.99s
Final training  654/4999 loss: 0.8973 time 23.84s
Final training  655/4999 loss: 0.9230 time 23.92s
Final training  656/4999 loss: 0.8940 time 24.08s
Final training  657/4999 loss: 0.9418 time 23.93s
Final training  658/4999 loss: 0.9741 time 24.05s
Final training  659/4999 loss: 0.9329 time 23.89s
Final training  660/4999 loss: 0.9402 time 24.18s
Final training  661/4999 loss: 0.9230 time 24.12s
Final training  662/4999 loss: 0.9224 time 24.02s
Final training  663/4999 loss: 0.9102 time 24.11s
Final training  664/4999 loss: 0.9321 time 24.26s
Final training  665/4999 loss: 0.9691 time 24.01s
Final training  666/4999 loss: 0.9890 time 24.21s
Final training  667/4999 loss: 0.9263 time 24.26s
Final training  668/4999 loss: 0.9117 time 24.20s
Final training  669/4999 loss: 0.9404 time 24.02s
Final training  670/4999 loss: 0.9384 time 24.05s
Final training  671/4999 loss: 0.9342 time 23.83s
Final training  672/4999 loss: 0.9299 time 24.06s
Final training  673/4999 loss: 0.9043 time 24.29s
Final training  674/4999 loss: 0.9037 time 24.31s
Final training  675/4999 loss: 0.9399 time 23.98s
Final training  676/4999 loss: 0.9006 time 24.19s
Final training  677/4999 loss: 0.8878 time 24.20s
Final training  678/4999 loss: 0.9386 time 24.13s
Final training  679/4999 loss: 0.9319 time 24.01s
Final training  680/4999 loss: 0.9469 time 24.28s
Final training  681/4999 loss: 0.9429 time 24.07s
Final training  682/4999 loss: 0.9169 time 24.10s
Final training  683/4999 loss: 0.9193 time 24.24s
Final training  684/4999 loss: 0.9473 time 24.11s
Final training  685/4999 loss: 0.9583 time 24.30s
Final training  686/4999 loss: 0.9436 time 24.25s
Final training  687/4999 loss: 0.9382 time 24.23s
Final training  688/4999 loss: 0.9171 time 24.11s
Final training  689/4999 loss: 0.9114 time 24.19s
Final training  690/4999 loss: 0.8896 time 24.18s
Final training  691/4999 loss: 0.9386 time 24.04s
Final training  692/4999 loss: 0.9217 time 24.11s
Final training  693/4999 loss: 0.9529 time 24.28s
Final training  694/4999 loss: 0.9579 time 24.00s
Final training  695/4999 loss: 0.9260 time 24.08s
Final training  696/4999 loss: 0.9267 time 24.09s
Final training  697/4999 loss: 0.9336 time 24.01s
Final training  698/4999 loss: 0.9135 time 24.19s
Final training  699/4999 loss: 0.9034 time 23.97s
Dice accuracy for each class:  (tensor([0.9921, 0.8804, 0.7962, 0.8624, 0.7278, 0.0062, 0.8363, 0.6855, 0.8585,
        0.7862, 0.6912, 0.6196, 0.0000, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  699/4999 acc [ 0.623] time 121.08s
Reset trigger time to 0
new best (0.606496 --> 0.622762). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  700/4999 loss: 0.9198 time 24.21s
Final training  701/4999 loss: 0.9216 time 24.25s
Final training  702/4999 loss: 0.9325 time 24.66s
Final training  703/4999 loss: 0.9104 time 24.34s
Final training  704/4999 loss: 0.9260 time 24.24s
Final training  705/4999 loss: 0.9796 time 24.20s
Final training  706/4999 loss: 0.9486 time 24.09s
Final training  707/4999 loss: 0.9269 time 24.22s
Final training  708/4999 loss: 0.9182 time 24.25s
Final training  709/4999 loss: 0.9040 time 24.25s
Final training  710/4999 loss: 0.9215 time 24.49s
Final training  711/4999 loss: 0.9223 time 24.60s
Final training  712/4999 loss: 0.9071 time 24.87s
Final training  713/4999 loss: 0.9405 time 24.97s
Final training  714/4999 loss: 0.9366 time 24.64s
Final training  715/4999 loss: 0.9411 time 24.42s
Final training  716/4999 loss: 0.9262 time 24.45s
Final training  717/4999 loss: 0.9230 time 24.44s
Final training  718/4999 loss: 0.9596 time 24.55s
Final training  719/4999 loss: 0.9147 time 24.24s
Final training  720/4999 loss: 0.9288 time 24.24s
Final training  721/4999 loss: 0.9130 time 24.63s
Final training  722/4999 loss: 0.9072 time 24.56s
Final training  723/4999 loss: 0.9676 time 24.75s
Final training  724/4999 loss: 0.9299 time 24.72s
Final training  725/4999 loss: 0.9254 time 24.70s
Final training  726/4999 loss: 0.9386 time 24.77s
Final training  727/4999 loss: 0.9123 time 24.64s
Final training  728/4999 loss: 0.8946 time 24.28s
Final training  729/4999 loss: 0.9168 time 24.11s
Final training  730/4999 loss: 0.9460 time 24.60s
Final training  731/4999 loss: 0.9064 time 24.75s
Final training  732/4999 loss: 0.9172 time 24.79s
Final training  733/4999 loss: 0.9085 time 24.63s
Final training  734/4999 loss: 0.9400 time 24.84s
Final training  735/4999 loss: 0.9200 time 24.25s
Final training  736/4999 loss: 0.9505 time 24.66s
Final training  737/4999 loss: 0.9693 time 24.77s
Final training  738/4999 loss: 0.9322 time 24.25s
Final training  739/4999 loss: 0.9068 time 24.12s
Final training  740/4999 loss: 0.9283 time 24.04s
Final training  741/4999 loss: 0.9006 time 24.23s
Final training  742/4999 loss: 0.9225 time 24.14s
Final training  743/4999 loss: 0.9255 time 24.17s
Final training  744/4999 loss: 0.8971 time 24.13s
Final training  745/4999 loss: 0.9313 time 24.12s
Final training  746/4999 loss: 0.9078 time 23.83s
Final training  747/4999 loss: 0.9384 time 24.67s
Final training  748/4999 loss: 0.9098 time 24.36s
Final training  749/4999 loss: 0.9185 time 24.18s
Final training  750/4999 loss: 0.9129 time 24.35s
Final training  751/4999 loss: 0.9259 time 24.45s
Final training  752/4999 loss: 0.9248 time 24.64s
Final training  753/4999 loss: 0.9245 time 24.18s
Final training  754/4999 loss: 0.9166 time 24.03s
Final training  755/4999 loss: 0.9058 time 24.31s
Final training  756/4999 loss: 0.9135 time 24.03s
Final training  757/4999 loss: 0.9490 time 24.32s
Final training  758/4999 loss: 0.9148 time 24.59s
Final training  759/4999 loss: 0.8960 time 24.34s
Final training  760/4999 loss: 0.8928 time 23.91s
Final training  761/4999 loss: 0.8866 time 23.99s
Final training  762/4999 loss: 0.9047 time 24.18s
Final training  763/4999 loss: 0.9126 time 24.26s
Final training  764/4999 loss: 0.8975 time 24.21s
Final training  765/4999 loss: 0.9073 time 24.23s
Final training  766/4999 loss: 0.8931 time 23.71s
Final training  767/4999 loss: 0.8985 time 24.13s
Final training  768/4999 loss: 0.9154 time 24.00s
Final training  769/4999 loss: 0.8838 time 24.25s
Final training  770/4999 loss: 0.8866 time 24.43s
Final training  771/4999 loss: 0.8855 time 24.57s
Final training  772/4999 loss: 0.9051 time 24.29s
Final training  773/4999 loss: 0.8956 time 24.36s
Final training  774/4999 loss: 0.8955 time 24.35s
Final training  775/4999 loss: 0.9340 time 24.37s
Final training  776/4999 loss: 0.9036 time 24.22s
Final training  777/4999 loss: 0.9329 time 24.28s
Final training  778/4999 loss: 0.9257 time 24.66s
Final training  779/4999 loss: 0.9666 time 24.48s
Final training  780/4999 loss: 0.8834 time 24.37s
Final training  781/4999 loss: 0.9256 time 24.43s
Final training  782/4999 loss: 0.9493 time 24.51s
Final training  783/4999 loss: 0.9297 time 24.46s
Final training  784/4999 loss: 0.9397 time 24.48s
Final training  785/4999 loss: 0.9360 time 24.39s
Final training  786/4999 loss: 0.9126 time 24.36s
Final training  787/4999 loss: 0.9194 time 24.36s
Final training  788/4999 loss: 0.9192 time 24.29s
Final training  789/4999 loss: 0.8999 time 24.11s
Final training  790/4999 loss: 0.8961 time 24.19s
Final training  791/4999 loss: 0.8928 time 24.27s
Final training  792/4999 loss: 0.8963 time 24.11s
Final training  793/4999 loss: 0.9600 time 24.20s
Final training  794/4999 loss: 0.9335 time 24.21s
Final training  795/4999 loss: 0.9293 time 24.08s
Final training  796/4999 loss: 0.9858 time 24.23s
Final training  797/4999 loss: 0.9235 time 23.98s
Final training  798/4999 loss: 0.8954 time 24.18s
Final training  799/4999 loss: 0.9137 time 24.09s
Dice accuracy for each class:  (tensor([0.9934, 0.9159, 0.8164, 0.8644, 0.6821, 0.1582, 0.8718, 0.6435, 0.8443,
        0.7647, 0.6732, 0.6144, 0.3085, 0.0000], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  799/4999 acc [ 0.653] time 121.10s
Reset trigger time to 0
new best (0.622762 --> 0.652859). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  800/4999 loss: 0.8960 time 24.18s
Final training  801/4999 loss: 0.9100 time 24.18s
Final training  802/4999 loss: 0.8816 time 24.05s
Final training  803/4999 loss: 0.8802 time 24.33s
Final training  804/4999 loss: 0.8893 time 24.09s
Final training  805/4999 loss: 0.8973 time 23.96s
Final training  806/4999 loss: 0.8958 time 24.18s
Final training  807/4999 loss: 0.8774 time 23.78s
Final training  808/4999 loss: 0.9243 time 24.11s
Final training  809/4999 loss: 0.8887 time 23.88s
Final training  810/4999 loss: 0.8967 time 24.20s
Final training  811/4999 loss: 0.8899 time 24.05s
Final training  812/4999 loss: 0.8888 time 23.94s
Final training  813/4999 loss: 0.9145 time 24.02s
Final training  814/4999 loss: 0.8984 time 23.94s
Final training  815/4999 loss: 0.8946 time 23.66s
Final training  816/4999 loss: 0.9106 time 24.04s
Final training  817/4999 loss: 0.9522 time 24.36s
Final training  818/4999 loss: 0.9093 time 24.12s
Final training  819/4999 loss: 0.9573 time 24.01s
Final training  820/4999 loss: 0.9607 time 24.23s
Final training  821/4999 loss: 0.9396 time 24.05s
Final training  822/4999 loss: 0.9068 time 24.17s
Final training  823/4999 loss: 0.8932 time 24.03s
Final training  824/4999 loss: 0.8951 time 24.08s
Final training  825/4999 loss: 0.9045 time 24.13s
Final training  826/4999 loss: 0.9270 time 24.29s
Final training  827/4999 loss: 0.9215 time 24.23s
Final training  828/4999 loss: 0.9527 time 24.28s
Final training  829/4999 loss: 0.9472 time 24.11s
Final training  830/4999 loss: 0.9435 time 24.58s
Final training  831/4999 loss: 0.8944 time 24.05s
Final training  832/4999 loss: 0.8934 time 24.33s
Final training  833/4999 loss: 0.9093 time 24.17s
Final training  834/4999 loss: 0.9742 time 24.09s
Final training  835/4999 loss: 0.9084 time 24.42s
Final training  836/4999 loss: 0.8676 time 24.31s
Final training  837/4999 loss: 0.8942 time 24.15s
Final training  838/4999 loss: 0.8870 time 24.22s
Final training  839/4999 loss: 0.8810 time 24.21s
Final training  840/4999 loss: 0.8928 time 24.06s
Final training  841/4999 loss: 0.8915 time 24.26s
Final training  842/4999 loss: 0.8870 time 24.19s
Final training  843/4999 loss: 0.9015 time 24.11s
Final training  844/4999 loss: 0.9028 time 24.08s
Final training  845/4999 loss: 0.8836 time 24.23s
Final training  846/4999 loss: 0.9399 time 23.80s
Final training  847/4999 loss: 0.9239 time 23.99s
Final training  848/4999 loss: 0.9079 time 24.12s
Final training  849/4999 loss: 0.9120 time 23.99s
Final training  850/4999 loss: 0.9082 time 23.97s
Final training  851/4999 loss: 0.8777 time 24.14s
Final training  852/4999 loss: 0.8741 time 23.95s
Final training  853/4999 loss: 0.8844 time 23.85s
Final training  854/4999 loss: 0.9014 time 24.06s
Final training  855/4999 loss: 0.9093 time 23.85s
Final training  856/4999 loss: 0.8893 time 23.67s
Final training  857/4999 loss: 0.8745 time 24.22s
Final training  858/4999 loss: 0.8828 time 23.99s
Final training  859/4999 loss: 0.9008 time 24.50s
Final training  860/4999 loss: 0.9086 time 24.71s
Final training  861/4999 loss: 0.8958 time 24.30s
Final training  862/4999 loss: 0.8878 time 24.57s
Final training  863/4999 loss: 0.9140 time 24.53s
Final training  864/4999 loss: 0.9265 time 24.45s
Final training  865/4999 loss: 0.9224 time 24.53s
Final training  866/4999 loss: 0.9148 time 24.64s
Final training  867/4999 loss: 0.8826 time 24.52s
Final training  868/4999 loss: 0.9180 time 24.34s
Final training  869/4999 loss: 0.8941 time 24.19s
Final training  870/4999 loss: 0.8904 time 24.29s
Final training  871/4999 loss: 0.8887 time 24.17s
Final training  872/4999 loss: 0.9124 time 24.23s
Final training  873/4999 loss: 0.9097 time 24.35s
Final training  874/4999 loss: 0.9319 time 24.23s
Final training  875/4999 loss: 0.8961 time 24.13s
Final training  876/4999 loss: 0.8818 time 24.12s
Final training  877/4999 loss: 0.8805 time 24.10s
Final training  878/4999 loss: 0.8817 time 24.06s
Final training  879/4999 loss: 0.9000 time 24.02s
Final training  880/4999 loss: 0.8770 time 24.35s
Final training  881/4999 loss: 0.8882 time 24.35s
Final training  882/4999 loss: 0.8842 time 24.16s
Final training  883/4999 loss: 0.8859 time 24.30s
Final training  884/4999 loss: 0.8589 time 24.29s
Final training  885/4999 loss: 0.9167 time 24.31s
Final training  886/4999 loss: 0.8680 time 24.28s
Final training  887/4999 loss: 0.8894 time 24.37s
Final training  888/4999 loss: 0.9012 time 24.48s
Final training  889/4999 loss: 0.8982 time 24.16s
Final training  890/4999 loss: 0.9305 time 24.24s
Final training  891/4999 loss: 0.9022 time 24.06s
Final training  892/4999 loss: 0.9176 time 24.27s
Final training  893/4999 loss: 0.8795 time 23.93s
Final training  894/4999 loss: 0.8831 time 23.92s
Final training  895/4999 loss: 0.8944 time 24.30s
Final training  896/4999 loss: 0.8844 time 24.65s
Final training  897/4999 loss: 0.8730 time 24.87s
Final training  898/4999 loss: 0.8804 time 24.61s
Final training  899/4999 loss: 0.9092 time 24.80s
Dice accuracy for each class:  (tensor([0.9950, 0.9177, 0.7464, 0.8648, 0.7702, 0.4819, 0.9265, 0.7346, 0.8813,
        0.8191, 0.7140, 0.6140, 0.4963, 0.0010], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  899/4999 acc [ 0.710] time 121.53s
Reset trigger time to 0
new best (0.652859 --> 0.710399). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  900/4999 loss: 0.9008 time 23.61s
Final training  901/4999 loss: 0.9047 time 24.06s
Final training  902/4999 loss: 0.8762 time 24.01s
Final training  903/4999 loss: 0.8541 time 23.86s
Final training  904/4999 loss: 0.8837 time 24.14s
Final training  905/4999 loss: 0.8957 time 24.36s
Final training  906/4999 loss: 0.9038 time 24.06s
Final training  907/4999 loss: 0.8715 time 24.12s
Final training  908/4999 loss: 0.8704 time 24.09s
Final training  909/4999 loss: 0.8834 time 24.31s
Final training  910/4999 loss: 0.8873 time 24.04s
Final training  911/4999 loss: 0.8953 time 24.31s
Final training  912/4999 loss: 0.8802 time 23.86s
Final training  913/4999 loss: 0.8893 time 24.10s
Final training  914/4999 loss: 0.8830 time 23.90s
Final training  915/4999 loss: 0.8768 time 24.09s
Final training  916/4999 loss: 0.8730 time 23.92s
Final training  917/4999 loss: 0.8860 time 24.28s
Final training  918/4999 loss: 0.8952 time 24.02s
Final training  919/4999 loss: 0.8697 time 24.15s
Final training  920/4999 loss: 0.8649 time 23.85s
Final training  921/4999 loss: 0.8905 time 23.88s
Final training  922/4999 loss: 0.8875 time 24.31s
Final training  923/4999 loss: 0.8835 time 24.06s
Final training  924/4999 loss: 0.8682 time 24.14s
Final training  925/4999 loss: 0.8908 time 24.17s
Final training  926/4999 loss: 0.8865 time 24.19s
Final training  927/4999 loss: 0.8962 time 23.80s
Final training  928/4999 loss: 0.8686 time 23.93s
Final training  929/4999 loss: 0.8922 time 24.16s
Final training  930/4999 loss: 0.8771 time 24.20s
Final training  931/4999 loss: 0.8813 time 24.44s
Final training  932/4999 loss: 0.8929 time 24.26s
Final training  933/4999 loss: 0.8941 time 24.37s
Final training  934/4999 loss: 0.9187 time 24.88s
Final training  935/4999 loss: 0.8758 time 24.54s
Final training  936/4999 loss: 0.8989 time 24.58s
Final training  937/4999 loss: 0.9025 time 24.79s
Final training  938/4999 loss: 0.8918 time 24.75s
Final training  939/4999 loss: 0.9211 time 24.20s
Final training  940/4999 loss: 0.9187 time 24.52s
Final training  941/4999 loss: 0.9715 time 24.21s
Final training  942/4999 loss: 0.9780 time 24.41s
Final training  943/4999 loss: 0.9350 time 24.45s
Final training  944/4999 loss: 0.9233 time 24.33s
Final training  945/4999 loss: 0.8901 time 24.43s
Final training  946/4999 loss: 0.8975 time 24.55s
Final training  947/4999 loss: 0.8704 time 24.19s
Final training  948/4999 loss: 0.9182 time 24.24s
Final training  949/4999 loss: 0.9095 time 23.89s
Final training  950/4999 loss: 0.8857 time 24.03s
Final training  951/4999 loss: 0.8867 time 24.19s
Final training  952/4999 loss: 0.8787 time 23.89s
Final training  953/4999 loss: 0.9041 time 24.06s
Final training  954/4999 loss: 0.9528 time 24.07s
Final training  955/4999 loss: 0.8906 time 23.98s
Final training  956/4999 loss: 0.8894 time 24.00s
Final training  957/4999 loss: 0.8683 time 24.24s
Final training  958/4999 loss: 0.8791 time 24.11s
Final training  959/4999 loss: 0.8872 time 24.04s
Final training  960/4999 loss: 0.8756 time 24.23s
Final training  961/4999 loss: 0.8885 time 24.13s
Final training  962/4999 loss: 0.8997 time 24.20s
Final training  963/4999 loss: 0.8653 time 24.24s
Final training  964/4999 loss: 0.8655 time 24.11s
Final training  965/4999 loss: 0.8646 time 24.24s
Final training  966/4999 loss: 0.8769 time 24.08s
Final training  967/4999 loss: 0.8588 time 24.21s
Final training  968/4999 loss: 0.8769 time 24.22s
Final training  969/4999 loss: 0.8937 time 24.10s
Final training  970/4999 loss: 0.8897 time 24.23s
Final training  971/4999 loss: 0.8757 time 24.22s
Final training  972/4999 loss: 0.8756 time 24.38s
Final training  973/4999 loss: 0.9228 time 24.34s
Final training  974/4999 loss: 0.8918 time 24.14s
Final training  975/4999 loss: 0.8836 time 24.13s
Final training  976/4999 loss: 0.8900 time 24.03s
Final training  977/4999 loss: 0.8601 time 24.19s
Final training  978/4999 loss: 0.8683 time 24.36s
Final training  979/4999 loss: 0.8802 time 23.90s
Final training  980/4999 loss: 0.8697 time 24.19s
Final training  981/4999 loss: 0.8634 time 24.18s
Final training  982/4999 loss: 0.8417 time 24.51s
Final training  983/4999 loss: 0.8784 time 24.12s
Final training  984/4999 loss: 0.8586 time 24.23s
Final training  985/4999 loss: 0.8698 time 24.06s
Final training  986/4999 loss: 0.8645 time 24.14s
Final training  987/4999 loss: 0.8699 time 24.38s
Final training  988/4999 loss: 0.8665 time 24.04s
Final training  989/4999 loss: 0.8506 time 24.55s
Final training  990/4999 loss: 0.8629 time 24.55s
Final training  991/4999 loss: 0.8732 time 24.29s
Final training  992/4999 loss: 0.8798 time 24.19s
Final training  993/4999 loss: 0.8605 time 24.17s
Final training  994/4999 loss: 0.8836 time 24.19s
Final training  995/4999 loss: 0.8876 time 24.21s
Final training  996/4999 loss: 0.8691 time 24.24s
Final training  997/4999 loss: 0.9030 time 24.23s
Final training  998/4999 loss: 0.8681 time 24.17s
Final training  999/4999 loss: 0.8594 time 23.95s
Dice accuracy for each class:  (tensor([0.9940, 0.8772, 0.8631, 0.9083, 0.7658, 0.4929, 0.8678, 0.7800, 0.8922,
        0.7608, 0.7225, 0.6791, 0.3911, 0.3111], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  999/4999 acc [ 0.735] time 120.99s
Reset trigger time to 0
new best (0.710399 --> 0.734882). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1000/4999 loss: 0.8822 time 24.20s
Final training  1001/4999 loss: 0.8802 time 24.00s
Final training  1002/4999 loss: 0.8843 time 24.02s
Final training  1003/4999 loss: 0.8855 time 24.10s
Final training  1004/4999 loss: 0.8923 time 24.16s
Final training  1005/4999 loss: 0.8683 time 24.00s
Final training  1006/4999 loss: 0.8897 time 24.13s
Final training  1007/4999 loss: 0.8638 time 24.03s
Final training  1008/4999 loss: 0.8748 time 23.72s
Final training  1009/4999 loss: 0.8936 time 24.07s
Final training  1010/4999 loss: 0.9008 time 24.17s
Final training  1011/4999 loss: 0.8805 time 24.24s
Final training  1012/4999 loss: 0.8575 time 24.25s
Final training  1013/4999 loss: 0.8590 time 24.18s
Final training  1014/4999 loss: 0.8934 time 24.14s
Final training  1015/4999 loss: 0.8549 time 23.98s
Final training  1016/4999 loss: 0.8534 time 24.18s
Final training  1017/4999 loss: 0.8682 time 24.21s
Final training  1018/4999 loss: 0.8792 time 24.26s
Final training  1019/4999 loss: 0.8441 time 24.23s
Final training  1020/4999 loss: 0.8723 time 24.13s
Final training  1021/4999 loss: 0.8539 time 24.23s
Final training  1022/4999 loss: 0.8423 time 24.35s
Final training  1023/4999 loss: 0.8713 time 23.80s
Final training  1024/4999 loss: 0.8486 time 24.04s
Final training  1025/4999 loss: 0.8359 time 23.78s
Final training  1026/4999 loss: 0.8516 time 23.95s
Final training  1027/4999 loss: 0.8738 time 24.21s
Final training  1028/4999 loss: 0.8679 time 24.05s
Final training  1029/4999 loss: 0.8496 time 23.98s
Final training  1030/4999 loss: 0.8451 time 23.74s
Final training  1031/4999 loss: 0.8574 time 24.03s
Final training  1032/4999 loss: 0.8831 time 23.90s
Final training  1033/4999 loss: 0.9048 time 24.05s
Final training  1034/4999 loss: 0.9095 time 23.96s
Final training  1035/4999 loss: 0.8729 time 23.94s
Final training  1036/4999 loss: 0.8735 time 23.85s
Final training  1037/4999 loss: 0.8581 time 24.02s
Final training  1038/4999 loss: 0.9102 time 24.01s
Final training  1039/4999 loss: 0.8830 time 23.96s
Final training  1040/4999 loss: 0.8722 time 24.02s
Final training  1041/4999 loss: 0.8570 time 24.25s
Final training  1042/4999 loss: 0.8880 time 24.66s
Final training  1043/4999 loss: 0.8545 time 24.13s
Final training  1044/4999 loss: 0.8663 time 24.20s
Final training  1045/4999 loss: 0.8559 time 24.17s
Final training  1046/4999 loss: 0.8696 time 24.12s
Final training  1047/4999 loss: 0.9017 time 24.14s
Final training  1048/4999 loss: 0.8908 time 23.96s
Final training  1049/4999 loss: 0.8776 time 23.96s
Final training  1050/4999 loss: 0.8852 time 24.01s
Final training  1051/4999 loss: 0.8610 time 23.95s
Final training  1052/4999 loss: 0.8866 time 23.98s
Final training  1053/4999 loss: 0.8688 time 24.17s
Final training  1054/4999 loss: 0.8682 time 23.98s
Final training  1055/4999 loss: 0.9065 time 23.91s
Final training  1056/4999 loss: 0.8526 time 23.77s
Final training  1057/4999 loss: 0.8449 time 24.05s
Final training  1058/4999 loss: 0.8835 time 24.02s
Final training  1059/4999 loss: 0.9221 time 24.02s
Final training  1060/4999 loss: 0.8732 time 23.80s
Final training  1061/4999 loss: 0.8762 time 24.25s
Final training  1062/4999 loss: 0.8639 time 23.82s
Final training  1063/4999 loss: 0.8633 time 24.08s
Final training  1064/4999 loss: 0.8771 time 23.91s
Final training  1065/4999 loss: 0.8337 time 24.05s
Final training  1066/4999 loss: 0.8571 time 24.21s
Final training  1067/4999 loss: 0.8598 time 24.08s
Final training  1068/4999 loss: 0.8588 time 24.08s
Final training  1069/4999 loss: 0.8692 time 24.04s
Final training  1070/4999 loss: 0.8509 time 24.12s
Final training  1071/4999 loss: 0.8375 time 23.94s
Final training  1072/4999 loss: 0.8578 time 24.13s
Final training  1073/4999 loss: 0.8932 time 23.97s
Final training  1074/4999 loss: 0.8502 time 24.18s
Final training  1075/4999 loss: 0.8801 time 24.16s
Final training  1076/4999 loss: 0.8706 time 24.53s
Final training  1077/4999 loss: 0.8356 time 24.27s
Final training  1078/4999 loss: 0.8543 time 24.29s
Final training  1079/4999 loss: 0.8786 time 24.19s
Final training  1080/4999 loss: 0.8609 time 24.11s
Final training  1081/4999 loss: 0.8715 time 24.20s
Final training  1082/4999 loss: 0.8622 time 24.01s
Final training  1083/4999 loss: 0.8822 time 23.98s
Final training  1084/4999 loss: 0.8668 time 23.83s
Final training  1085/4999 loss: 0.8814 time 23.84s
Final training  1086/4999 loss: 0.8910 time 23.96s
Final training  1087/4999 loss: 0.8296 time 24.12s
Final training  1088/4999 loss: 0.8566 time 24.07s
Final training  1089/4999 loss: 0.8557 time 23.74s
Final training  1090/4999 loss: 0.8436 time 24.21s
Final training  1091/4999 loss: 0.8548 time 24.08s
Final training  1092/4999 loss: 0.8604 time 23.87s
Final training  1093/4999 loss: 0.8539 time 24.04s
Final training  1094/4999 loss: 0.8722 time 24.04s
Final training  1095/4999 loss: 0.8752 time 24.14s
Final training  1096/4999 loss: 0.8861 time 24.13s
Final training  1097/4999 loss: 0.8620 time 24.22s
Final training  1098/4999 loss: 0.8602 time 24.28s
Final training  1099/4999 loss: 0.8500 time 24.23s
Dice accuracy for each class:  (tensor([0.9915, 0.8861, 0.8032, 0.7647, 0.7002, 0.6676, 0.8084, 0.7236, 0.8792,
        0.7895, 0.7308, 0.7194, 0.6070, 0.4719], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1099/4999 acc [ 0.754] time 118.22s
Reset trigger time to 0
new best (0.734882 --> 0.753680). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1100/4999 loss: 0.8605 time 24.28s
Final training  1101/4999 loss: 0.8479 time 24.65s
Final training  1102/4999 loss: 0.8820 time 24.01s
Final training  1103/4999 loss: 0.8765 time 24.16s
Final training  1104/4999 loss: 0.8582 time 24.18s
Final training  1105/4999 loss: 0.8690 time 23.99s
Final training  1106/4999 loss: 0.8488 time 24.14s
Final training  1107/4999 loss: 0.8438 time 24.06s
Final training  1108/4999 loss: 0.8552 time 23.73s
Final training  1109/4999 loss: 0.8465 time 23.82s
Final training  1110/4999 loss: 0.8516 time 24.08s
Final training  1111/4999 loss: 0.8623 time 24.25s
Final training  1112/4999 loss: 0.8564 time 24.51s
Final training  1113/4999 loss: 0.8640 time 24.54s
Final training  1114/4999 loss: 0.8543 time 24.27s
Final training  1115/4999 loss: 0.8579 time 24.46s
Final training  1116/4999 loss: 0.8667 time 24.31s
Final training  1117/4999 loss: 0.8382 time 23.96s
Final training  1118/4999 loss: 0.8552 time 23.99s
Final training  1119/4999 loss: 0.8781 time 23.96s
Final training  1120/4999 loss: 0.8429 time 24.05s
Final training  1121/4999 loss: 0.8378 time 23.81s
Final training  1122/4999 loss: 0.8527 time 24.06s
Final training  1123/4999 loss: 0.8656 time 23.91s
Final training  1124/4999 loss: 0.8452 time 24.07s
Final training  1125/4999 loss: 0.8668 time 23.90s
Final training  1126/4999 loss: 0.8660 time 23.59s
Final training  1127/4999 loss: 0.8744 time 24.20s
Final training  1128/4999 loss: 0.8526 time 23.86s
Final training  1129/4999 loss: 0.8514 time 23.86s
Final training  1130/4999 loss: 0.8570 time 23.91s
Final training  1131/4999 loss: 0.8575 time 24.05s
Final training  1132/4999 loss: 0.8644 time 24.43s
Final training  1133/4999 loss: 0.8710 time 24.54s
Final training  1134/4999 loss: 0.8779 time 24.20s
Final training  1135/4999 loss: 0.9036 time 23.81s
Final training  1136/4999 loss: 0.8782 time 24.20s
Final training  1137/4999 loss: 0.8816 time 24.00s
Final training  1138/4999 loss: 0.8660 time 24.23s
Final training  1139/4999 loss: 0.8557 time 24.36s
Final training  1140/4999 loss: 0.8932 time 24.27s
Final training  1141/4999 loss: 0.8407 time 24.41s
Final training  1142/4999 loss: 0.8581 time 24.67s
Final training  1143/4999 loss: 0.8693 time 24.51s
Final training  1144/4999 loss: 0.8721 time 24.36s
Final training  1145/4999 loss: 0.8551 time 24.57s
Final training  1146/4999 loss: 0.8255 time 24.25s
Final training  1147/4999 loss: 0.8566 time 24.26s
Final training  1148/4999 loss: 0.8674 time 24.15s
Final training  1149/4999 loss: 0.9091 time 23.94s
Final training  1150/4999 loss: 0.8924 time 23.88s
Final training  1151/4999 loss: 0.8648 time 24.04s
Final training  1152/4999 loss: 0.8780 time 24.20s
Final training  1153/4999 loss: 0.9006 time 24.23s
Final training  1154/4999 loss: 0.8515 time 24.06s
Final training  1155/4999 loss: 0.8991 time 24.12s
Final training  1156/4999 loss: 0.8430 time 24.25s
Final training  1157/4999 loss: 0.8358 time 24.04s
Final training  1158/4999 loss: 0.8382 time 24.13s
Final training  1159/4999 loss: 0.8665 time 24.23s
Final training  1160/4999 loss: 0.8615 time 24.02s
Final training  1161/4999 loss: 0.8708 time 24.19s
Final training  1162/4999 loss: 0.8581 time 24.17s
Final training  1163/4999 loss: 0.8535 time 24.07s
Final training  1164/4999 loss: 0.8593 time 24.09s
Final training  1165/4999 loss: 0.8631 time 24.22s
Final training  1166/4999 loss: 0.8467 time 23.80s
Final training  1167/4999 loss: 0.8790 time 24.35s
Final training  1168/4999 loss: 0.8566 time 24.27s
Final training  1169/4999 loss: 0.8543 time 24.07s
Final training  1170/4999 loss: 0.8584 time 24.07s
Final training  1171/4999 loss: 0.8728 time 24.11s
Final training  1172/4999 loss: 0.8555 time 24.13s
Final training  1173/4999 loss: 0.8687 time 24.19s
Final training  1174/4999 loss: 0.8852 time 23.96s
Final training  1175/4999 loss: 0.8926 time 24.12s
Final training  1176/4999 loss: 0.8694 time 24.19s
Final training  1177/4999 loss: 0.8497 time 24.21s
Final training  1178/4999 loss: 0.8326 time 24.17s
Final training  1179/4999 loss: 0.8389 time 24.23s
Final training  1180/4999 loss: 0.8529 time 24.01s
Final training  1181/4999 loss: 0.8462 time 24.10s
Final training  1182/4999 loss: 0.8481 time 24.33s
Final training  1183/4999 loss: 0.8633 time 24.39s
Final training  1184/4999 loss: 0.8681 time 24.35s
Final training  1185/4999 loss: 0.8503 time 24.47s
Final training  1186/4999 loss: 0.8266 time 24.33s
Final training  1187/4999 loss: 0.8457 time 23.87s
Final training  1188/4999 loss: 0.8450 time 24.39s
Final training  1189/4999 loss: 0.8634 time 24.29s
Final training  1190/4999 loss: 0.8389 time 24.07s
Final training  1191/4999 loss: 0.8515 time 24.33s
Final training  1192/4999 loss: 0.8366 time 24.44s
Final training  1193/4999 loss: 0.8599 time 24.45s
Final training  1194/4999 loss: 0.8255 time 24.14s
Final training  1195/4999 loss: 0.8641 time 24.35s
Final training  1196/4999 loss: 0.8652 time 24.11s
Final training  1197/4999 loss: 0.8542 time 23.89s
Final training  1198/4999 loss: 0.8523 time 24.15s
Final training  1199/4999 loss: 0.8217 time 23.74s
Dice accuracy for each class:  (tensor([0.9945, 0.8810, 0.9064, 0.9208, 0.7547, 0.7056, 0.8921, 0.7069, 0.8844,
        0.7338, 0.7417, 0.7288, 0.6179, 0.5640], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1199/4999 acc [ 0.788] time 120.80s
Reset trigger time to 0
new best (0.753680 --> 0.788034). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1200/4999 loss: 0.8433 time 24.49s
Final training  1201/4999 loss: 0.8375 time 24.31s
Final training  1202/4999 loss: 0.8531 time 24.21s
Final training  1203/4999 loss: 0.8360 time 24.04s
Final training  1204/4999 loss: 0.8565 time 24.26s
Final training  1205/4999 loss: 0.8358 time 24.15s
Final training  1206/4999 loss: 0.8701 time 24.11s
Final training  1207/4999 loss: 0.8397 time 24.17s
Final training  1208/4999 loss: 0.8479 time 24.24s
Final training  1209/4999 loss: 0.8647 time 24.17s
Final training  1210/4999 loss: 0.8770 time 23.87s
Final training  1211/4999 loss: 0.8710 time 24.11s
Final training  1212/4999 loss: 0.8532 time 24.16s
Final training  1213/4999 loss: 0.8605 time 23.95s
Final training  1214/4999 loss: 0.8368 time 24.23s
Final training  1215/4999 loss: 0.8703 time 23.95s
Final training  1216/4999 loss: 0.8610 time 24.12s
Final training  1217/4999 loss: 0.8588 time 24.03s
Final training  1218/4999 loss: 0.8595 time 24.13s
Final training  1219/4999 loss: 0.8515 time 24.14s
Final training  1220/4999 loss: 0.8746 time 23.90s
Final training  1221/4999 loss: 0.8453 time 24.02s
Final training  1222/4999 loss: 0.8756 time 24.06s
Final training  1223/4999 loss: 0.8473 time 24.36s
Final training  1224/4999 loss: 0.8629 time 23.28s
Final training  1225/4999 loss: 0.8811 time 24.27s
Final training  1226/4999 loss: 0.8623 time 24.87s
Final training  1227/4999 loss: 0.8740 time 24.20s
Final training  1228/4999 loss: 0.8486 time 23.78s
Final training  1229/4999 loss: 0.8550 time 24.46s
Final training  1230/4999 loss: 0.8655 time 24.17s
Final training  1231/4999 loss: 0.8444 time 24.02s
Final training  1232/4999 loss: 0.8395 time 23.71s
Final training  1233/4999 loss: 0.8385 time 23.93s
Final training  1234/4999 loss: 0.8870 time 23.82s
Final training  1235/4999 loss: 0.8866 time 24.04s
Final training  1236/4999 loss: 0.8793 time 24.25s
Final training  1237/4999 loss: 0.8672 time 24.16s
Final training  1238/4999 loss: 0.9001 time 24.15s
Final training  1239/4999 loss: 0.8930 time 24.34s
Final training  1240/4999 loss: 0.8800 time 24.18s
Final training  1241/4999 loss: 0.8910 time 23.92s
Final training  1242/4999 loss: 0.8829 time 24.20s
Final training  1243/4999 loss: 0.8826 time 24.08s
Final training  1244/4999 loss: 0.8429 time 24.03s
Final training  1245/4999 loss: 0.8570 time 24.23s
Final training  1246/4999 loss: 0.8584 time 23.78s
Final training  1247/4999 loss: 0.8983 time 24.27s
Final training  1248/4999 loss: 0.8623 time 24.25s
Final training  1249/4999 loss: 0.8758 time 24.06s
Final training  1250/4999 loss: 0.8508 time 24.02s
Final training  1251/4999 loss: 0.8738 time 24.01s
Final training  1252/4999 loss: 0.8713 time 23.92s
Final training  1253/4999 loss: 0.8512 time 24.19s
Final training  1254/4999 loss: 0.8581 time 23.86s
Final training  1255/4999 loss: 0.8286 time 24.19s
Final training  1256/4999 loss: 0.8794 time 24.00s
Final training  1257/4999 loss: 0.8409 time 24.04s
Final training  1258/4999 loss: 0.8577 time 23.82s
Final training  1259/4999 loss: 0.8751 time 24.07s
Final training  1260/4999 loss: 0.8602 time 24.03s
Final training  1261/4999 loss: 0.8753 time 24.05s
Final training  1262/4999 loss: 0.8748 time 24.38s
Final training  1263/4999 loss: 0.8658 time 24.11s
Final training  1264/4999 loss: 0.8572 time 23.83s
Final training  1265/4999 loss: 0.8409 time 23.99s
Final training  1266/4999 loss: 0.8959 time 24.11s
Final training  1267/4999 loss: 0.8735 time 24.05s
Final training  1268/4999 loss: 0.8675 time 23.90s
Final training  1269/4999 loss: 0.8374 time 23.88s
Final training  1270/4999 loss: 0.8586 time 24.04s
Final training  1271/4999 loss: 0.8943 time 23.41s
Final training  1272/4999 loss: 0.8507 time 24.11s
Final training  1273/4999 loss: 0.8691 time 24.16s
Final training  1274/4999 loss: 0.8567 time 24.41s
Final training  1275/4999 loss: 0.8613 time 24.41s
Final training  1276/4999 loss: 0.8670 time 24.80s
Final training  1277/4999 loss: 0.8394 time 24.80s
Final training  1278/4999 loss: 0.8647 time 24.78s
Final training  1279/4999 loss: 0.8365 time 24.53s
Final training  1280/4999 loss: 0.8581 time 24.55s
Final training  1281/4999 loss: 0.8522 time 24.36s
Final training  1282/4999 loss: 0.8953 time 24.61s
Final training  1283/4999 loss: 0.8738 time 24.29s
Final training  1284/4999 loss: 0.9154 time 24.54s
Final training  1285/4999 loss: 0.8940 time 24.54s
Final training  1286/4999 loss: 0.8959 time 24.19s
Final training  1287/4999 loss: 0.8366 time 24.52s
Final training  1288/4999 loss: 0.8449 time 24.59s
Final training  1289/4999 loss: 0.8447 time 24.27s
Final training  1290/4999 loss: 0.8292 time 24.56s
Final training  1291/4999 loss: 0.8768 time 24.75s
Final training  1292/4999 loss: 0.8415 time 24.30s
Final training  1293/4999 loss: 0.8399 time 24.33s
Final training  1294/4999 loss: 0.8118 time 24.43s
Final training  1295/4999 loss: 0.8273 time 24.44s
Final training  1296/4999 loss: 0.8223 time 24.19s
Final training  1297/4999 loss: 0.8414 time 24.12s
Final training  1298/4999 loss: 0.8300 time 24.18s
Final training  1299/4999 loss: 0.8232 time 24.22s
Dice accuracy for each class:  (tensor([0.9935, 0.8278, 0.9304, 0.9322, 0.7603, 0.7076, 0.8554, 0.7944, 0.9041,
        0.7529, 0.7326, 0.7504, 0.6082, 0.5760], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1299/4999 acc [ 0.795] time 118.78s
Reset trigger time to 0
new best (0.788034 --> 0.794693). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1300/4999 loss: 0.8376 time 24.00s
Final training  1301/4999 loss: 0.8417 time 24.34s
Final training  1302/4999 loss: 0.8155 time 24.20s
Final training  1303/4999 loss: 0.8531 time 24.23s
Final training  1304/4999 loss: 0.8234 time 23.89s
Final training  1305/4999 loss: 0.8366 time 24.21s
Final training  1306/4999 loss: 0.8564 time 24.32s
Final training  1307/4999 loss: 0.8471 time 24.48s
Final training  1308/4999 loss: 0.8505 time 24.29s
Final training  1309/4999 loss: 0.8491 time 24.44s
Final training  1310/4999 loss: 0.8675 time 24.31s
Final training  1311/4999 loss: 0.8209 time 24.72s
Final training  1312/4999 loss: 0.8248 time 24.98s
Final training  1313/4999 loss: 0.8388 time 24.67s
Final training  1314/4999 loss: 0.8322 time 24.35s
Final training  1315/4999 loss: 0.8601 time 24.26s
Final training  1316/4999 loss: 0.8283 time 24.37s
Final training  1317/4999 loss: 0.8409 time 24.26s
Final training  1318/4999 loss: 0.8490 time 24.14s
Final training  1319/4999 loss: 0.8619 time 24.43s
Final training  1320/4999 loss: 0.8528 time 24.45s
Final training  1321/4999 loss: 0.8391 time 24.42s
Final training  1322/4999 loss: 0.8225 time 24.52s
Final training  1323/4999 loss: 0.8910 time 24.36s
Final training  1324/4999 loss: 0.8547 time 24.30s
Final training  1325/4999 loss: 0.8139 time 24.14s
Final training  1326/4999 loss: 0.8392 time 24.17s
Final training  1327/4999 loss: 0.8419 time 24.27s
Final training  1328/4999 loss: 0.8534 time 24.17s
Final training  1329/4999 loss: 0.8669 time 23.99s
Final training  1330/4999 loss: 0.8664 time 24.21s
Final training  1331/4999 loss: 0.8745 time 24.52s
Final training  1332/4999 loss: 0.8867 time 24.23s
Final training  1333/4999 loss: 0.8504 time 24.17s
Final training  1334/4999 loss: 0.8487 time 24.18s
Final training  1335/4999 loss: 0.8448 time 24.10s
Final training  1336/4999 loss: 0.8553 time 24.28s
Final training  1337/4999 loss: 0.8283 time 24.18s
Final training  1338/4999 loss: 0.8586 time 23.95s
Final training  1339/4999 loss: 0.8748 time 23.93s
Final training  1340/4999 loss: 0.8682 time 24.16s
Final training  1341/4999 loss: 0.8767 time 23.92s
Final training  1342/4999 loss: 0.9375 time 24.09s
Final training  1343/4999 loss: 0.8930 time 23.92s
Final training  1344/4999 loss: 0.8735 time 23.83s
Final training  1345/4999 loss: 0.8465 time 24.00s
Final training  1346/4999 loss: 0.8540 time 24.17s
Final training  1347/4999 loss: 0.8471 time 23.86s
Final training  1348/4999 loss: 0.8169 time 23.97s
Final training  1349/4999 loss: 0.8559 time 24.00s
Final training  1350/4999 loss: 0.8307 time 24.35s
Final training  1351/4999 loss: 0.8452 time 23.83s
Final training  1352/4999 loss: 0.8285 time 24.17s
Final training  1353/4999 loss: 0.8658 time 24.10s
Final training  1354/4999 loss: 0.8520 time 24.11s
Final training  1355/4999 loss: 0.8331 time 24.27s
Final training  1356/4999 loss: 0.8290 time 24.22s
Final training  1357/4999 loss: 0.8693 time 24.13s
Final training  1358/4999 loss: 0.8317 time 24.05s
Final training  1359/4999 loss: 0.8195 time 24.09s
Final training  1360/4999 loss: 0.8459 time 24.10s
Final training  1361/4999 loss: 0.8397 time 24.22s
Final training  1362/4999 loss: 0.8749 time 24.32s
Final training  1363/4999 loss: 0.8289 time 24.13s
Final training  1364/4999 loss: 0.8483 time 24.20s
Final training  1365/4999 loss: 0.8606 time 24.17s
Final training  1366/4999 loss: 0.8322 time 24.11s
Final training  1367/4999 loss: 0.8269 time 24.16s
Final training  1368/4999 loss: 0.8541 time 24.26s
Final training  1369/4999 loss: 0.9257 time 24.19s
Final training  1370/4999 loss: 0.8733 time 24.19s
Final training  1371/4999 loss: 0.8834 time 24.54s
Final training  1372/4999 loss: 0.8615 time 24.28s
Final training  1373/4999 loss: 0.8531 time 24.41s
Final training  1374/4999 loss: 0.8721 time 24.55s
Final training  1375/4999 loss: 0.8507 time 23.99s
Final training  1376/4999 loss: 0.8419 time 24.16s
Final training  1377/4999 loss: 0.8527 time 24.39s
Final training  1378/4999 loss: 0.8519 time 24.26s
Final training  1379/4999 loss: 0.8359 time 24.40s
Final training  1380/4999 loss: 0.8350 time 24.38s
Final training  1381/4999 loss: 0.8530 time 24.91s
Final training  1382/4999 loss: 0.8259 time 24.80s
Final training  1383/4999 loss: 0.8278 time 24.99s
Final training  1384/4999 loss: 0.8251 time 24.62s
Final training  1385/4999 loss: 0.8671 time 24.33s
Final training  1386/4999 loss: 0.8480 time 24.01s
Final training  1387/4999 loss: 0.8322 time 24.35s
Final training  1388/4999 loss: 0.8313 time 24.23s
Final training  1389/4999 loss: 0.8353 time 24.20s
Final training  1390/4999 loss: 0.8708 time 24.29s
Final training  1391/4999 loss: 0.8397 time 24.22s
Final training  1392/4999 loss: 0.8315 time 23.68s
Final training  1393/4999 loss: 0.8332 time 24.19s
Final training  1394/4999 loss: 0.8626 time 23.97s
Final training  1395/4999 loss: 0.8332 time 24.16s
Final training  1396/4999 loss: 0.8331 time 24.21s
Final training  1397/4999 loss: 0.8395 time 24.29s
Final training  1398/4999 loss: 0.8219 time 24.15s
Final training  1399/4999 loss: 0.8620 time 24.06s
Dice accuracy for each class:  (tensor([0.9946, 0.8467, 0.9345, 0.9364, 0.6929, 0.6894, 0.8862, 0.7610, 0.8878,
        0.8194, 0.7130, 0.7426, 0.6264, 0.5912], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1399/4999 acc [ 0.795] time 121.20s
Reset trigger time to 0
new best (0.794693 --> 0.795498). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1400/4999 loss: 0.8027 time 24.25s
Final training  1401/4999 loss: 0.8362 time 24.14s
Final training  1402/4999 loss: 0.8442 time 24.15s
Final training  1403/4999 loss: 0.8434 time 24.16s
Final training  1404/4999 loss: 0.8452 time 23.98s
Final training  1405/4999 loss: 0.8236 time 24.13s
Final training  1406/4999 loss: 0.8366 time 24.24s
Final training  1407/4999 loss: 0.8862 time 24.17s
Final training  1408/4999 loss: 0.8393 time 24.15s
Final training  1409/4999 loss: 0.8291 time 24.36s
Final training  1410/4999 loss: 0.8283 time 24.19s
Final training  1411/4999 loss: 0.8467 time 24.65s
Final training  1412/4999 loss: 0.8477 time 24.94s
Final training  1413/4999 loss: 0.8467 time 24.52s
Final training  1414/4999 loss: 0.8547 time 24.18s
Final training  1415/4999 loss: 0.8589 time 24.11s
Final training  1416/4999 loss: 0.8412 time 24.14s
Final training  1417/4999 loss: 0.8244 time 24.06s
Final training  1418/4999 loss: 0.8342 time 23.95s
Final training  1419/4999 loss: 0.8405 time 24.11s
Final training  1420/4999 loss: 0.8425 time 24.41s
Final training  1421/4999 loss: 0.8385 time 24.01s
Final training  1422/4999 loss: 0.9055 time 23.99s
Final training  1423/4999 loss: 0.8616 time 24.19s
Final training  1424/4999 loss: 0.8396 time 24.39s
Final training  1425/4999 loss: 0.8277 time 24.41s
Final training  1426/4999 loss: 0.8470 time 24.07s
Final training  1427/4999 loss: 0.8714 time 24.14s
Final training  1428/4999 loss: 0.8596 time 24.13s
Final training  1429/4999 loss: 0.8795 time 24.17s
Final training  1430/4999 loss: 0.8390 time 24.14s
Final training  1431/4999 loss: 0.8799 time 24.10s
Final training  1432/4999 loss: 0.8248 time 24.29s
Final training  1433/4999 loss: 0.8201 time 23.85s
Final training  1434/4999 loss: 0.8331 time 24.24s
Final training  1435/4999 loss: 0.8806 time 24.11s
Final training  1436/4999 loss: 0.8731 time 24.13s
Final training  1437/4999 loss: 0.8537 time 24.18s
Final training  1438/4999 loss: 0.8604 time 24.14s
Final training  1439/4999 loss: 0.8493 time 23.90s
Final training  1440/4999 loss: 0.8451 time 24.07s
Final training  1441/4999 loss: 0.8421 time 24.24s
Final training  1442/4999 loss: 0.8395 time 24.11s
Final training  1443/4999 loss: 0.8540 time 23.93s
Final training  1444/4999 loss: 0.8524 time 23.95s
Final training  1445/4999 loss: 0.8546 time 24.05s
Final training  1446/4999 loss: 0.8307 time 24.22s
Final training  1447/4999 loss: 0.8387 time 24.27s
Final training  1448/4999 loss: 0.8319 time 24.25s
Final training  1449/4999 loss: 0.8735 time 24.39s
Final training  1450/4999 loss: 0.8520 time 24.22s
Final training  1451/4999 loss: 0.8671 time 24.05s
Final training  1452/4999 loss: 0.8287 time 24.01s
Final training  1453/4999 loss: 0.8354 time 24.03s
Final training  1454/4999 loss: 0.8765 time 24.30s
Final training  1455/4999 loss: 0.8383 time 24.11s
Final training  1456/4999 loss: 0.8395 time 23.91s
Final training  1457/4999 loss: 0.8656 time 24.06s
Final training  1458/4999 loss: 0.8444 time 24.23s
Final training  1459/4999 loss: 0.8371 time 24.12s
Final training  1460/4999 loss: 0.8454 time 24.16s
Final training  1461/4999 loss: 0.8297 time 24.17s
Final training  1462/4999 loss: 0.8215 time 24.66s
Final training  1463/4999 loss: 0.8306 time 24.81s
Final training  1464/4999 loss: 0.8236 time 24.27s
Final training  1465/4999 loss: 0.8422 time 24.14s
Final training  1466/4999 loss: 0.8235 time 24.05s
Final training  1467/4999 loss: 0.8196 time 23.55s
Final training  1468/4999 loss: 0.8453 time 24.12s
Final training  1469/4999 loss: 0.8469 time 24.12s
Final training  1470/4999 loss: 0.8270 time 24.14s
Final training  1471/4999 loss: 0.8400 time 24.24s
Final training  1472/4999 loss: 0.8199 time 24.00s
Final training  1473/4999 loss: 0.8395 time 24.08s
Final training  1474/4999 loss: 0.8495 time 24.43s
Final training  1475/4999 loss: 0.8530 time 24.59s
Final training  1476/4999 loss: 0.8403 time 24.24s
Final training  1477/4999 loss: 0.8457 time 24.01s
Final training  1478/4999 loss: 0.8462 time 24.13s
Final training  1479/4999 loss: 0.8396 time 24.08s
Final training  1480/4999 loss: 0.8585 time 24.27s
Final training  1481/4999 loss: 0.8402 time 24.10s
Final training  1482/4999 loss: 0.8525 time 24.29s
Final training  1483/4999 loss: 0.8385 time 24.45s
Final training  1484/4999 loss: 0.8234 time 24.24s
Final training  1485/4999 loss: 0.8366 time 24.51s
Final training  1486/4999 loss: 0.8027 time 24.78s
Final training  1487/4999 loss: 0.8120 time 24.71s
Final training  1488/4999 loss: 0.8142 time 24.58s
Final training  1489/4999 loss: 0.8224 time 24.57s
Final training  1490/4999 loss: 0.8530 time 24.45s
Final training  1491/4999 loss: 0.8764 time 24.15s
Final training  1492/4999 loss: 0.8641 time 23.80s
Final training  1493/4999 loss: 0.8326 time 24.28s
Final training  1494/4999 loss: 0.8220 time 24.14s
Final training  1495/4999 loss: 0.8286 time 23.95s
Final training  1496/4999 loss: 0.8325 time 24.10s
Final training  1497/4999 loss: 0.8125 time 24.19s
Final training  1498/4999 loss: 0.8732 time 24.14s
Final training  1499/4999 loss: 0.8331 time 24.28s
Dice accuracy for each class:  (tensor([0.9933, 0.9323, 0.8727, 0.8508, 0.7821, 0.7201, 0.8338, 0.7293, 0.8994,
        0.8189, 0.7474, 0.7573, 0.6300, 0.5470], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1499/4999 acc [ 0.794] time 118.74s
trigger times: 1
Final training  1500/4999 loss: 0.8521 time 24.18s
Final training  1501/4999 loss: 0.8544 time 24.33s
Final training  1502/4999 loss: 0.8425 time 24.28s
Final training  1503/4999 loss: 0.8282 time 24.57s
Final training  1504/4999 loss: 0.8343 time 24.67s
Final training  1505/4999 loss: 0.8356 time 24.64s
Final training  1506/4999 loss: 0.8456 time 24.61s
Final training  1507/4999 loss: 0.8114 time 24.50s
Final training  1508/4999 loss: 0.8450 time 24.53s
Final training  1509/4999 loss: 0.8377 time 24.50s
Final training  1510/4999 loss: 0.8453 time 24.42s
Final training  1511/4999 loss: 0.8504 time 24.67s
Final training  1512/4999 loss: 0.8597 time 24.72s
Final training  1513/4999 loss: 0.8349 time 24.78s
Final training  1514/4999 loss: 0.8306 time 24.73s
Final training  1515/4999 loss: 0.8225 time 24.65s
Final training  1516/4999 loss: 0.8254 time 24.71s
Final training  1517/4999 loss: 0.8380 time 24.22s
Final training  1518/4999 loss: 0.8226 time 24.43s
Final training  1519/4999 loss: 0.8397 time 24.30s
Final training  1520/4999 loss: 0.8247 time 24.46s
Final training  1521/4999 loss: 0.8526 time 24.13s
Final training  1522/4999 loss: 0.8084 time 24.15s
Final training  1523/4999 loss: 0.8037 time 23.98s
Final training  1524/4999 loss: 0.8231 time 24.22s
Final training  1525/4999 loss: 0.8002 time 24.15s
Final training  1526/4999 loss: 0.8432 time 24.16s
Final training  1527/4999 loss: 0.9229 time 24.11s
Final training  1528/4999 loss: 0.8824 time 24.18s
Final training  1529/4999 loss: 0.8789 time 24.14s
Final training  1530/4999 loss: 0.8629 time 24.11s
Final training  1531/4999 loss: 0.8674 time 24.30s
Final training  1532/4999 loss: 0.8400 time 24.08s
Final training  1533/4999 loss: 0.8192 time 24.17s
Final training  1534/4999 loss: 0.8352 time 24.27s
Final training  1535/4999 loss: 0.8442 time 24.54s
Final training  1536/4999 loss: 0.8311 time 24.00s
Final training  1537/4999 loss: 0.8454 time 24.01s
Final training  1538/4999 loss: 0.8355 time 23.73s
Final training  1539/4999 loss: 0.8276 time 24.00s
Final training  1540/4999 loss: 0.8525 time 24.25s
Final training  1541/4999 loss: 0.8257 time 24.29s
Final training  1542/4999 loss: 0.8070 time 24.15s
Final training  1543/4999 loss: 0.8324 time 24.08s
Final training  1544/4999 loss: 0.8178 time 24.35s
Final training  1545/4999 loss: 0.8181 time 24.16s
Final training  1546/4999 loss: 0.8390 time 24.21s
Final training  1547/4999 loss: 0.8635 time 24.06s
Final training  1548/4999 loss: 0.8457 time 23.76s
Final training  1549/4999 loss: 0.8648 time 23.87s
Final training  1550/4999 loss: 0.8397 time 23.87s
Final training  1551/4999 loss: 0.8303 time 24.31s
Final training  1552/4999 loss: 0.8338 time 24.13s
Final training  1553/4999 loss: 0.8118 time 24.10s
Final training  1554/4999 loss: 0.8306 time 24.10s
Final training  1555/4999 loss: 0.8019 time 24.33s
Final training  1556/4999 loss: 0.8308 time 24.33s
Final training  1557/4999 loss: 0.8015 time 24.11s
Final training  1558/4999 loss: 0.8098 time 23.87s
Final training  1559/4999 loss: 0.8495 time 24.27s
Final training  1560/4999 loss: 0.8397 time 24.02s
Final training  1561/4999 loss: 0.8473 time 24.21s
Final training  1562/4999 loss: 0.8471 time 23.78s
Final training  1563/4999 loss: 0.8486 time 24.43s
Final training  1564/4999 loss: 0.8872 time 24.56s
Final training  1565/4999 loss: 0.8053 time 24.54s
Final training  1566/4999 loss: 0.8333 time 24.39s
Final training  1567/4999 loss: 0.8412 time 24.24s
Final training  1568/4999 loss: 0.8454 time 24.24s
Final training  1569/4999 loss: 0.8324 time 24.11s
Final training  1570/4999 loss: 0.8400 time 24.17s
Final training  1571/4999 loss: 0.8242 time 24.11s
Final training  1572/4999 loss: 0.8393 time 23.86s
Final training  1573/4999 loss: 0.8470 time 24.10s
Final training  1574/4999 loss: 0.8192 time 23.99s
Final training  1575/4999 loss: 0.8327 time 24.20s
Final training  1576/4999 loss: 0.8265 time 24.20s
Final training  1577/4999 loss: 0.8690 time 24.07s
Final training  1578/4999 loss: 0.8574 time 24.24s
Final training  1579/4999 loss: 0.8576 time 24.07s
Final training  1580/4999 loss: 0.8369 time 24.48s
Final training  1581/4999 loss: 0.8205 time 24.24s
Final training  1582/4999 loss: 0.8432 time 24.09s
Final training  1583/4999 loss: 0.8115 time 24.11s
Final training  1584/4999 loss: 0.8333 time 24.07s
Final training  1585/4999 loss: 0.8119 time 24.29s
Final training  1586/4999 loss: 0.8382 time 24.22s
Final training  1587/4999 loss: 0.8281 time 24.20s
Final training  1588/4999 loss: 0.8127 time 23.90s
Final training  1589/4999 loss: 0.8370 time 23.82s
Final training  1590/4999 loss: 0.8246 time 24.27s
Final training  1591/4999 loss: 0.7924 time 24.10s
Final training  1592/4999 loss: 0.8317 time 24.20s
Final training  1593/4999 loss: 0.8254 time 24.28s
Final training  1594/4999 loss: 0.8566 time 23.96s
Final training  1595/4999 loss: 0.8561 time 24.08s
Final training  1596/4999 loss: 0.8498 time 24.44s
Final training  1597/4999 loss: 0.8425 time 23.81s
Final training  1598/4999 loss: 0.8615 time 24.36s
Final training  1599/4999 loss: 0.8360 time 24.25s
Dice accuracy for each class:  (tensor([0.9934, 0.9464, 0.9398, 0.9407, 0.7905, 0.6928, 0.8353, 0.8054, 0.8999,
        0.8454, 0.7440, 0.7335, 0.6209, 0.5413], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1599/4999 acc [ 0.809] time 121.43s
Reset trigger time to 0
new best (0.795498 --> 0.809157). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1600/4999 loss: 0.8444 time 24.38s
Final training  1601/4999 loss: 0.8121 time 24.62s
Final training  1602/4999 loss: 0.8474 time 24.29s
Final training  1603/4999 loss: 0.8479 time 24.08s
Final training  1604/4999 loss: 0.8203 time 24.07s
Final training  1605/4999 loss: 0.8424 time 24.00s
Final training  1606/4999 loss: 0.7887 time 24.12s
Final training  1607/4999 loss: 0.8329 time 24.19s
Final training  1608/4999 loss: 0.8355 time 24.11s
Final training  1609/4999 loss: 0.8499 time 24.29s
Final training  1610/4999 loss: 0.8192 time 24.14s
Final training  1611/4999 loss: 0.8211 time 24.34s
Final training  1612/4999 loss: 0.8095 time 24.21s
Final training  1613/4999 loss: 0.8160 time 24.06s
Final training  1614/4999 loss: 0.8340 time 24.14s
Final training  1615/4999 loss: 0.8111 time 24.11s
Final training  1616/4999 loss: 0.8213 time 23.85s
Final training  1617/4999 loss: 0.8279 time 24.17s
Final training  1618/4999 loss: 0.8145 time 24.25s
Final training  1619/4999 loss: 0.8380 time 24.10s
Final training  1620/4999 loss: 0.8155 time 23.86s
Final training  1621/4999 loss: 0.8353 time 24.02s
Final training  1622/4999 loss: 0.8203 time 24.06s
Final training  1623/4999 loss: 0.8058 time 24.27s
Final training  1624/4999 loss: 0.8217 time 24.13s
Final training  1625/4999 loss: 0.8273 time 24.22s
Final training  1626/4999 loss: 0.8366 time 24.32s
Final training  1627/4999 loss: 0.8184 time 24.30s
Final training  1628/4999 loss: 0.8056 time 24.47s
Final training  1629/4999 loss: 0.8183 time 24.15s
Final training  1630/4999 loss: 0.8173 time 24.23s
Final training  1631/4999 loss: 0.8340 time 24.17s
Final training  1632/4999 loss: 0.8271 time 24.25s
Final training  1633/4999 loss: 0.8463 time 24.30s
Final training  1634/4999 loss: 0.8227 time 24.05s
Final training  1635/4999 loss: 0.8351 time 24.20s
Final training  1636/4999 loss: 0.8254 time 24.19s
Final training  1637/4999 loss: 0.8199 time 24.09s
Final training  1638/4999 loss: 0.8504 time 24.38s
Final training  1639/4999 loss: 0.8459 time 24.16s
Final training  1640/4999 loss: 0.8085 time 24.03s
Final training  1641/4999 loss: 0.8189 time 24.03s
Final training  1642/4999 loss: 0.8255 time 24.03s
Final training  1643/4999 loss: 0.8488 time 24.24s
Final training  1644/4999 loss: 0.8293 time 24.54s
Final training  1645/4999 loss: 0.8147 time 24.12s
Final training  1646/4999 loss: 0.8775 time 24.25s
Final training  1647/4999 loss: 0.9090 time 24.03s
Final training  1648/4999 loss: 0.8815 time 24.25s
Final training  1649/4999 loss: 0.8546 time 24.13s
Final training  1650/4999 loss: 0.8484 time 24.16s
Final training  1651/4999 loss: 0.8253 time 24.22s
Final training  1652/4999 loss: 0.8315 time 23.80s
Final training  1653/4999 loss: 0.8272 time 23.76s
Final training  1654/4999 loss: 0.8424 time 23.85s
Final training  1655/4999 loss: 0.8258 time 24.19s
Final training  1656/4999 loss: 0.8446 time 24.28s
Final training  1657/4999 loss: 0.8570 time 24.23s
Final training  1658/4999 loss: 0.8314 time 23.47s
Final training  1659/4999 loss: 0.8142 time 24.00s
Final training  1660/4999 loss: 0.8235 time 24.33s
Final training  1661/4999 loss: 0.8141 time 24.16s
Final training  1662/4999 loss: 0.8401 time 24.20s
Final training  1663/4999 loss: 0.8292 time 24.00s
Final training  1664/4999 loss: 0.8026 time 24.22s
Final training  1665/4999 loss: 0.8258 time 24.09s
Final training  1666/4999 loss: 0.8351 time 24.21s
Final training  1667/4999 loss: 0.7917 time 23.92s
Final training  1668/4999 loss: 0.8140 time 24.21s
Final training  1669/4999 loss: 0.8366 time 23.86s
Final training  1670/4999 loss: 0.8412 time 24.26s
Final training  1671/4999 loss: 0.8446 time 24.20s
Final training  1672/4999 loss: 0.8347 time 23.95s
Final training  1673/4999 loss: 0.8254 time 23.98s
Final training  1674/4999 loss: 0.8503 time 24.02s
Final training  1675/4999 loss: 0.8321 time 23.71s
Final training  1676/4999 loss: 0.8056 time 24.23s
Final training  1677/4999 loss: 0.8263 time 24.59s
Final training  1678/4999 loss: 0.8092 time 24.07s
Final training  1679/4999 loss: 0.8389 time 24.38s
Final training  1680/4999 loss: 0.8128 time 24.33s
Final training  1681/4999 loss: 0.8194 time 24.01s
Final training  1682/4999 loss: 0.7982 time 24.05s
Final training  1683/4999 loss: 0.8113 time 24.00s
Final training  1684/4999 loss: 0.8240 time 24.13s
Final training  1685/4999 loss: 0.8075 time 24.31s
Final training  1686/4999 loss: 0.8291 time 24.55s
Final training  1687/4999 loss: 0.8288 time 23.99s
Final training  1688/4999 loss: 0.8236 time 24.90s
Final training  1689/4999 loss: 0.8364 time 24.51s
Final training  1690/4999 loss: 0.8171 time 24.72s
Final training  1691/4999 loss: 0.8267 time 24.72s
Final training  1692/4999 loss: 0.7935 time 24.68s
Final training  1693/4999 loss: 0.8261 time 24.81s
Final training  1694/4999 loss: 0.8178 time 24.37s
Final training  1695/4999 loss: 0.8384 time 24.67s
Final training  1696/4999 loss: 0.8354 time 24.44s
Final training  1697/4999 loss: 0.8096 time 24.65s
Final training  1698/4999 loss: 0.8405 time 24.55s
Final training  1699/4999 loss: 0.8399 time 24.55s
Dice accuracy for each class:  (tensor([0.9925, 0.9096, 0.9385, 0.9418, 0.7556, 0.7068, 0.8208, 0.7727, 0.9097,
        0.8512, 0.7251, 0.7330, 0.6548, 0.5953], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1699/4999 acc [ 0.808] time 122.16s
trigger times: 1
Final training  1700/4999 loss: 0.8188 time 24.64s
Final training  1701/4999 loss: 0.8088 time 24.80s
Final training  1702/4999 loss: 0.8533 time 24.49s
Final training  1703/4999 loss: 0.8137 time 24.49s
Final training  1704/4999 loss: 0.8267 time 24.33s
Final training  1705/4999 loss: 0.8243 time 24.51s
Final training  1706/4999 loss: 0.8307 time 24.55s
Final training  1707/4999 loss: 0.8422 time 24.57s
Final training  1708/4999 loss: 0.8436 time 24.52s
Final training  1709/4999 loss: 0.8451 time 24.11s
Final training  1710/4999 loss: 0.8410 time 24.01s
Final training  1711/4999 loss: 0.8260 time 23.95s
Final training  1712/4999 loss: 0.8275 time 23.97s
Final training  1713/4999 loss: 0.8202 time 24.11s
Final training  1714/4999 loss: 0.8122 time 24.13s
Final training  1715/4999 loss: 0.8246 time 24.22s
Final training  1716/4999 loss: 0.8460 time 24.10s
Final training  1717/4999 loss: 0.8298 time 24.20s
Final training  1718/4999 loss: 0.8663 time 24.58s
Final training  1719/4999 loss: 0.8569 time 24.09s
Final training  1720/4999 loss: 0.8421 time 24.18s
Final training  1721/4999 loss: 0.8408 time 23.99s
Final training  1722/4999 loss: 0.8230 time 24.26s
Final training  1723/4999 loss: 0.8146 time 24.21s
Final training  1724/4999 loss: 0.8148 time 24.22s
Final training  1725/4999 loss: 0.8337 time 24.23s
Final training  1726/4999 loss: 0.8381 time 24.42s
Final training  1727/4999 loss: 0.8337 time 24.33s
Final training  1728/4999 loss: 0.8151 time 24.36s
Final training  1729/4999 loss: 0.8311 time 24.02s
Final training  1730/4999 loss: 0.8298 time 23.78s
Final training  1731/4999 loss: 0.7932 time 24.16s
Final training  1732/4999 loss: 0.8150 time 24.12s
Final training  1733/4999 loss: 0.8276 time 24.17s
Final training  1734/4999 loss: 0.8342 time 24.26s
Final training  1735/4999 loss: 0.8321 time 24.11s
Final training  1736/4999 loss: 0.8343 time 24.16s
Final training  1737/4999 loss: 0.8419 time 24.23s
Final training  1738/4999 loss: 0.8298 time 24.19s
Final training  1739/4999 loss: 0.8239 time 23.53s
Final training  1740/4999 loss: 0.8496 time 24.26s
Final training  1741/4999 loss: 0.8250 time 24.05s
Final training  1742/4999 loss: 0.8373 time 24.15s
Final training  1743/4999 loss: 0.8519 time 24.24s
Final training  1744/4999 loss: 0.8492 time 23.95s
Final training  1745/4999 loss: 0.8304 time 24.01s
Final training  1746/4999 loss: 0.8290 time 24.22s
Final training  1747/4999 loss: 0.8294 time 24.20s
Final training  1748/4999 loss: 0.8231 time 24.36s
Final training  1749/4999 loss: 0.8295 time 24.11s
Final training  1750/4999 loss: 0.8470 time 24.20s
Final training  1751/4999 loss: 0.8231 time 24.20s
Final training  1752/4999 loss: 0.8122 time 23.94s
Final training  1753/4999 loss: 0.8140 time 24.18s
Final training  1754/4999 loss: 0.8177 time 23.96s
Final training  1755/4999 loss: 0.8055 time 23.90s
Final training  1756/4999 loss: 0.8359 time 24.13s
Final training  1757/4999 loss: 0.8195 time 24.06s
Final training  1758/4999 loss: 0.8318 time 23.88s
Final training  1759/4999 loss: 0.8492 time 23.85s
Final training  1760/4999 loss: 0.8462 time 23.89s
Final training  1761/4999 loss: 0.8263 time 24.50s
Final training  1762/4999 loss: 0.8407 time 24.16s
Final training  1763/4999 loss: 0.8384 time 23.85s
Final training  1764/4999 loss: 0.8481 time 24.11s
Final training  1765/4999 loss: 0.8223 time 24.17s
Final training  1766/4999 loss: 0.8559 time 23.96s
Final training  1767/4999 loss: 0.8463 time 24.24s
Final training  1768/4999 loss: 0.8156 time 24.06s
Final training  1769/4999 loss: 0.7984 time 24.00s
Final training  1770/4999 loss: 0.8074 time 24.03s
Final training  1771/4999 loss: 0.8083 time 24.12s
Final training  1772/4999 loss: 0.8398 time 24.21s
Final training  1773/4999 loss: 0.8529 time 23.97s
Final training  1774/4999 loss: 0.8465 time 23.94s
Final training  1775/4999 loss: 0.8726 time 24.15s
Final training  1776/4999 loss: 0.8292 time 23.85s
Final training  1777/4999 loss: 0.8198 time 24.05s
Final training  1778/4999 loss: 0.8414 time 24.05s
Final training  1779/4999 loss: 0.8340 time 24.08s
Final training  1780/4999 loss: 0.8651 time 23.90s
Final training  1781/4999 loss: 0.8490 time 24.25s
Final training  1782/4999 loss: 0.8550 time 24.74s
Final training  1783/4999 loss: 0.8518 time 24.32s
Final training  1784/4999 loss: 0.8392 time 24.12s
Final training  1785/4999 loss: 0.8173 time 24.06s
Final training  1786/4999 loss: 0.8313 time 23.83s
Final training  1787/4999 loss: 0.8536 time 24.18s
Final training  1788/4999 loss: 0.8236 time 24.05s
Final training  1789/4999 loss: 0.8471 time 24.05s
Final training  1790/4999 loss: 0.8238 time 23.80s
Final training  1791/4999 loss: 0.8061 time 23.99s
Final training  1792/4999 loss: 0.8231 time 23.96s
Final training  1793/4999 loss: 0.8025 time 24.18s
Final training  1794/4999 loss: 0.8110 time 23.90s
Final training  1795/4999 loss: 0.8076 time 23.91s
Final training  1796/4999 loss: 0.8571 time 23.99s
Final training  1797/4999 loss: 0.8175 time 23.91s
Final training  1798/4999 loss: 0.8232 time 24.00s
Final training  1799/4999 loss: 0.8346 time 24.21s
Dice accuracy for each class:  (tensor([0.9925, 0.9471, 0.9314, 0.9424, 0.7884, 0.6779, 0.8142, 0.8099, 0.8917,
        0.8447, 0.7455, 0.7750, 0.6529, 0.6154], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1799/4999 acc [ 0.816] time 118.54s
Reset trigger time to 0
new best (0.809157 --> 0.816426). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  1800/4999 loss: 0.8181 time 24.17s
Final training  1801/4999 loss: 0.8350 time 24.01s
Final training  1802/4999 loss: 0.8337 time 24.20s
Final training  1803/4999 loss: 0.7987 time 23.93s
Final training  1804/4999 loss: 0.8108 time 24.07s
Final training  1805/4999 loss: 0.7857 time 23.78s
Final training  1806/4999 loss: 0.8115 time 23.90s
Final training  1807/4999 loss: 0.8234 time 24.07s
Final training  1808/4999 loss: 0.8279 time 24.23s
Final training  1809/4999 loss: 0.8224 time 24.01s
Final training  1810/4999 loss: 0.8168 time 24.02s
Final training  1811/4999 loss: 0.8211 time 23.97s
Final training  1812/4999 loss: 0.8321 time 23.90s
Final training  1813/4999 loss: 0.8112 time 23.98s
Final training  1814/4999 loss: 0.8125 time 24.17s
Final training  1815/4999 loss: 0.8379 time 24.17s
Final training  1816/4999 loss: 0.8271 time 23.52s
Final training  1817/4999 loss: 0.8067 time 24.16s
Final training  1818/4999 loss: 0.8428 time 24.20s
Final training  1819/4999 loss: 0.8371 time 24.11s
Final training  1820/4999 loss: 0.8509 time 24.11s
Final training  1821/4999 loss: 0.8555 time 24.30s
Final training  1822/4999 loss: 0.8216 time 23.93s
Final training  1823/4999 loss: 0.8146 time 23.89s
Final training  1824/4999 loss: 0.8118 time 23.90s
Final training  1825/4999 loss: 0.8498 time 24.14s
Final training  1826/4999 loss: 0.8478 time 24.09s
Final training  1827/4999 loss: 0.8220 time 24.10s
Final training  1828/4999 loss: 0.8310 time 24.06s
Final training  1829/4999 loss: 0.8249 time 23.93s
Final training  1830/4999 loss: 0.8095 time 24.02s
Final training  1831/4999 loss: 0.8110 time 23.86s
Final training  1832/4999 loss: 0.8330 time 24.07s
Final training  1833/4999 loss: 0.8173 time 24.14s
Final training  1834/4999 loss: 0.8170 time 24.05s
Final training  1835/4999 loss: 0.8338 time 24.19s
Final training  1836/4999 loss: 0.8154 time 23.99s
Final training  1837/4999 loss: 0.7996 time 24.15s
Final training  1838/4999 loss: 0.8318 time 23.51s
Final training  1839/4999 loss: 0.8001 time 24.14s
Final training  1840/4999 loss: 0.8186 time 24.04s
Final training  1841/4999 loss: 0.8115 time 23.82s
Final training  1842/4999 loss: 0.7895 time 23.87s
Final training  1843/4999 loss: 0.8554 time 24.05s
Final training  1844/4999 loss: 0.8824 time 24.07s
Final training  1845/4999 loss: 0.8250 time 24.25s
Final training  1846/4999 loss: 0.8314 time 24.33s
Final training  1847/4999 loss: 0.8069 time 23.95s
Final training  1848/4999 loss: 0.8159 time 23.99s
Final training  1849/4999 loss: 0.8239 time 24.09s
Final training  1850/4999 loss: 0.8023 time 23.87s
Final training  1851/4999 loss: 0.8233 time 24.02s
Final training  1852/4999 loss: 0.8041 time 24.04s
Final training  1853/4999 loss: 0.8028 time 24.06s
Final training  1854/4999 loss: 0.8226 time 24.07s
Final training  1855/4999 loss: 0.7934 time 24.04s
Final training  1856/4999 loss: 0.8323 time 24.04s
Final training  1857/4999 loss: 0.7957 time 23.94s
Final training  1858/4999 loss: 0.8199 time 24.12s
Final training  1859/4999 loss: 0.8348 time 23.93s
Final training  1860/4999 loss: 0.8208 time 24.09s
Final training  1861/4999 loss: 0.8013 time 23.81s
Final training  1862/4999 loss: 0.8047 time 23.74s
Final training  1863/4999 loss: 0.8272 time 23.92s
Final training  1864/4999 loss: 0.8076 time 23.95s
Final training  1865/4999 loss: 0.8072 time 24.25s
Final training  1866/4999 loss: 0.8457 time 24.18s
Final training  1867/4999 loss: 0.8287 time 23.97s
Final training  1868/4999 loss: 0.8594 time 24.15s
Final training  1869/4999 loss: 0.8503 time 24.15s
Final training  1870/4999 loss: 0.8446 time 24.08s
Final training  1871/4999 loss: 0.8317 time 24.11s
Final training  1872/4999 loss: 0.8352 time 24.34s
Final training  1873/4999 loss: 0.8367 time 24.29s
Final training  1874/4999 loss: 0.8131 time 24.24s
Final training  1875/4999 loss: 0.8382 time 24.47s
Final training  1876/4999 loss: 0.8191 time 24.32s
Final training  1877/4999 loss: 0.8338 time 24.33s
Final training  1878/4999 loss: 0.8068 time 24.06s
Final training  1879/4999 loss: 0.8273 time 23.98s
Final training  1880/4999 loss: 0.8134 time 24.03s
Final training  1881/4999 loss: 0.8248 time 24.39s
Final training  1882/4999 loss: 0.7930 time 24.94s
Final training  1883/4999 loss: 0.8146 time 24.81s
Final training  1884/4999 loss: 0.8235 time 24.74s
Final training  1885/4999 loss: 0.8272 time 24.60s
Final training  1886/4999 loss: 0.8175 time 24.69s
Final training  1887/4999 loss: 0.8367 time 24.65s
Final training  1888/4999 loss: 0.8516 time 24.23s
Final training  1889/4999 loss: 0.8266 time 24.59s
Final training  1890/4999 loss: 0.8216 time 24.31s
Final training  1891/4999 loss: 0.8510 time 24.19s
Final training  1892/4999 loss: 0.8290 time 24.19s
Final training  1893/4999 loss: 0.8028 time 24.09s
Final training  1894/4999 loss: 0.8101 time 23.94s
Final training  1895/4999 loss: 0.8401 time 24.00s
Final training  1896/4999 loss: 0.7953 time 24.25s
Final training  1897/4999 loss: 0.8143 time 24.08s
Final training  1898/4999 loss: 0.8059 time 24.12s
Final training  1899/4999 loss: 0.8246 time 24.30s
Dice accuracy for each class:  (tensor([0.9928, 0.9482, 0.8843, 0.8744, 0.7871, 0.6755, 0.8274, 0.7558, 0.8967,
        0.8273, 0.7417, 0.7652, 0.6458, 0.5359], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1899/4999 acc [ 0.797] time 121.16s
trigger times: 1
Final training  1900/4999 loss: 0.8164 time 23.88s
Final training  1901/4999 loss: 0.8302 time 24.25s
Final training  1902/4999 loss: 0.8227 time 24.08s
Final training  1903/4999 loss: 0.8390 time 23.87s
Final training  1904/4999 loss: 0.8330 time 23.84s
Final training  1905/4999 loss: 0.8347 time 24.33s
Final training  1906/4999 loss: 0.8182 time 24.08s
Final training  1907/4999 loss: 0.8281 time 24.26s
Final training  1908/4999 loss: 0.8149 time 23.81s
Final training  1909/4999 loss: 0.8245 time 24.07s
Final training  1910/4999 loss: 0.8435 time 24.26s
Final training  1911/4999 loss: 0.8263 time 24.34s
Final training  1912/4999 loss: 0.8103 time 24.29s
Final training  1913/4999 loss: 0.8215 time 24.36s
Final training  1914/4999 loss: 0.8113 time 24.03s
Final training  1915/4999 loss: 0.8161 time 24.22s
Final training  1916/4999 loss: 0.8189 time 24.19s
Final training  1917/4999 loss: 0.7792 time 23.85s
Final training  1918/4999 loss: 0.7991 time 24.00s
Final training  1919/4999 loss: 0.7960 time 23.97s
Final training  1920/4999 loss: 0.8257 time 24.06s
Final training  1921/4999 loss: 0.8233 time 24.00s
Final training  1922/4999 loss: 0.8122 time 23.83s
Final training  1923/4999 loss: 0.8145 time 24.01s
Final training  1924/4999 loss: 0.8332 time 23.92s
Final training  1925/4999 loss: 0.8076 time 24.13s
Final training  1926/4999 loss: 0.8377 time 23.96s
Final training  1927/4999 loss: 0.8282 time 24.05s
Final training  1928/4999 loss: 0.8163 time 23.99s
Final training  1929/4999 loss: 0.8349 time 24.07s
Final training  1930/4999 loss: 0.8265 time 24.06s
Final training  1931/4999 loss: 0.8441 time 23.91s
Final training  1932/4999 loss: 0.8085 time 24.14s
Final training  1933/4999 loss: 0.8206 time 23.87s
Final training  1934/4999 loss: 0.8049 time 23.95s
Final training  1935/4999 loss: 0.8199 time 24.23s
Final training  1936/4999 loss: 0.8282 time 24.31s
Final training  1937/4999 loss: 0.8152 time 24.29s
Final training  1938/4999 loss: 0.7975 time 24.30s
Final training  1939/4999 loss: 0.8213 time 24.36s
Final training  1940/4999 loss: 0.8257 time 24.41s
Final training  1941/4999 loss: 0.8233 time 24.33s
Final training  1942/4999 loss: 0.8095 time 24.34s
Final training  1943/4999 loss: 0.7618 time 24.14s
Final training  1944/4999 loss: 0.8351 time 24.63s
Final training  1945/4999 loss: 0.8192 time 24.05s
Final training  1946/4999 loss: 0.8162 time 24.27s
Final training  1947/4999 loss: 0.8164 time 23.99s
Final training  1948/4999 loss: 0.8126 time 24.19s
Final training  1949/4999 loss: 0.8373 time 24.07s
Final training  1950/4999 loss: 0.8247 time 24.11s
Final training  1951/4999 loss: 0.8231 time 23.85s
Final training  1952/4999 loss: 0.8213 time 24.07s
Final training  1953/4999 loss: 0.8377 time 24.14s
Final training  1954/4999 loss: 0.8195 time 24.07s
Final training  1955/4999 loss: 0.8371 time 24.05s
Final training  1956/4999 loss: 0.8863 time 24.22s
Final training  1957/4999 loss: 0.8703 time 24.11s
Final training  1958/4999 loss: 0.9194 time 24.06s
Final training  1959/4999 loss: 0.8586 time 24.05s
Final training  1960/4999 loss: 0.8450 time 24.13s
Final training  1961/4999 loss: 0.8348 time 23.96s
Final training  1962/4999 loss: 0.8248 time 23.91s
Final training  1963/4999 loss: 0.8285 time 23.84s
Final training  1964/4999 loss: 0.8389 time 23.98s
Final training  1965/4999 loss: 0.8257 time 24.04s
Final training  1966/4999 loss: 0.8177 time 23.72s
Final training  1967/4999 loss: 0.8013 time 23.71s
Final training  1968/4999 loss: 0.8014 time 23.97s
Final training  1969/4999 loss: 0.8177 time 24.02s
Final training  1970/4999 loss: 0.8131 time 24.33s
Final training  1971/4999 loss: 0.8283 time 24.29s
Final training  1972/4999 loss: 0.8137 time 23.97s
Final training  1973/4999 loss: 0.7961 time 23.96s
Final training  1974/4999 loss: 0.8302 time 23.77s
Final training  1975/4999 loss: 0.8063 time 24.25s
Final training  1976/4999 loss: 0.8124 time 24.20s
Final training  1977/4999 loss: 0.8124 time 24.26s
Final training  1978/4999 loss: 0.8142 time 24.09s
Final training  1979/4999 loss: 0.8164 time 24.17s
Final training  1980/4999 loss: 0.7998 time 24.00s
Final training  1981/4999 loss: 0.8025 time 24.78s
Final training  1982/4999 loss: 0.8238 time 24.44s
Final training  1983/4999 loss: 0.8290 time 24.78s
Final training  1984/4999 loss: 0.7929 time 24.54s
Final training  1985/4999 loss: 0.8094 time 24.49s
Final training  1986/4999 loss: 0.8553 time 24.21s
Final training  1987/4999 loss: 0.8546 time 23.99s
Final training  1988/4999 loss: 0.8541 time 24.03s
Final training  1989/4999 loss: 0.8033 time 24.08s
Final training  1990/4999 loss: 0.8204 time 24.43s
Final training  1991/4999 loss: 0.8258 time 23.89s
Final training  1992/4999 loss: 0.8194 time 23.98s
Final training  1993/4999 loss: 0.8239 time 24.07s
Final training  1994/4999 loss: 0.8308 time 23.98s
Final training  1995/4999 loss: 0.8188 time 24.16s
Final training  1996/4999 loss: 0.8305 time 24.05s
Final training  1997/4999 loss: 0.8416 time 23.97s
Final training  1998/4999 loss: 0.8082 time 23.98s
Final training  1999/4999 loss: 0.8105 time 23.90s
Dice accuracy for each class:  (tensor([0.9927, 0.8787, 0.9334, 0.9367, 0.7980, 0.7145, 0.8273, 0.7256, 0.8849,
        0.8409, 0.7442, 0.7631, 0.6221, 0.5773], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  1999/4999 acc [ 0.802] time 121.35s
trigger times: 2
Final training  2000/4999 loss: 0.8475 time 24.58s
Final training  2001/4999 loss: 0.8555 time 24.65s
Final training  2002/4999 loss: 0.8297 time 24.56s
Final training  2003/4999 loss: 0.8197 time 24.72s
Final training  2004/4999 loss: 0.8066 time 24.76s
Final training  2005/4999 loss: 0.8160 time 24.64s
Final training  2006/4999 loss: 0.8302 time 24.35s
Final training  2007/4999 loss: 0.8243 time 23.94s
Final training  2008/4999 loss: 0.8223 time 24.03s
Final training  2009/4999 loss: 0.8103 time 24.15s
Final training  2010/4999 loss: 0.8166 time 24.18s
Final training  2011/4999 loss: 0.8281 time 24.10s
Final training  2012/4999 loss: 0.8067 time 23.96s
Final training  2013/4999 loss: 0.8283 time 24.18s
Final training  2014/4999 loss: 0.8336 time 23.80s
Final training  2015/4999 loss: 0.8392 time 23.91s
Final training  2016/4999 loss: 0.8163 time 23.84s
Final training  2017/4999 loss: 0.8155 time 23.94s
Final training  2018/4999 loss: 0.8331 time 24.22s
Final training  2019/4999 loss: 0.8250 time 24.34s
Final training  2020/4999 loss: 0.8378 time 24.59s
Final training  2021/4999 loss: 0.8050 time 24.47s
Final training  2022/4999 loss: 0.7985 time 24.42s
Final training  2023/4999 loss: 0.8198 time 24.57s
Final training  2024/4999 loss: 0.8186 time 24.31s
Final training  2025/4999 loss: 0.8092 time 24.28s
Final training  2026/4999 loss: 0.8273 time 24.41s
Final training  2027/4999 loss: 0.8073 time 24.08s
Final training  2028/4999 loss: 0.8025 time 24.08s
Final training  2029/4999 loss: 0.8071 time 24.05s
Final training  2030/4999 loss: 0.7973 time 24.20s
Final training  2031/4999 loss: 0.8041 time 23.83s
Final training  2032/4999 loss: 0.8089 time 24.54s
Final training  2033/4999 loss: 0.8777 time 24.29s
Final training  2034/4999 loss: 0.8131 time 24.15s
Final training  2035/4999 loss: 0.8226 time 24.07s
Final training  2036/4999 loss: 0.8142 time 24.26s
Final training  2037/4999 loss: 0.8129 time 24.02s
Final training  2038/4999 loss: 0.8085 time 24.05s
Final training  2039/4999 loss: 0.8288 time 24.07s
Final training  2040/4999 loss: 0.8015 time 24.56s
Final training  2041/4999 loss: 0.8076 time 24.06s
Final training  2042/4999 loss: 0.8223 time 24.05s
Final training  2043/4999 loss: 0.8026 time 24.16s
Final training  2044/4999 loss: 0.8089 time 24.02s
Final training  2045/4999 loss: 0.8153 time 23.95s
Final training  2046/4999 loss: 0.8226 time 24.05s
Final training  2047/4999 loss: 0.8464 time 24.16s
Final training  2048/4999 loss: 0.8091 time 24.12s
Final training  2049/4999 loss: 0.7830 time 24.12s
Final training  2050/4999 loss: 0.8104 time 23.95s
Final training  2051/4999 loss: 0.8323 time 23.83s
Final training  2052/4999 loss: 0.8147 time 23.98s
Final training  2053/4999 loss: 0.8107 time 24.09s
Final training  2054/4999 loss: 0.8380 time 23.72s
Final training  2055/4999 loss: 0.8013 time 23.99s
Final training  2056/4999 loss: 0.8229 time 24.15s
Final training  2057/4999 loss: 0.8346 time 24.14s
Final training  2058/4999 loss: 0.8169 time 24.07s
Final training  2059/4999 loss: 0.8383 time 24.22s
Final training  2060/4999 loss: 0.8093 time 23.99s
Final training  2061/4999 loss: 0.8290 time 24.18s
Final training  2062/4999 loss: 0.8138 time 24.10s
Final training  2063/4999 loss: 0.8244 time 23.92s
Final training  2064/4999 loss: 0.8089 time 23.96s
Final training  2065/4999 loss: 0.8005 time 23.89s
Final training  2066/4999 loss: 0.8126 time 23.56s
Final training  2067/4999 loss: 0.8136 time 23.93s
Final training  2068/4999 loss: 0.8086 time 24.13s
Final training  2069/4999 loss: 0.8158 time 23.61s
Final training  2070/4999 loss: 0.8167 time 24.10s
Final training  2071/4999 loss: 0.7981 time 24.11s
Final training  2072/4999 loss: 0.8112 time 24.01s
Final training  2073/4999 loss: 0.8094 time 23.86s
Final training  2074/4999 loss: 0.8328 time 23.91s
Final training  2075/4999 loss: 0.8210 time 24.54s
Final training  2076/4999 loss: 0.8261 time 24.53s
Final training  2077/4999 loss: 0.8396 time 24.05s
Final training  2078/4999 loss: 0.8157 time 23.58s
Final training  2079/4999 loss: 0.8108 time 24.32s
Final training  2080/4999 loss: 0.7833 time 24.07s
Final training  2081/4999 loss: 0.8294 time 23.91s
Final training  2082/4999 loss: 0.8365 time 24.02s
Final training  2083/4999 loss: 0.8115 time 24.16s
Final training  2084/4999 loss: 0.8024 time 24.19s
Final training  2085/4999 loss: 0.8232 time 24.21s
Final training  2086/4999 loss: 0.8302 time 24.12s
Final training  2087/4999 loss: 0.7997 time 24.02s
Final training  2088/4999 loss: 0.8282 time 24.05s
Final training  2089/4999 loss: 0.8184 time 24.29s
Final training  2090/4999 loss: 0.7965 time 24.65s
Final training  2091/4999 loss: 0.8003 time 24.41s
Final training  2092/4999 loss: 0.8018 time 23.92s
Final training  2093/4999 loss: 0.8271 time 24.58s
Final training  2094/4999 loss: 0.8244 time 24.54s
Final training  2095/4999 loss: 0.8107 time 24.75s
Final training  2096/4999 loss: 0.8252 time 24.79s
Final training  2097/4999 loss: 0.8279 time 24.42s
Final training  2098/4999 loss: 0.8367 time 24.26s
Final training  2099/4999 loss: 0.8013 time 24.46s
Dice accuracy for each class:  (tensor([0.9917, 0.8792, 0.9315, 0.9354, 0.7967, 0.7410, 0.7994, 0.7464, 0.8938,
        0.8466, 0.7547, 0.7537, 0.6287, 0.5647], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2099/4999 acc [ 0.804] time 121.35s
trigger times: 3
Final training  2100/4999 loss: 0.8351 time 24.19s
Final training  2101/4999 loss: 0.8339 time 23.75s
Final training  2102/4999 loss: 0.8168 time 24.08s
Final training  2103/4999 loss: 0.8206 time 24.15s
Final training  2104/4999 loss: 0.8216 time 23.93s
Final training  2105/4999 loss: 0.7974 time 24.06s
Final training  2106/4999 loss: 0.8030 time 24.06s
Final training  2107/4999 loss: 0.7918 time 24.14s
Final training  2108/4999 loss: 0.7903 time 24.13s
Final training  2109/4999 loss: 0.8236 time 24.15s
Final training  2110/4999 loss: 0.8007 time 24.15s
Final training  2111/4999 loss: 0.8370 time 23.99s
Final training  2112/4999 loss: 0.8108 time 24.15s
Final training  2113/4999 loss: 0.8172 time 24.08s
Final training  2114/4999 loss: 0.8056 time 24.08s
Final training  2115/4999 loss: 0.8285 time 24.38s
Final training  2116/4999 loss: 0.8211 time 23.95s
Final training  2117/4999 loss: 0.8082 time 24.49s
Final training  2118/4999 loss: 0.7935 time 24.37s
Final training  2119/4999 loss: 0.8263 time 23.92s
Final training  2120/4999 loss: 0.8072 time 23.91s
Final training  2121/4999 loss: 0.8207 time 24.03s
Final training  2122/4999 loss: 0.8227 time 24.13s
Final training  2123/4999 loss: 0.8032 time 23.84s
Final training  2124/4999 loss: 0.8027 time 24.07s
Final training  2125/4999 loss: 0.7959 time 24.13s
Final training  2126/4999 loss: 0.8264 time 24.10s
Final training  2127/4999 loss: 0.7934 time 24.10s
Final training  2128/4999 loss: 0.8139 time 24.07s
Final training  2129/4999 loss: 0.8241 time 24.08s
Final training  2130/4999 loss: 0.8078 time 24.12s
Final training  2131/4999 loss: 0.8231 time 23.88s
Final training  2132/4999 loss: 0.7768 time 23.80s
Final training  2133/4999 loss: 0.7836 time 24.01s
Final training  2134/4999 loss: 0.7888 time 24.14s
Final training  2135/4999 loss: 0.8173 time 24.04s
Final training  2136/4999 loss: 0.8010 time 23.85s
Final training  2137/4999 loss: 0.8052 time 24.19s
Final training  2138/4999 loss: 0.8042 time 23.87s
Final training  2139/4999 loss: 0.7929 time 23.96s
Final training  2140/4999 loss: 0.8039 time 23.93s
Final training  2141/4999 loss: 0.8179 time 24.08s
Final training  2142/4999 loss: 0.8329 time 24.11s
Final training  2143/4999 loss: 0.8358 time 24.04s
Final training  2144/4999 loss: 0.8325 time 24.03s
Final training  2145/4999 loss: 0.8163 time 24.32s
Final training  2146/4999 loss: 0.8182 time 24.13s
Final training  2147/4999 loss: 0.8153 time 24.41s
Final training  2148/4999 loss: 0.8166 time 23.92s
Final training  2149/4999 loss: 0.7983 time 24.01s
Final training  2150/4999 loss: 0.8215 time 24.01s
Final training  2151/4999 loss: 0.7853 time 24.09s
Final training  2152/4999 loss: 0.8238 time 24.26s
Final training  2153/4999 loss: 0.8077 time 24.29s
Final training  2154/4999 loss: 0.8123 time 24.17s
Final training  2155/4999 loss: 0.7936 time 24.47s
Final training  2156/4999 loss: 0.8108 time 24.68s
Final training  2157/4999 loss: 0.7946 time 24.37s
Final training  2158/4999 loss: 0.8119 time 24.77s
Final training  2159/4999 loss: 0.8003 time 24.72s
Final training  2160/4999 loss: 0.8036 time 24.66s
Final training  2161/4999 loss: 0.8184 time 24.40s
Final training  2162/4999 loss: 0.8012 time 24.85s
Final training  2163/4999 loss: 0.8043 time 24.68s
Final training  2164/4999 loss: 0.8068 time 24.74s
Final training  2165/4999 loss: 0.7934 time 24.53s
Final training  2166/4999 loss: 0.8182 time 24.26s
Final training  2167/4999 loss: 0.8132 time 24.32s
Final training  2168/4999 loss: 0.8098 time 24.32s
Final training  2169/4999 loss: 0.8179 time 24.19s
Final training  2170/4999 loss: 0.8297 time 24.09s
Final training  2171/4999 loss: 0.8057 time 24.20s
Final training  2172/4999 loss: 0.8113 time 23.94s
Final training  2173/4999 loss: 0.7966 time 24.18s
Final training  2174/4999 loss: 0.8195 time 23.87s
Final training  2175/4999 loss: 0.7949 time 24.16s
Final training  2176/4999 loss: 0.8458 time 24.00s
Final training  2177/4999 loss: 0.8091 time 23.72s
Final training  2178/4999 loss: 0.7884 time 23.84s
Final training  2179/4999 loss: 0.8092 time 23.95s
Final training  2180/4999 loss: 0.7873 time 24.31s
Final training  2181/4999 loss: 0.8028 time 24.15s
Final training  2182/4999 loss: 0.8222 time 24.24s
Final training  2183/4999 loss: 0.8305 time 24.21s
Final training  2184/4999 loss: 0.8205 time 24.25s
Final training  2185/4999 loss: 0.7966 time 23.97s
Final training  2186/4999 loss: 0.8073 time 23.98s
Final training  2187/4999 loss: 0.8095 time 23.92s
Final training  2188/4999 loss: 0.8543 time 24.26s
Final training  2189/4999 loss: 0.8274 time 23.84s
Final training  2190/4999 loss: 0.8275 time 24.05s
Final training  2191/4999 loss: 0.8179 time 24.21s
Final training  2192/4999 loss: 0.8069 time 24.16s
Final training  2193/4999 loss: 0.8186 time 24.18s
Final training  2194/4999 loss: 0.8110 time 23.89s
Final training  2195/4999 loss: 0.7890 time 24.10s
Final training  2196/4999 loss: 0.8132 time 24.59s
Final training  2197/4999 loss: 0.8129 time 24.77s
Final training  2198/4999 loss: 0.8067 time 24.08s
Final training  2199/4999 loss: 0.8057 time 24.13s
Dice accuracy for each class:  (tensor([0.9910, 0.9464, 0.9222, 0.9295, 0.7771, 0.7411, 0.7940, 0.8076, 0.9016,
        0.8334, 0.7414, 0.7805, 0.6448, 0.6107], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2199/4999 acc [ 0.816] time 120.58s
trigger times: 4
Final training  2200/4999 loss: 0.8185 time 24.16s
Final training  2201/4999 loss: 0.7982 time 24.10s
Final training  2202/4999 loss: 0.8013 time 24.22s
Final training  2203/4999 loss: 0.8087 time 24.11s
Final training  2204/4999 loss: 0.7982 time 24.20s
Final training  2205/4999 loss: 0.8141 time 23.96s
Final training  2206/4999 loss: 0.8020 time 24.02s
Final training  2207/4999 loss: 0.8267 time 23.85s
Final training  2208/4999 loss: 0.8260 time 23.89s
Final training  2209/4999 loss: 0.8133 time 23.70s
Final training  2210/4999 loss: 0.8175 time 24.12s
Final training  2211/4999 loss: 0.8048 time 24.03s
Final training  2212/4999 loss: 0.8185 time 24.22s
Final training  2213/4999 loss: 0.8204 time 24.27s
Final training  2214/4999 loss: 0.7998 time 24.15s
Final training  2215/4999 loss: 0.8218 time 23.83s
Final training  2216/4999 loss: 0.8106 time 23.93s
Final training  2217/4999 loss: 0.8258 time 24.39s
Final training  2218/4999 loss: 0.8101 time 23.84s
Final training  2219/4999 loss: 0.8234 time 23.94s
Final training  2220/4999 loss: 0.8051 time 24.20s
Final training  2221/4999 loss: 0.7928 time 23.93s
Final training  2222/4999 loss: 0.8031 time 24.17s
Final training  2223/4999 loss: 0.7979 time 24.04s
Final training  2224/4999 loss: 0.7979 time 24.10s
Final training  2225/4999 loss: 0.8099 time 24.17s
Final training  2226/4999 loss: 0.8062 time 24.05s
Final training  2227/4999 loss: 0.7760 time 24.09s
Final training  2228/4999 loss: 0.8151 time 24.39s
Final training  2229/4999 loss: 0.8072 time 24.48s
Final training  2230/4999 loss: 0.7869 time 24.22s
Final training  2231/4999 loss: 0.8411 time 24.40s
Final training  2232/4999 loss: 0.8355 time 24.24s
Final training  2233/4999 loss: 0.8291 time 23.90s
Final training  2234/4999 loss: 0.8091 time 24.25s
Final training  2235/4999 loss: 0.8136 time 24.36s
Final training  2236/4999 loss: 0.8038 time 24.03s
Final training  2237/4999 loss: 0.8242 time 24.28s
Final training  2238/4999 loss: 0.7755 time 23.64s
Final training  2239/4999 loss: 0.8141 time 24.09s
Final training  2240/4999 loss: 0.8094 time 24.08s
Final training  2241/4999 loss: 0.8102 time 23.97s
Final training  2242/4999 loss: 0.8241 time 24.13s
Final training  2243/4999 loss: 0.7888 time 24.19s
Final training  2244/4999 loss: 0.8210 time 24.07s
Final training  2245/4999 loss: 0.8334 time 24.18s
Final training  2246/4999 loss: 0.8025 time 24.36s
Final training  2247/4999 loss: 0.8143 time 24.19s
Final training  2248/4999 loss: 0.8015 time 24.03s
Final training  2249/4999 loss: 0.7968 time 23.86s
Final training  2250/4999 loss: 0.7944 time 24.06s
Final training  2251/4999 loss: 0.8015 time 24.19s
Final training  2252/4999 loss: 0.8135 time 24.42s
Final training  2253/4999 loss: 0.8040 time 24.53s
Final training  2254/4999 loss: 0.7962 time 24.35s
Final training  2255/4999 loss: 0.8188 time 24.14s
Final training  2256/4999 loss: 0.8242 time 24.23s
Final training  2257/4999 loss: 0.8194 time 23.90s
Final training  2258/4999 loss: 0.7911 time 24.06s
Final training  2259/4999 loss: 0.8246 time 24.49s
Final training  2260/4999 loss: 0.7844 time 24.17s
Final training  2261/4999 loss: 0.8199 time 24.22s
Final training  2262/4999 loss: 0.8210 time 23.88s
Final training  2263/4999 loss: 0.8007 time 24.16s
Final training  2264/4999 loss: 0.8026 time 24.01s
Final training  2265/4999 loss: 0.7814 time 23.94s
Final training  2266/4999 loss: 0.8328 time 24.28s
Final training  2267/4999 loss: 0.7971 time 24.21s
Final training  2268/4999 loss: 0.8063 time 24.15s
Final training  2269/4999 loss: 0.8107 time 23.85s
Final training  2270/4999 loss: 0.8118 time 23.91s
Final training  2271/4999 loss: 0.8218 time 24.16s
Final training  2272/4999 loss: 0.8015 time 24.20s
Final training  2273/4999 loss: 0.7836 time 23.89s
Final training  2274/4999 loss: 0.8116 time 24.20s
Final training  2275/4999 loss: 0.8128 time 24.17s
Final training  2276/4999 loss: 0.8023 time 23.69s
Final training  2277/4999 loss: 0.7870 time 23.99s
Final training  2278/4999 loss: 0.8079 time 24.03s
Final training  2279/4999 loss: 0.8025 time 24.04s
Final training  2280/4999 loss: 0.8113 time 24.12s
Final training  2281/4999 loss: 0.8102 time 24.06s
Final training  2282/4999 loss: 0.8082 time 24.24s
Final training  2283/4999 loss: 0.8093 time 23.89s
Final training  2284/4999 loss: 0.7910 time 23.89s
Final training  2285/4999 loss: 0.8029 time 24.24s
Final training  2286/4999 loss: 0.8117 time 24.12s
Final training  2287/4999 loss: 0.8030 time 24.12s
Final training  2288/4999 loss: 0.7990 time 24.27s
Final training  2289/4999 loss: 0.8132 time 24.30s
Final training  2290/4999 loss: 0.8302 time 24.41s
Final training  2291/4999 loss: 0.7998 time 24.77s
Final training  2292/4999 loss: 0.8288 time 24.55s
Final training  2293/4999 loss: 0.8209 time 24.76s
Final training  2294/4999 loss: 0.8002 time 24.70s
Final training  2295/4999 loss: 0.7941 time 24.04s
Final training  2296/4999 loss: 0.8000 time 24.36s
Final training  2297/4999 loss: 0.7751 time 24.21s
Final training  2298/4999 loss: 0.7803 time 24.19s
Final training  2299/4999 loss: 0.8280 time 24.15s
Dice accuracy for each class:  (tensor([0.9913, 0.9241, 0.9411, 0.9417, 0.7832, 0.7368, 0.7989, 0.8016, 0.8999,
        0.8413, 0.7399, 0.7733, 0.6564, 0.5678], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2299/4999 acc [ 0.814] time 121.27s
trigger times: 5
Final training  2300/4999 loss: 0.8224 time 24.09s
Final training  2301/4999 loss: 0.8187 time 24.16s
Final training  2302/4999 loss: 0.8141 time 23.94s
Final training  2303/4999 loss: 0.8090 time 23.84s
Final training  2304/4999 loss: 0.8076 time 24.32s
Final training  2305/4999 loss: 0.8003 time 24.22s
Final training  2306/4999 loss: 0.7872 time 24.19s
Final training  2307/4999 loss: 0.7936 time 24.33s
Final training  2308/4999 loss: 0.7923 time 24.34s
Final training  2309/4999 loss: 0.7851 time 24.30s
Final training  2310/4999 loss: 0.8037 time 24.02s
Final training  2311/4999 loss: 0.7823 time 24.37s
Final training  2312/4999 loss: 0.8072 time 24.05s
Final training  2313/4999 loss: 0.8033 time 24.35s
Final training  2314/4999 loss: 0.8178 time 24.20s
Final training  2315/4999 loss: 0.8034 time 24.21s
Final training  2316/4999 loss: 0.7893 time 24.06s
Final training  2317/4999 loss: 0.7880 time 24.00s
Final training  2318/4999 loss: 0.8226 time 24.07s
Final training  2319/4999 loss: 0.8087 time 24.05s
Final training  2320/4999 loss: 0.8135 time 23.99s
Final training  2321/4999 loss: 0.8118 time 24.08s
Final training  2322/4999 loss: 0.8072 time 24.02s
Final training  2323/4999 loss: 0.7900 time 23.80s
Final training  2324/4999 loss: 0.8158 time 24.07s
Final training  2325/4999 loss: 0.8250 time 24.14s
Final training  2326/4999 loss: 0.7915 time 23.93s
Final training  2327/4999 loss: 0.8063 time 23.99s
Final training  2328/4999 loss: 0.8160 time 24.15s
Final training  2329/4999 loss: 0.8462 time 24.25s
Final training  2330/4999 loss: 0.8219 time 24.24s
Final training  2331/4999 loss: 0.8401 time 24.39s
Final training  2332/4999 loss: 0.8523 time 23.92s
Final training  2333/4999 loss: 0.8428 time 24.21s
Final training  2334/4999 loss: 0.8162 time 23.95s
Final training  2335/4999 loss: 0.7986 time 24.10s
Final training  2336/4999 loss: 0.7876 time 24.20s
Final training  2337/4999 loss: 0.8204 time 24.13s
Final training  2338/4999 loss: 0.7933 time 24.20s
Final training  2339/4999 loss: 0.8105 time 24.26s
Final training  2340/4999 loss: 0.7812 time 24.31s
Final training  2341/4999 loss: 0.7823 time 24.08s
Final training  2342/4999 loss: 0.8009 time 24.31s
Final training  2343/4999 loss: 0.7881 time 24.43s
Final training  2344/4999 loss: 0.7990 time 24.03s
Final training  2345/4999 loss: 0.8320 time 23.94s
Final training  2346/4999 loss: 0.8055 time 24.19s
Final training  2347/4999 loss: 0.7833 time 23.91s
Final training  2348/4999 loss: 0.8161 time 24.01s
Final training  2349/4999 loss: 0.7954 time 24.07s
Final training  2350/4999 loss: 0.7962 time 24.16s
Final training  2351/4999 loss: 0.8087 time 24.07s
Final training  2352/4999 loss: 0.8158 time 24.27s
Final training  2353/4999 loss: 0.7923 time 24.26s
Final training  2354/4999 loss: 0.8034 time 24.45s
Final training  2355/4999 loss: 0.8097 time 24.36s
Final training  2356/4999 loss: 0.7839 time 24.22s
Final training  2357/4999 loss: 0.8093 time 24.30s
Final training  2358/4999 loss: 0.8090 time 24.18s
Final training  2359/4999 loss: 0.8357 time 24.06s
Final training  2360/4999 loss: 0.8179 time 24.06s
Final training  2361/4999 loss: 0.8106 time 23.96s
Final training  2362/4999 loss: 0.8169 time 24.20s
Final training  2363/4999 loss: 0.7887 time 24.31s
Final training  2364/4999 loss: 0.8280 time 23.96s
Final training  2365/4999 loss: 0.8284 time 24.21s
Final training  2366/4999 loss: 0.8110 time 24.18s
Final training  2367/4999 loss: 0.8074 time 24.26s
Final training  2368/4999 loss: 0.7932 time 24.36s
Final training  2369/4999 loss: 0.8029 time 24.64s
Final training  2370/4999 loss: 0.7951 time 24.52s
Final training  2371/4999 loss: 0.7984 time 24.37s
Final training  2372/4999 loss: 0.8174 time 23.99s
Final training  2373/4999 loss: 0.8155 time 24.33s
Final training  2374/4999 loss: 0.8157 time 24.30s
Final training  2375/4999 loss: 0.7989 time 24.26s
Final training  2376/4999 loss: 0.8166 time 23.78s
Final training  2377/4999 loss: 0.7999 time 24.28s
Final training  2378/4999 loss: 0.7855 time 24.00s
Final training  2379/4999 loss: 0.7943 time 24.52s
Final training  2380/4999 loss: 0.8276 time 24.80s
Final training  2381/4999 loss: 0.8197 time 24.36s
Final training  2382/4999 loss: 0.7978 time 24.17s
Final training  2383/4999 loss: 0.8050 time 24.37s
Final training  2384/4999 loss: 0.8014 time 24.21s
Final training  2385/4999 loss: 0.7793 time 24.47s
Final training  2386/4999 loss: 0.8069 time 24.21s
Final training  2387/4999 loss: 0.8200 time 23.90s
Final training  2388/4999 loss: 0.7954 time 23.93s
Final training  2389/4999 loss: 0.8083 time 23.81s
Final training  2390/4999 loss: 0.7942 time 24.16s
Final training  2391/4999 loss: 0.7947 time 24.18s
Final training  2392/4999 loss: 0.7812 time 24.14s
Final training  2393/4999 loss: 0.7923 time 24.10s
Final training  2394/4999 loss: 0.8035 time 24.19s
Final training  2395/4999 loss: 0.7897 time 24.00s
Final training  2396/4999 loss: 0.7849 time 23.93s
Final training  2397/4999 loss: 0.8371 time 23.93s
Final training  2398/4999 loss: 0.8097 time 23.89s
Final training  2399/4999 loss: 0.8206 time 24.18s
Dice accuracy for each class:  (tensor([0.9899, 0.9448, 0.9410, 0.9433, 0.7267, 0.7376, 0.7804, 0.7987, 0.9046,
        0.8149, 0.7403, 0.7301, 0.6619, 0.5743], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2399/4999 acc [ 0.807] time 118.75s
trigger times: 6
Final training  2400/4999 loss: 0.7966 time 23.80s
Final training  2401/4999 loss: 0.7870 time 24.29s
Final training  2402/4999 loss: 0.8036 time 24.49s
Final training  2403/4999 loss: 0.8505 time 24.78s
Final training  2404/4999 loss: 0.8441 time 24.78s
Final training  2405/4999 loss: 0.8196 time 24.89s
Final training  2406/4999 loss: 0.8014 time 24.72s
Final training  2407/4999 loss: 0.8053 time 24.67s
Final training  2408/4999 loss: 0.7996 time 24.18s
Final training  2409/4999 loss: 0.8328 time 24.39s
Final training  2410/4999 loss: 0.8182 time 24.26s
Final training  2411/4999 loss: 0.8251 time 24.34s
Final training  2412/4999 loss: 0.8013 time 24.08s
Final training  2413/4999 loss: 0.8077 time 24.08s
Final training  2414/4999 loss: 0.8157 time 24.23s
Final training  2415/4999 loss: 0.8169 time 23.94s
Final training  2416/4999 loss: 0.7730 time 24.07s
Final training  2417/4999 loss: 0.8096 time 24.13s
Final training  2418/4999 loss: 0.7958 time 24.27s
Final training  2419/4999 loss: 0.7971 time 24.04s
Final training  2420/4999 loss: 0.8187 time 23.80s
Final training  2421/4999 loss: 0.7903 time 23.84s
Final training  2422/4999 loss: 0.7985 time 24.06s
Final training  2423/4999 loss: 0.8010 time 24.22s
Final training  2424/4999 loss: 0.8142 time 23.89s
Final training  2425/4999 loss: 0.7968 time 23.98s
Final training  2426/4999 loss: 0.8067 time 23.95s
Final training  2427/4999 loss: 0.8197 time 24.01s
Final training  2428/4999 loss: 0.8237 time 24.00s
Final training  2429/4999 loss: 0.8033 time 24.12s
Final training  2430/4999 loss: 0.8376 time 24.14s
Final training  2431/4999 loss: 0.8281 time 24.01s
Final training  2432/4999 loss: 0.8012 time 24.19s
Final training  2433/4999 loss: 0.7990 time 23.81s
Final training  2434/4999 loss: 0.8088 time 24.02s
Final training  2435/4999 loss: 0.8153 time 24.07s
Final training  2436/4999 loss: 0.8137 time 24.15s
Final training  2437/4999 loss: 0.8064 time 23.97s
Final training  2438/4999 loss: 0.8147 time 24.18s
Final training  2439/4999 loss: 0.7989 time 24.01s
Final training  2440/4999 loss: 0.8245 time 24.03s
Final training  2441/4999 loss: 0.8117 time 24.15s
Final training  2442/4999 loss: 0.8015 time 23.81s
Final training  2443/4999 loss: 0.8077 time 24.14s
Final training  2444/4999 loss: 0.8002 time 24.11s
Final training  2445/4999 loss: 0.8174 time 24.03s
Final training  2446/4999 loss: 0.8054 time 24.07s
Final training  2447/4999 loss: 0.7844 time 24.03s
Final training  2448/4999 loss: 0.7910 time 24.02s
Final training  2449/4999 loss: 0.7911 time 24.43s
Final training  2450/4999 loss: 0.7979 time 24.25s
Final training  2451/4999 loss: 0.7961 time 24.19s
Final training  2452/4999 loss: 0.8021 time 24.07s
Final training  2453/4999 loss: 0.8271 time 23.98s
Final training  2454/4999 loss: 0.8165 time 24.10s
Final training  2455/4999 loss: 0.8027 time 24.02s
Final training  2456/4999 loss: 0.8153 time 24.10s
Final training  2457/4999 loss: 0.7762 time 24.03s
Final training  2458/4999 loss: 0.7868 time 23.93s
Final training  2459/4999 loss: 0.8055 time 24.04s
Final training  2460/4999 loss: 0.7933 time 24.19s
Final training  2461/4999 loss: 0.7974 time 23.87s
Final training  2462/4999 loss: 0.7907 time 24.07s
Final training  2463/4999 loss: 0.7980 time 23.92s
Final training  2464/4999 loss: 0.8008 time 24.20s
Final training  2465/4999 loss: 0.7785 time 24.27s
Final training  2466/4999 loss: 0.7875 time 24.02s
Final training  2467/4999 loss: 0.8008 time 24.20s
Final training  2468/4999 loss: 0.7869 time 24.14s
Final training  2469/4999 loss: 0.7769 time 24.20s
Final training  2470/4999 loss: 0.8064 time 24.07s
Final training  2471/4999 loss: 0.8073 time 24.10s
Final training  2472/4999 loss: 0.7826 time 24.22s
Final training  2473/4999 loss: 0.7988 time 24.05s
Final training  2474/4999 loss: 0.8210 time 24.05s
Final training  2475/4999 loss: 0.7995 time 24.01s
Final training  2476/4999 loss: 0.7903 time 24.15s
Final training  2477/4999 loss: 0.8305 time 24.35s
Final training  2478/4999 loss: 0.7999 time 24.62s
Final training  2479/4999 loss: 0.7994 time 24.51s
Final training  2480/4999 loss: 0.8113 time 24.24s
Final training  2481/4999 loss: 0.8019 time 23.66s
Final training  2482/4999 loss: 0.8294 time 24.02s
Final training  2483/4999 loss: 0.8072 time 24.20s
Final training  2484/4999 loss: 0.8052 time 24.17s
Final training  2485/4999 loss: 0.7977 time 24.26s
Final training  2486/4999 loss: 0.7956 time 24.02s
Final training  2487/4999 loss: 0.7924 time 24.15s
Final training  2488/4999 loss: 0.8066 time 23.79s
Final training  2489/4999 loss: 0.7898 time 23.82s
Final training  2490/4999 loss: 0.7997 time 23.98s
Final training  2491/4999 loss: 0.8189 time 23.82s
Final training  2492/4999 loss: 0.7889 time 23.89s
Final training  2493/4999 loss: 0.7920 time 24.12s
Final training  2494/4999 loss: 0.8024 time 24.01s
Final training  2495/4999 loss: 0.7891 time 24.18s
Final training  2496/4999 loss: 0.8059 time 24.06s
Final training  2497/4999 loss: 0.7942 time 24.16s
Final training  2498/4999 loss: 0.7873 time 23.95s
Final training  2499/4999 loss: 0.8229 time 23.95s
Dice accuracy for each class:  (tensor([0.9907, 0.9018, 0.9185, 0.9239, 0.8035, 0.7215, 0.7951, 0.7799, 0.9032,
        0.8145, 0.7417, 0.7629, 0.6656, 0.5690], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2499/4999 acc [ 0.806] time 119.20s
trigger times: 7
Final training  2500/4999 loss: 0.8042 time 23.94s
Final training  2501/4999 loss: 0.8019 time 23.90s
Final training  2502/4999 loss: 0.8176 time 24.02s
Final training  2503/4999 loss: 0.8200 time 24.21s
Final training  2504/4999 loss: 0.7968 time 24.14s
Final training  2505/4999 loss: 0.8146 time 24.18s
Final training  2506/4999 loss: 0.8122 time 24.26s
Final training  2507/4999 loss: 0.7891 time 24.19s
Final training  2508/4999 loss: 0.7928 time 24.08s
Final training  2509/4999 loss: 0.7935 time 24.56s
Final training  2510/4999 loss: 0.8404 time 24.12s
Final training  2511/4999 loss: 0.8059 time 24.04s
Final training  2512/4999 loss: 0.8182 time 24.15s
Final training  2513/4999 loss: 0.8135 time 23.90s
Final training  2514/4999 loss: 0.7997 time 24.07s
Final training  2515/4999 loss: 0.8120 time 23.97s
Final training  2516/4999 loss: 0.8077 time 23.85s
Final training  2517/4999 loss: 0.8123 time 24.09s
Final training  2518/4999 loss: 0.7871 time 23.98s
Final training  2519/4999 loss: 0.8248 time 23.86s
Final training  2520/4999 loss: 0.8085 time 24.11s
Final training  2521/4999 loss: 0.7644 time 23.93s
Final training  2522/4999 loss: 0.8022 time 23.88s
Final training  2523/4999 loss: 0.7977 time 23.95s
Final training  2524/4999 loss: 0.8102 time 24.08s
Final training  2525/4999 loss: 0.8262 time 23.93s
Final training  2526/4999 loss: 0.8086 time 24.32s
Final training  2527/4999 loss: 0.8079 time 24.17s
Final training  2528/4999 loss: 0.7973 time 24.15s
Final training  2529/4999 loss: 0.8180 time 24.33s
Final training  2530/4999 loss: 0.7994 time 24.01s
Final training  2531/4999 loss: 0.8116 time 24.45s
Final training  2532/4999 loss: 0.7902 time 24.45s
Final training  2533/4999 loss: 0.8146 time 24.11s
Final training  2534/4999 loss: 0.8503 time 24.06s
Final training  2535/4999 loss: 0.8416 time 24.02s
Final training  2536/4999 loss: 0.8295 time 23.98s
Final training  2537/4999 loss: 0.8090 time 23.93s
Final training  2538/4999 loss: 0.8036 time 23.92s
Final training  2539/4999 loss: 0.8185 time 24.14s
Final training  2540/4999 loss: 0.8092 time 23.97s
Final training  2541/4999 loss: 0.7916 time 24.01s
Final training  2542/4999 loss: 0.8534 time 24.05s
Final training  2543/4999 loss: 0.8237 time 24.04s
Final training  2544/4999 loss: 0.7866 time 24.18s
Final training  2545/4999 loss: 0.8013 time 23.88s
Final training  2546/4999 loss: 0.7995 time 24.07s
Final training  2547/4999 loss: 0.8062 time 24.16s
Final training  2548/4999 loss: 0.8145 time 24.10s
Final training  2549/4999 loss: 0.8227 time 24.20s
Final training  2550/4999 loss: 0.7659 time 24.14s
Final training  2551/4999 loss: 0.8062 time 24.20s
Final training  2552/4999 loss: 0.7862 time 24.11s
Final training  2553/4999 loss: 0.8203 time 24.10s
Final training  2554/4999 loss: 0.8102 time 24.29s
Final training  2555/4999 loss: 0.7800 time 24.22s
Final training  2556/4999 loss: 0.7999 time 24.19s
Final training  2557/4999 loss: 0.7842 time 23.81s
Final training  2558/4999 loss: 0.7898 time 23.98s
Final training  2559/4999 loss: 0.7926 time 23.97s
Final training  2560/4999 loss: 0.7919 time 23.71s
Final training  2561/4999 loss: 0.7839 time 24.00s
Final training  2562/4999 loss: 0.8057 time 24.18s
Final training  2563/4999 loss: 0.7945 time 24.27s
Final training  2564/4999 loss: 0.8108 time 23.94s
Final training  2565/4999 loss: 0.8044 time 24.17s
Final training  2566/4999 loss: 0.8229 time 24.21s
Final training  2567/4999 loss: 0.8109 time 24.07s
Final training  2568/4999 loss: 0.8003 time 24.23s
Final training  2569/4999 loss: 0.8231 time 24.16s
Final training  2570/4999 loss: 0.8011 time 24.04s
Final training  2571/4999 loss: 0.8022 time 24.22s
Final training  2572/4999 loss: 0.8093 time 24.15s
Final training  2573/4999 loss: 0.7799 time 23.89s
Final training  2574/4999 loss: 0.7900 time 24.23s
Final training  2575/4999 loss: 0.8035 time 24.06s
Final training  2576/4999 loss: 0.7907 time 24.01s
Final training  2577/4999 loss: 0.7999 time 24.21s
Final training  2578/4999 loss: 0.8033 time 24.23s
Final training  2579/4999 loss: 0.8240 time 24.28s
Final training  2580/4999 loss: 0.7852 time 23.48s
Final training  2581/4999 loss: 0.7967 time 24.09s
Final training  2582/4999 loss: 0.7966 time 24.00s
Final training  2583/4999 loss: 0.7810 time 23.99s
Final training  2584/4999 loss: 0.7890 time 23.95s
Final training  2585/4999 loss: 0.8029 time 24.19s
Final training  2586/4999 loss: 0.7752 time 24.06s
Final training  2587/4999 loss: 0.7975 time 24.03s
Final training  2588/4999 loss: 0.7853 time 24.16s
Final training  2589/4999 loss: 0.8210 time 23.94s
Final training  2590/4999 loss: 0.7919 time 23.89s
Final training  2591/4999 loss: 0.8264 time 23.55s
Final training  2592/4999 loss: 0.8278 time 24.04s
Final training  2593/4999 loss: 0.8337 time 23.91s
Final training  2594/4999 loss: 0.8126 time 24.06s
Final training  2595/4999 loss: 0.7818 time 24.14s
Final training  2596/4999 loss: 0.7792 time 23.63s
Final training  2597/4999 loss: 0.8131 time 23.78s
Final training  2598/4999 loss: 0.8135 time 23.63s
Final training  2599/4999 loss: 0.8042 time 24.05s
Dice accuracy for each class:  (tensor([0.9927, 0.9213, 0.9406, 0.9407, 0.7789, 0.7185, 0.8245, 0.7870, 0.9065,
        0.8344, 0.7442, 0.7876, 0.6469, 0.5725], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2599/4999 acc [ 0.814] time 121.11s
trigger times: 8
Final training  2600/4999 loss: 0.8202 time 24.22s
Final training  2601/4999 loss: 0.7914 time 24.15s
Final training  2602/4999 loss: 0.7973 time 24.34s
Final training  2603/4999 loss: 0.7957 time 24.09s
Final training  2604/4999 loss: 0.7998 time 24.17s
Final training  2605/4999 loss: 0.8062 time 24.05s
Final training  2606/4999 loss: 0.7734 time 23.84s
Final training  2607/4999 loss: 0.7843 time 24.18s
Final training  2608/4999 loss: 0.7892 time 23.73s
Final training  2609/4999 loss: 0.7989 time 24.07s
Final training  2610/4999 loss: 0.7924 time 23.93s
Final training  2611/4999 loss: 0.7890 time 24.28s
Final training  2612/4999 loss: 0.7901 time 24.19s
Final training  2613/4999 loss: 0.7923 time 23.94s
Final training  2614/4999 loss: 0.7919 time 24.18s
Final training  2615/4999 loss: 0.8166 time 24.15s
Final training  2616/4999 loss: 0.8103 time 24.18s
Final training  2617/4999 loss: 0.8125 time 24.26s
Final training  2618/4999 loss: 0.7889 time 24.10s
Final training  2619/4999 loss: 0.8115 time 24.18s
Final training  2620/4999 loss: 0.8225 time 24.09s
Final training  2621/4999 loss: 0.8112 time 24.05s
Final training  2622/4999 loss: 0.8014 time 24.06s
Final training  2623/4999 loss: 0.8114 time 24.07s
Final training  2624/4999 loss: 0.7998 time 24.15s
Final training  2625/4999 loss: 0.7708 time 24.19s
Final training  2626/4999 loss: 0.7730 time 24.11s
Final training  2627/4999 loss: 0.7759 time 23.93s
Final training  2628/4999 loss: 0.7944 time 24.10s
Final training  2629/4999 loss: 0.8178 time 24.16s
Final training  2630/4999 loss: 0.7975 time 24.17s
Final training  2631/4999 loss: 0.7940 time 24.31s
Final training  2632/4999 loss: 0.7875 time 24.24s
Final training  2633/4999 loss: 0.7943 time 24.41s
Final training  2634/4999 loss: 0.7960 time 24.16s
Final training  2635/4999 loss: 0.8146 time 23.95s
Final training  2636/4999 loss: 0.8078 time 24.25s
Final training  2637/4999 loss: 0.7802 time 24.10s
Final training  2638/4999 loss: 0.8106 time 24.03s
Final training  2639/4999 loss: 0.8018 time 23.63s
Final training  2640/4999 loss: 0.7840 time 24.07s
Final training  2641/4999 loss: 0.8073 time 24.06s
Final training  2642/4999 loss: 0.7882 time 24.10s
Final training  2643/4999 loss: 0.7809 time 24.18s
Final training  2644/4999 loss: 0.8013 time 24.22s
Final training  2645/4999 loss: 0.7838 time 24.09s
Final training  2646/4999 loss: 0.7857 time 23.86s
Final training  2647/4999 loss: 0.7889 time 24.30s
Final training  2648/4999 loss: 0.7796 time 23.94s
Final training  2649/4999 loss: 0.7966 time 23.99s
Final training  2650/4999 loss: 0.7838 time 24.14s
Final training  2651/4999 loss: 0.8189 time 23.98s
Final training  2652/4999 loss: 0.7761 time 23.29s
Final training  2653/4999 loss: 0.8005 time 23.86s
Final training  2654/4999 loss: 0.7746 time 24.31s
Final training  2655/4999 loss: 0.7876 time 24.67s
Final training  2656/4999 loss: 0.7969 time 24.48s
Final training  2657/4999 loss: 0.7847 time 24.32s
Final training  2658/4999 loss: 0.8113 time 24.12s
Final training  2659/4999 loss: 0.7857 time 24.12s
Final training  2660/4999 loss: 0.8002 time 24.15s
Final training  2661/4999 loss: 0.8244 time 24.46s
Final training  2662/4999 loss: 0.8327 time 24.08s
Final training  2663/4999 loss: 0.8149 time 24.48s
Final training  2664/4999 loss: 0.8135 time 24.42s
Final training  2665/4999 loss: 0.8368 time 24.42s
Final training  2666/4999 loss: 0.8044 time 24.72s
Final training  2667/4999 loss: 0.7990 time 24.53s
Final training  2668/4999 loss: 0.7715 time 24.51s
Final training  2669/4999 loss: 0.7788 time 24.35s
Final training  2670/4999 loss: 0.8176 time 24.66s
Final training  2671/4999 loss: 0.7910 time 25.00s
Final training  2672/4999 loss: 0.7928 time 24.57s
Final training  2673/4999 loss: 0.7928 time 24.53s
Final training  2674/4999 loss: 0.8097 time 24.54s
Final training  2675/4999 loss: 0.8034 time 24.42s
Final training  2676/4999 loss: 0.8056 time 24.47s
Final training  2677/4999 loss: 0.8024 time 24.45s
Final training  2678/4999 loss: 0.8024 time 24.60s
Final training  2679/4999 loss: 0.7995 time 24.74s
Final training  2680/4999 loss: 0.8050 time 24.70s
Final training  2681/4999 loss: 0.7838 time 24.64s
Final training  2682/4999 loss: 0.7886 time 24.48s
Final training  2683/4999 loss: 0.7962 time 24.52s
Final training  2684/4999 loss: 0.8115 time 24.38s
Final training  2685/4999 loss: 0.7667 time 24.14s
Final training  2686/4999 loss: 0.8086 time 24.27s
Final training  2687/4999 loss: 0.8005 time 24.06s
Final training  2688/4999 loss: 0.7971 time 24.13s
Final training  2689/4999 loss: 0.8004 time 24.17s
Final training  2690/4999 loss: 0.7817 time 24.07s
Final training  2691/4999 loss: 0.7921 time 24.28s
Final training  2692/4999 loss: 0.8019 time 24.26s
Final training  2693/4999 loss: 0.7689 time 24.30s
Final training  2694/4999 loss: 0.7821 time 24.08s
Final training  2695/4999 loss: 0.8068 time 24.14s
Final training  2696/4999 loss: 0.7905 time 24.02s
Final training  2697/4999 loss: 0.7923 time 24.24s
Final training  2698/4999 loss: 0.7847 time 24.06s
Final training  2699/4999 loss: 0.7922 time 24.21s
Dice accuracy for each class:  (tensor([0.9955, 0.9068, 0.9349, 0.9368, 0.7863, 0.7311, 0.8970, 0.8117, 0.9040,
        0.8424, 0.7501, 0.7878, 0.6647, 0.6155], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2699/4999 acc [ 0.826] time 119.74s
Reset trigger time to 0
new best (0.816426 --> 0.826444). 
Saving checkpoint /data/vision_group/medical/btcv/results_tsm/0model_lastsaved_fold0.pt
Copying to model.pt new best model!!!!
Final training  2700/4999 loss: 0.8067 time 24.30s
Final training  2701/4999 loss: 0.7983 time 24.17s
Final training  2702/4999 loss: 0.7893 time 24.18s
Final training  2703/4999 loss: 0.7912 time 23.63s
Final training  2704/4999 loss: 0.7970 time 23.60s
Final training  2705/4999 loss: 0.7960 time 23.98s
Final training  2706/4999 loss: 0.8248 time 23.58s
Final training  2707/4999 loss: 0.7871 time 23.96s
Final training  2708/4999 loss: 0.8077 time 24.17s
Final training  2709/4999 loss: 0.8320 time 24.10s
Final training  2710/4999 loss: 0.7880 time 23.94s
Final training  2711/4999 loss: 0.7893 time 24.03s
Final training  2712/4999 loss: 0.7979 time 23.93s
Final training  2713/4999 loss: 0.7897 time 23.80s
Final training  2714/4999 loss: 0.7797 time 24.01s
Final training  2715/4999 loss: 0.7865 time 23.57s
Final training  2716/4999 loss: 0.7868 time 24.46s
Final training  2717/4999 loss: 0.7945 time 24.16s
Final training  2718/4999 loss: 0.7869 time 24.06s
Final training  2719/4999 loss: 0.7886 time 23.89s
Final training  2720/4999 loss: 0.7953 time 24.03s
Final training  2721/4999 loss: 0.7483 time 24.10s
Final training  2722/4999 loss: 0.7841 time 23.89s
Final training  2723/4999 loss: 0.8124 time 23.87s
Final training  2724/4999 loss: 0.7750 time 23.94s
Final training  2725/4999 loss: 0.8112 time 24.16s
Final training  2726/4999 loss: 0.7990 time 24.31s
Final training  2727/4999 loss: 0.7982 time 24.22s
Final training  2728/4999 loss: 0.8022 time 23.95s
Final training  2729/4999 loss: 0.8254 time 24.11s
Final training  2730/4999 loss: 0.8205 time 24.32s
Final training  2731/4999 loss: 0.8029 time 24.20s
Final training  2732/4999 loss: 0.8086 time 23.87s
Final training  2733/4999 loss: 0.8305 time 23.92s
Final training  2734/4999 loss: 0.7745 time 24.26s
Final training  2735/4999 loss: 0.7795 time 24.25s
Final training  2736/4999 loss: 0.7638 time 24.36s
Final training  2737/4999 loss: 0.7990 time 24.11s
Final training  2738/4999 loss: 0.8144 time 24.38s
Final training  2739/4999 loss: 0.7721 time 24.06s
Final training  2740/4999 loss: 0.7947 time 24.42s
Final training  2741/4999 loss: 0.7901 time 24.34s
Final training  2742/4999 loss: 0.7675 time 24.20s
Final training  2743/4999 loss: 0.7969 time 24.16s
Final training  2744/4999 loss: 0.7925 time 23.81s
Final training  2745/4999 loss: 0.8120 time 23.96s
Final training  2746/4999 loss: 0.7981 time 24.00s
Final training  2747/4999 loss: 0.8041 time 23.86s
Final training  2748/4999 loss: 0.8017 time 23.97s
Final training  2749/4999 loss: 0.7925 time 23.88s
Final training  2750/4999 loss: 0.7841 time 23.88s
Final training  2751/4999 loss: 0.7869 time 24.35s
Final training  2752/4999 loss: 0.7984 time 24.12s
Final training  2753/4999 loss: 0.8046 time 23.85s
Final training  2754/4999 loss: 0.8002 time 24.19s
Final training  2755/4999 loss: 0.8048 time 24.07s
Final training  2756/4999 loss: 0.8004 time 24.13s
Final training  2757/4999 loss: 0.7935 time 24.08s
Final training  2758/4999 loss: 0.7807 time 23.73s
Final training  2759/4999 loss: 0.7689 time 23.89s
Final training  2760/4999 loss: 0.7741 time 24.07s
Final training  2761/4999 loss: 0.7771 time 24.01s
Final training  2762/4999 loss: 0.7769 time 23.88s
Final training  2763/4999 loss: 0.7961 time 24.19s
Final training  2764/4999 loss: 0.8151 time 24.07s
Final training  2765/4999 loss: 0.8298 time 23.93s
Final training  2766/4999 loss: 0.8035 time 24.10s
Final training  2767/4999 loss: 0.8098 time 24.07s
Final training  2768/4999 loss: 0.8230 time 24.11s
Final training  2769/4999 loss: 0.7745 time 23.99s
Final training  2770/4999 loss: 0.8106 time 24.02s
Final training  2771/4999 loss: 0.7817 time 24.30s
Final training  2772/4999 loss: 0.7750 time 24.20s
Final training  2773/4999 loss: 0.7953 time 23.97s
Final training  2774/4999 loss: 0.7758 time 24.14s
Final training  2775/4999 loss: 0.8013 time 24.25s
Final training  2776/4999 loss: 0.7952 time 23.95s
Final training  2777/4999 loss: 0.8001 time 24.13s
Final training  2778/4999 loss: 0.7919 time 23.92s
Final training  2779/4999 loss: 0.7871 time 24.10s
Final training  2780/4999 loss: 0.8012 time 24.54s
Final training  2781/4999 loss: 0.7760 time 24.28s
Final training  2782/4999 loss: 0.8084 time 24.20s
Final training  2783/4999 loss: 0.7807 time 23.92s
Final training  2784/4999 loss: 0.7948 time 24.30s
Final training  2785/4999 loss: 0.7993 time 24.20s
Final training  2786/4999 loss: 0.8149 time 24.14s
Final training  2787/4999 loss: 0.7663 time 24.38s
Final training  2788/4999 loss: 0.7874 time 24.33s
Final training  2789/4999 loss: 0.8070 time 24.17s
Final training  2790/4999 loss: 0.7677 time 24.05s
Final training  2791/4999 loss: 0.7979 time 24.04s
Final training  2792/4999 loss: 0.7822 time 23.87s
Final training  2793/4999 loss: 0.7509 time 24.15s
Final training  2794/4999 loss: 0.7908 time 24.12s
Final training  2795/4999 loss: 0.8114 time 24.19s
Final training  2796/4999 loss: 0.7981 time 24.02s
Final training  2797/4999 loss: 0.7833 time 23.91s
Final training  2798/4999 loss: 0.8025 time 24.22s
Final training  2799/4999 loss: 0.8114 time 24.13s
Dice accuracy for each class:  (tensor([0.9931, 0.9225, 0.9421, 0.9420, 0.7690, 0.7180, 0.8308, 0.8069, 0.9065,
        0.8454, 0.7518, 0.8075, 0.6439, 0.5955], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2799/4999 acc [ 0.820] time 121.39s
trigger times: 1
Final training  2800/4999 loss: 0.7830 time 23.85s
Final training  2801/4999 loss: 0.8054 time 23.84s
Final training  2802/4999 loss: 0.8007 time 23.59s
Final training  2803/4999 loss: 0.7958 time 23.99s
Final training  2804/4999 loss: 0.7906 time 24.20s
Final training  2805/4999 loss: 0.8246 time 23.77s
Final training  2806/4999 loss: 0.7872 time 24.15s
Final training  2807/4999 loss: 0.7943 time 23.73s
Final training  2808/4999 loss: 0.7813 time 24.08s
Final training  2809/4999 loss: 0.7878 time 24.07s
Final training  2810/4999 loss: 0.7819 time 23.98s
Final training  2811/4999 loss: 0.7802 time 24.26s
Final training  2812/4999 loss: 0.7830 time 23.97s
Final training  2813/4999 loss: 0.7813 time 24.02s
Final training  2814/4999 loss: 0.8041 time 24.10s
Final training  2815/4999 loss: 0.7759 time 24.03s
Final training  2816/4999 loss: 0.8005 time 24.00s
Final training  2817/4999 loss: 0.7926 time 24.22s
Final training  2818/4999 loss: 0.7877 time 23.99s
Final training  2819/4999 loss: 0.7821 time 24.14s
Final training  2820/4999 loss: 0.8006 time 24.10s
Final training  2821/4999 loss: 0.7765 time 24.02s
Final training  2822/4999 loss: 0.7901 time 24.04s
Final training  2823/4999 loss: 0.8042 time 24.24s
Final training  2824/4999 loss: 0.7988 time 24.06s
Final training  2825/4999 loss: 0.7692 time 23.89s
Final training  2826/4999 loss: 0.7992 time 23.91s
Final training  2827/4999 loss: 0.7926 time 24.24s
Final training  2828/4999 loss: 0.7899 time 24.01s
Final training  2829/4999 loss: 0.8179 time 24.19s
Final training  2830/4999 loss: 0.8028 time 24.08s
Final training  2831/4999 loss: 0.7767 time 24.26s
Final training  2832/4999 loss: 0.7798 time 24.03s
Final training  2833/4999 loss: 0.8056 time 24.10s
Final training  2834/4999 loss: 0.7964 time 23.96s
Final training  2835/4999 loss: 0.7714 time 23.88s
Final training  2836/4999 loss: 0.7999 time 23.99s
Final training  2837/4999 loss: 0.7900 time 24.46s
Final training  2838/4999 loss: 0.7750 time 24.58s
Final training  2839/4999 loss: 0.7811 time 24.21s
Final training  2840/4999 loss: 0.8002 time 24.05s
Final training  2841/4999 loss: 0.7829 time 24.62s
Final training  2842/4999 loss: 0.7975 time 24.90s
Final training  2843/4999 loss: 0.7655 time 24.34s
Final training  2844/4999 loss: 0.7972 time 24.50s
Final training  2845/4999 loss: 0.8126 time 24.52s
Final training  2846/4999 loss: 0.7875 time 24.46s
Final training  2847/4999 loss: 0.8191 time 24.33s
Final training  2848/4999 loss: 0.7818 time 24.58s
Final training  2849/4999 loss: 0.8106 time 24.78s
Final training  2850/4999 loss: 0.8088 time 24.62s
Final training  2851/4999 loss: 0.7969 time 24.39s
Final training  2852/4999 loss: 0.7986 time 24.50s
Final training  2853/4999 loss: 0.8011 time 24.33s
Final training  2854/4999 loss: 0.7990 time 24.61s
Final training  2855/4999 loss: 0.7899 time 24.58s
Final training  2856/4999 loss: 0.7860 time 24.19s
Final training  2857/4999 loss: 0.7956 time 23.96s
Final training  2858/4999 loss: 0.7906 time 24.07s
Final training  2859/4999 loss: 0.7795 time 23.90s
Final training  2860/4999 loss: 0.7985 time 23.99s
Final training  2861/4999 loss: 0.8047 time 24.06s
Final training  2862/4999 loss: 0.7960 time 23.94s
Final training  2863/4999 loss: 0.7792 time 24.14s
Final training  2864/4999 loss: 0.7806 time 24.18s
Final training  2865/4999 loss: 0.7801 time 24.14s
Final training  2866/4999 loss: 0.7933 time 24.25s
Final training  2867/4999 loss: 0.7918 time 24.14s
Final training  2868/4999 loss: 0.7893 time 24.25s
Final training  2869/4999 loss: 0.8124 time 24.23s
Final training  2870/4999 loss: 0.7825 time 24.01s
Final training  2871/4999 loss: 0.8067 time 24.36s
Final training  2872/4999 loss: 0.7853 time 24.18s
Final training  2873/4999 loss: 0.7811 time 24.23s
Final training  2874/4999 loss: 0.7826 time 24.44s
Final training  2875/4999 loss: 0.7906 time 24.46s
Final training  2876/4999 loss: 0.7813 time 24.46s
Final training  2877/4999 loss: 0.7810 time 24.35s
Final training  2878/4999 loss: 0.7861 time 24.54s
Final training  2879/4999 loss: 0.7866 time 24.82s
Final training  2880/4999 loss: 0.7775 time 24.68s
Final training  2881/4999 loss: 0.7789 time 24.94s
Final training  2882/4999 loss: 0.7912 time 24.72s
Final training  2883/4999 loss: 0.7736 time 24.71s
Final training  2884/4999 loss: 0.7777 time 24.81s
Final training  2885/4999 loss: 0.7954 time 24.76s
Final training  2886/4999 loss: 0.7834 time 24.30s
Final training  2887/4999 loss: 0.7882 time 24.73s
Final training  2888/4999 loss: 0.8028 time 24.70s
Final training  2889/4999 loss: 0.8035 time 24.97s
Final training  2890/4999 loss: 0.7852 time 24.88s
Final training  2891/4999 loss: 0.7825 time 24.88s
Final training  2892/4999 loss: 0.7799 time 24.93s
Final training  2893/4999 loss: 0.8190 time 24.99s
Final training  2894/4999 loss: 0.7934 time 24.49s
Final training  2895/4999 loss: 0.7861 time 24.59s
Final training  2896/4999 loss: 0.7990 time 24.76s
Final training  2897/4999 loss: 0.8093 time 24.53s
Final training  2898/4999 loss: 0.7878 time 24.58s
Final training  2899/4999 loss: 0.8218 time 24.10s
Dice accuracy for each class:  (tensor([0.9948, 0.9343, 0.9333, 0.9400, 0.7521, 0.7183, 0.8865, 0.7402, 0.9045,
        0.8244, 0.7188, 0.7057, 0.6745, 0.5891], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2899/4999 acc [ 0.809] time 121.45s
trigger times: 2
Final training  2900/4999 loss: 0.7914 time 24.26s
Final training  2901/4999 loss: 0.7873 time 24.45s
Final training  2902/4999 loss: 0.7918 time 25.00s
Final training  2903/4999 loss: 0.8185 time 24.70s
Final training  2904/4999 loss: 0.8051 time 24.29s
Final training  2905/4999 loss: 0.7951 time 24.36s
Final training  2906/4999 loss: 0.7989 time 24.30s
Final training  2907/4999 loss: 0.7933 time 24.28s
Final training  2908/4999 loss: 0.8249 time 24.53s
Final training  2909/4999 loss: 0.8039 time 24.38s
Final training  2910/4999 loss: 0.8031 time 24.27s
Final training  2911/4999 loss: 0.7918 time 24.03s
Final training  2912/4999 loss: 0.7763 time 24.24s
Final training  2913/4999 loss: 0.8006 time 24.68s
Final training  2914/4999 loss: 0.7989 time 24.67s
Final training  2915/4999 loss: 0.7935 time 24.99s
Final training  2916/4999 loss: 0.7911 time 24.60s
Final training  2917/4999 loss: 0.8043 time 24.51s
Final training  2918/4999 loss: 0.7772 time 23.91s
Final training  2919/4999 loss: 0.7922 time 24.19s
Final training  2920/4999 loss: 0.7868 time 24.39s
Final training  2921/4999 loss: 0.7662 time 24.02s
Final training  2922/4999 loss: 0.7845 time 23.96s
Final training  2923/4999 loss: 0.7880 time 24.13s
Final training  2924/4999 loss: 0.7819 time 23.85s
Final training  2925/4999 loss: 0.7883 time 23.98s
Final training  2926/4999 loss: 0.7956 time 24.05s
Final training  2927/4999 loss: 0.7955 time 24.22s
Final training  2928/4999 loss: 0.7858 time 24.07s
Final training  2929/4999 loss: 0.7728 time 24.19s
Final training  2930/4999 loss: 0.7876 time 24.15s
Final training  2931/4999 loss: 0.7805 time 24.18s
Final training  2932/4999 loss: 0.8163 time 24.05s
Final training  2933/4999 loss: 0.8002 time 24.19s
Final training  2934/4999 loss: 0.7871 time 24.32s
Final training  2935/4999 loss: 0.8081 time 24.42s
Final training  2936/4999 loss: 0.7857 time 24.23s
Final training  2937/4999 loss: 0.8050 time 24.18s
Final training  2938/4999 loss: 0.7911 time 24.06s
Final training  2939/4999 loss: 0.7732 time 23.95s
Final training  2940/4999 loss: 0.7967 time 24.07s
Final training  2941/4999 loss: 0.8156 time 24.04s
Final training  2942/4999 loss: 0.8071 time 23.91s
Final training  2943/4999 loss: 0.7890 time 23.99s
Final training  2944/4999 loss: 0.7849 time 23.93s
Final training  2945/4999 loss: 0.7864 time 24.05s
Final training  2946/4999 loss: 0.7970 time 24.02s
Final training  2947/4999 loss: 0.7870 time 24.09s
Final training  2948/4999 loss: 0.7914 time 24.30s
Final training  2949/4999 loss: 0.7881 time 24.15s
Final training  2950/4999 loss: 0.7924 time 23.98s
Final training  2951/4999 loss: 0.8170 time 24.01s
Final training  2952/4999 loss: 0.7949 time 23.54s
Final training  2953/4999 loss: 0.7990 time 23.86s
Final training  2954/4999 loss: 0.7897 time 23.81s
Final training  2955/4999 loss: 0.7824 time 24.09s
Final training  2956/4999 loss: 0.8081 time 24.10s
Final training  2957/4999 loss: 0.7933 time 23.98s
Final training  2958/4999 loss: 0.7994 time 24.06s
Final training  2959/4999 loss: 0.8039 time 24.06s
Final training  2960/4999 loss: 0.8032 time 24.07s
Final training  2961/4999 loss: 0.7928 time 24.23s
Final training  2962/4999 loss: 0.7987 time 24.03s
Final training  2963/4999 loss: 0.7924 time 24.17s
Final training  2964/4999 loss: 0.7706 time 24.01s
Final training  2965/4999 loss: 0.7791 time 24.47s
Final training  2966/4999 loss: 0.7718 time 24.37s
Final training  2967/4999 loss: 0.8040 time 24.08s
Final training  2968/4999 loss: 0.7752 time 23.91s
Final training  2969/4999 loss: 0.7786 time 24.03s
Final training  2970/4999 loss: 0.7807 time 24.37s
Final training  2971/4999 loss: 0.7886 time 24.38s
Final training  2972/4999 loss: 0.7850 time 24.28s
Final training  2973/4999 loss: 0.7970 time 24.53s
Final training  2974/4999 loss: 0.7949 time 24.20s
Final training  2975/4999 loss: 0.7894 time 24.59s
Final training  2976/4999 loss: 0.8029 time 24.48s
Final training  2977/4999 loss: 0.7815 time 23.65s
Final training  2978/4999 loss: 0.8038 time 24.45s
Final training  2979/4999 loss: 0.7864 time 24.40s
Final training  2980/4999 loss: 0.7678 time 24.59s
Final training  2981/4999 loss: 0.7681 time 24.47s
Final training  2982/4999 loss: 0.8044 time 24.42s
Final training  2983/4999 loss: 0.7878 time 24.33s
Final training  2984/4999 loss: 0.8052 time 24.45s
Final training  2985/4999 loss: 0.8052 time 24.35s
Final training  2986/4999 loss: 0.7919 time 24.36s
Final training  2987/4999 loss: 0.8013 time 24.35s
Final training  2988/4999 loss: 0.7873 time 24.57s
Final training  2989/4999 loss: 0.7788 time 24.18s
Final training  2990/4999 loss: 0.7787 time 24.34s
Final training  2991/4999 loss: 0.8084 time 24.32s
Final training  2992/4999 loss: 0.8139 time 24.37s
Final training  2993/4999 loss: 0.8044 time 24.13s
Final training  2994/4999 loss: 0.7860 time 23.92s
Final training  2995/4999 loss: 0.7844 time 24.45s
Final training  2996/4999 loss: 0.7995 time 24.20s
Final training  2997/4999 loss: 0.7918 time 24.01s
Final training  2998/4999 loss: 0.8161 time 24.62s
Final training  2999/4999 loss: 0.7785 time 24.28s
Dice accuracy for each class:  (tensor([0.9942, 0.8949, 0.9380, 0.9408, 0.7545, 0.7178, 0.8631, 0.7964, 0.9065,
        0.8445, 0.7495, 0.7741, 0.6447, 0.5892], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  2999/4999 acc [ 0.815] time 118.76s
trigger times: 3
Final training  3000/4999 loss: 0.7936 time 24.13s
Final training  3001/4999 loss: 0.7810 time 23.86s
Final training  3002/4999 loss: 0.8137 time 23.97s
Final training  3003/4999 loss: 0.7840 time 24.32s
Final training  3004/4999 loss: 0.7852 time 24.25s
Final training  3005/4999 loss: 0.7845 time 24.41s
Final training  3006/4999 loss: 0.8010 time 24.35s
Final training  3007/4999 loss: 0.7931 time 24.33s
Final training  3008/4999 loss: 0.8047 time 24.19s
Final training  3009/4999 loss: 0.7923 time 24.73s
Final training  3010/4999 loss: 0.8000 time 24.30s
Final training  3011/4999 loss: 0.7712 time 23.82s
Final training  3012/4999 loss: 0.8185 time 24.07s
Final training  3013/4999 loss: 0.8397 time 24.52s
Final training  3014/4999 loss: 0.7943 time 24.80s
Final training  3015/4999 loss: 0.7798 time 24.63s
Final training  3016/4999 loss: 0.7774 time 24.50s
Final training  3017/4999 loss: 0.7886 time 24.46s
Final training  3018/4999 loss: 0.7813 time 24.65s
Final training  3019/4999 loss: 0.8096 time 24.17s
Final training  3020/4999 loss: 0.7663 time 24.34s
Final training  3021/4999 loss: 0.7634 time 23.95s
Final training  3022/4999 loss: 0.8199 time 24.19s
Final training  3023/4999 loss: 0.7833 time 24.57s
Final training  3024/4999 loss: 0.7913 time 24.36s
Final training  3025/4999 loss: 0.7660 time 24.40s
Final training  3026/4999 loss: 0.7895 time 24.42s
Final training  3027/4999 loss: 0.8304 time 24.31s
Final training  3028/4999 loss: 0.7623 time 24.62s
Final training  3029/4999 loss: 0.7979 time 24.49s
Final training  3030/4999 loss: 0.8002 time 24.46s
Final training  3031/4999 loss: 0.7900 time 24.23s
Final training  3032/4999 loss: 0.7885 time 24.27s
Final training  3033/4999 loss: 0.8150 time 24.18s
Final training  3034/4999 loss: 0.8088 time 24.27s
Final training  3035/4999 loss: 0.8139 time 24.10s
Final training  3036/4999 loss: 0.8036 time 24.17s
Final training  3037/4999 loss: 0.8291 time 23.95s
Final training  3038/4999 loss: 0.8029 time 24.22s
Final training  3039/4999 loss: 0.8047 time 24.38s
Final training  3040/4999 loss: 0.8013 time 24.00s
Final training  3041/4999 loss: 0.8016 time 24.30s
Final training  3042/4999 loss: 0.8021 time 24.41s
Final training  3043/4999 loss: 0.7656 time 24.06s
Final training  3044/4999 loss: 0.8235 time 24.06s
Final training  3045/4999 loss: 0.8039 time 24.08s
Final training  3046/4999 loss: 0.7741 time 24.15s
Final training  3047/4999 loss: 0.7822 time 24.31s
Final training  3048/4999 loss: 0.7881 time 24.01s
Final training  3049/4999 loss: 0.7724 time 24.04s
Final training  3050/4999 loss: 0.7937 time 24.15s
Final training  3051/4999 loss: 0.7755 time 24.14s
Final training  3052/4999 loss: 0.7938 time 24.07s
Final training  3053/4999 loss: 0.7739 time 24.12s
Final training  3054/4999 loss: 0.7759 time 24.08s
Final training  3055/4999 loss: 0.7964 time 24.02s
Final training  3056/4999 loss: 0.7861 time 23.99s
Final training  3057/4999 loss: 0.7859 time 24.06s
Final training  3058/4999 loss: 0.8083 time 23.90s
Final training  3059/4999 loss: 0.7882 time 24.11s
Final training  3060/4999 loss: 0.7808 time 24.12s
Final training  3061/4999 loss: 0.7997 time 24.25s
Final training  3062/4999 loss: 0.7695 time 23.98s
Final training  3063/4999 loss: 0.7762 time 24.04s
Final training  3064/4999 loss: 0.7829 time 24.08s
Final training  3065/4999 loss: 0.7787 time 24.13s
Final training  3066/4999 loss: 0.7952 time 24.12s
Final training  3067/4999 loss: 0.8001 time 24.26s
Final training  3068/4999 loss: 0.7858 time 24.27s
Final training  3069/4999 loss: 0.7854 time 24.24s
Final training  3070/4999 loss: 0.7792 time 24.09s
Final training  3071/4999 loss: 0.7918 time 24.07s
Final training  3072/4999 loss: 0.7944 time 24.14s
Final training  3073/4999 loss: 0.7932 time 24.44s
Final training  3074/4999 loss: 0.7733 time 24.46s
Final training  3075/4999 loss: 0.7809 time 24.47s
Final training  3076/4999 loss: 0.7635 time 24.34s
Final training  3077/4999 loss: 0.7953 time 24.68s
Final training  3078/4999 loss: 0.7929 time 24.75s
Final training  3079/4999 loss: 0.7959 time 24.54s
Final training  3080/4999 loss: 0.7834 time 24.17s
Final training  3081/4999 loss: 0.7793 time 24.07s
Final training  3082/4999 loss: 0.7574 time 24.14s
Final training  3083/4999 loss: 0.7639 time 24.01s
Final training  3084/4999 loss: 0.7817 time 23.96s
Final training  3085/4999 loss: 0.7785 time 24.06s
Final training  3086/4999 loss: 0.8193 time 24.12s
Final training  3087/4999 loss: 0.7983 time 23.99s
Final training  3088/4999 loss: 0.7725 time 23.94s
Final training  3089/4999 loss: 0.7707 time 24.22s
Final training  3090/4999 loss: 0.7862 time 24.04s
Final training  3091/4999 loss: 0.8052 time 24.26s
Final training  3092/4999 loss: 0.7910 time 23.85s
Final training  3093/4999 loss: 0.8097 time 23.87s
Final training  3094/4999 loss: 0.8119 time 24.05s
Final training  3095/4999 loss: 0.7813 time 24.27s
Final training  3096/4999 loss: 0.7988 time 24.01s
Final training  3097/4999 loss: 0.8001 time 24.09s
Final training  3098/4999 loss: 0.7638 time 23.83s
Final training  3099/4999 loss: 0.7873 time 24.19s
Dice accuracy for each class:  (tensor([0.9934, 0.9150, 0.9413, 0.9412, 0.7850, 0.7086, 0.8377, 0.7854, 0.9102,
        0.8401, 0.7467, 0.7773, 0.6564, 0.6110], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3099/4999 acc [ 0.818] time 120.82s
trigger times: 4
Final training  3100/4999 loss: 0.7660 time 24.32s
Final training  3101/4999 loss: 0.7780 time 24.20s
Final training  3102/4999 loss: 0.8200 time 24.26s
Final training  3103/4999 loss: 0.7813 time 24.37s
Final training  3104/4999 loss: 0.7791 time 24.02s
Final training  3105/4999 loss: 0.7846 time 24.09s
Final training  3106/4999 loss: 0.7871 time 24.10s
Final training  3107/4999 loss: 0.8195 time 23.98s
Final training  3108/4999 loss: 0.7800 time 24.18s
Final training  3109/4999 loss: 0.7906 time 24.22s
Final training  3110/4999 loss: 0.8017 time 24.00s
Final training  3111/4999 loss: 0.7870 time 24.34s
Final training  3112/4999 loss: 0.8031 time 24.02s
Final training  3113/4999 loss: 0.7685 time 24.20s
Final training  3114/4999 loss: 0.7902 time 23.95s
Final training  3115/4999 loss: 0.7932 time 23.78s
Final training  3116/4999 loss: 0.7851 time 23.87s
Final training  3117/4999 loss: 0.7946 time 24.06s
Final training  3118/4999 loss: 0.7959 time 24.17s
Final training  3119/4999 loss: 0.7963 time 24.39s
Final training  3120/4999 loss: 0.7920 time 23.93s
Final training  3121/4999 loss: 0.7751 time 23.92s
Final training  3122/4999 loss: 0.7956 time 24.23s
Final training  3123/4999 loss: 0.7708 time 23.80s
Final training  3124/4999 loss: 0.7795 time 24.18s
Final training  3125/4999 loss: 0.8020 time 24.04s
Final training  3126/4999 loss: 0.7864 time 23.81s
Final training  3127/4999 loss: 0.8009 time 24.20s
Final training  3128/4999 loss: 0.7925 time 23.93s
Final training  3129/4999 loss: 0.7979 time 24.00s
Final training  3130/4999 loss: 0.7913 time 24.00s
Final training  3131/4999 loss: 0.7851 time 24.16s
Final training  3132/4999 loss: 0.7876 time 24.19s
Final training  3133/4999 loss: 0.7868 time 24.06s
Final training  3134/4999 loss: 0.7818 time 24.06s
Final training  3135/4999 loss: 0.7835 time 24.10s
Final training  3136/4999 loss: 0.7925 time 24.47s
Final training  3137/4999 loss: 0.7642 time 24.40s
Final training  3138/4999 loss: 0.8061 time 24.30s
Final training  3139/4999 loss: 0.7674 time 24.30s
Final training  3140/4999 loss: 0.7860 time 24.40s
Final training  3141/4999 loss: 0.7877 time 24.65s
Final training  3142/4999 loss: 0.7750 time 24.35s
Final training  3143/4999 loss: 0.8154 time 24.61s
Final training  3144/4999 loss: 0.8032 time 24.54s
Final training  3145/4999 loss: 0.7960 time 24.50s
Final training  3146/4999 loss: 0.7982 time 24.80s
Final training  3147/4999 loss: 0.7924 time 24.61s
Final training  3148/4999 loss: 0.7671 time 24.41s
Final training  3149/4999 loss: 0.7969 time 24.49s
Final training  3150/4999 loss: 0.8005 time 24.15s
Final training  3151/4999 loss: 0.7847 time 24.42s
Final training  3152/4999 loss: 0.7834 time 24.39s
Final training  3153/4999 loss: 0.7875 time 24.22s
Final training  3154/4999 loss: 0.7947 time 24.84s
Final training  3155/4999 loss: 0.7759 time 24.78s
Final training  3156/4999 loss: 0.7994 time 24.81s
Final training  3157/4999 loss: 0.7618 time 24.80s
Final training  3158/4999 loss: 0.8049 time 25.20s
Final training  3159/4999 loss: 0.7814 time 24.25s
Final training  3160/4999 loss: 0.7704 time 24.30s
Final training  3161/4999 loss: 0.7945 time 24.23s
Final training  3162/4999 loss: 0.7919 time 23.90s
Final training  3163/4999 loss: 0.7809 time 23.78s
Final training  3164/4999 loss: 0.8252 time 24.11s
Final training  3165/4999 loss: 0.7982 time 24.18s
Final training  3166/4999 loss: 0.7995 time 24.04s
Final training  3167/4999 loss: 0.7908 time 24.15s
Final training  3168/4999 loss: 0.7601 time 23.79s
Final training  3169/4999 loss: 0.7801 time 24.37s
Final training  3170/4999 loss: 0.7955 time 24.09s
Final training  3171/4999 loss: 0.7705 time 24.07s
Final training  3172/4999 loss: 0.7835 time 24.35s
Final training  3173/4999 loss: 0.8072 time 24.47s
Final training  3174/4999 loss: 0.8176 time 24.22s
Final training  3175/4999 loss: 0.7914 time 24.02s
Final training  3176/4999 loss: 0.7651 time 24.03s
Final training  3177/4999 loss: 0.7930 time 24.01s
Final training  3178/4999 loss: 0.8144 time 24.07s
Final training  3179/4999 loss: 0.7756 time 24.23s
Final training  3180/4999 loss: 0.7727 time 23.99s
Final training  3181/4999 loss: 0.8053 time 24.27s
Final training  3182/4999 loss: 0.7912 time 23.83s
Final training  3183/4999 loss: 0.7822 time 24.14s
Final training  3184/4999 loss: 0.7684 time 24.10s
Final training  3185/4999 loss: 0.7883 time 24.50s
Final training  3186/4999 loss: 0.7909 time 24.42s
Final training  3187/4999 loss: 0.7814 time 24.38s
Final training  3188/4999 loss: 0.7648 time 24.15s
Final training  3189/4999 loss: 0.8069 time 24.19s
Final training  3190/4999 loss: 0.7668 time 24.29s
Final training  3191/4999 loss: 0.8085 time 24.21s
Final training  3192/4999 loss: 0.7891 time 24.02s
Final training  3193/4999 loss: 0.8077 time 23.99s
Final training  3194/4999 loss: 0.7735 time 24.08s
Final training  3195/4999 loss: 0.7710 time 24.08s
Final training  3196/4999 loss: 0.7785 time 23.96s
Final training  3197/4999 loss: 0.7876 time 23.98s
Final training  3198/4999 loss: 0.7511 time 23.98s
Final training  3199/4999 loss: 0.7728 time 23.78s
Dice accuracy for each class:  (tensor([0.9925, 0.9383, 0.9432, 0.9434, 0.8001, 0.7439, 0.8164, 0.7799, 0.9045,
        0.8433, 0.7473, 0.7662, 0.6798, 0.6019], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3199/4999 acc [ 0.822] time 120.59s
trigger times: 5
Final training  3200/4999 loss: 0.7891 time 24.12s
Final training  3201/4999 loss: 0.7874 time 23.98s
Final training  3202/4999 loss: 0.7781 time 23.98s
Final training  3203/4999 loss: 0.7950 time 23.92s
Final training  3204/4999 loss: 0.7942 time 24.29s
Final training  3205/4999 loss: 0.8010 time 24.39s
Final training  3206/4999 loss: 0.7784 time 24.33s
Final training  3207/4999 loss: 0.7721 time 24.21s
Final training  3208/4999 loss: 0.7778 time 24.50s
Final training  3209/4999 loss: 0.8000 time 24.19s
Final training  3210/4999 loss: 0.7795 time 24.24s
Final training  3211/4999 loss: 0.7634 time 24.26s
Final training  3212/4999 loss: 0.7775 time 24.24s
Final training  3213/4999 loss: 0.8066 time 24.32s
Final training  3214/4999 loss: 0.7961 time 24.23s
Final training  3215/4999 loss: 0.8031 time 24.30s
Final training  3216/4999 loss: 0.7930 time 24.55s
Final training  3217/4999 loss: 0.7831 time 24.43s
Final training  3218/4999 loss: 0.7954 time 24.24s
Final training  3219/4999 loss: 0.7874 time 24.06s
Final training  3220/4999 loss: 0.7675 time 23.90s
Final training  3221/4999 loss: 0.8016 time 23.76s
Final training  3222/4999 loss: 0.7912 time 23.84s
Final training  3223/4999 loss: 0.7708 time 24.08s
Final training  3224/4999 loss: 0.7816 time 23.92s
Final training  3225/4999 loss: 0.8083 time 23.85s
Final training  3226/4999 loss: 0.7930 time 24.19s
Final training  3227/4999 loss: 0.7671 time 24.19s
Final training  3228/4999 loss: 0.7764 time 23.92s
Final training  3229/4999 loss: 0.7666 time 23.92s
Final training  3230/4999 loss: 0.8027 time 24.08s
Final training  3231/4999 loss: 0.7939 time 24.23s
Final training  3232/4999 loss: 0.7790 time 23.96s
Final training  3233/4999 loss: 0.7963 time 23.91s
Final training  3234/4999 loss: 0.8264 time 23.90s
Final training  3235/4999 loss: 0.8087 time 24.16s
Final training  3236/4999 loss: 0.7837 time 24.13s
Final training  3237/4999 loss: 0.7906 time 23.95s
Final training  3238/4999 loss: 0.8074 time 23.95s
Final training  3239/4999 loss: 0.8067 time 24.00s
Final training  3240/4999 loss: 0.7771 time 23.97s
Final training  3241/4999 loss: 0.7863 time 24.18s
Final training  3242/4999 loss: 0.7813 time 24.06s
Final training  3243/4999 loss: 0.7490 time 24.17s
Final training  3244/4999 loss: 0.7861 time 23.93s
Final training  3245/4999 loss: 0.7412 time 24.20s
Final training  3246/4999 loss: 0.7814 time 24.01s
Final training  3247/4999 loss: 0.7750 time 23.93s
Final training  3248/4999 loss: 0.7904 time 24.03s
Final training  3249/4999 loss: 0.7960 time 24.18s
Final training  3250/4999 loss: 0.8116 time 23.92s
Final training  3251/4999 loss: 0.8311 time 24.11s
Final training  3252/4999 loss: 0.8265 time 24.30s
Final training  3253/4999 loss: 0.8062 time 24.46s
Final training  3254/4999 loss: 0.8020 time 24.21s
Final training  3255/4999 loss: 0.7688 time 24.16s
Final training  3256/4999 loss: 0.7936 time 24.17s
Final training  3257/4999 loss: 0.7940 time 23.84s
Final training  3258/4999 loss: 0.7802 time 24.07s
Final training  3259/4999 loss: 0.7994 time 24.22s
Final training  3260/4999 loss: 0.7674 time 23.98s
Final training  3261/4999 loss: 0.7900 time 23.81s
Final training  3262/4999 loss: 0.8018 time 24.14s
Final training  3263/4999 loss: 0.7888 time 24.03s
Final training  3264/4999 loss: 0.7786 time 23.95s
Final training  3265/4999 loss: 0.7942 time 23.97s
Final training  3266/4999 loss: 0.7552 time 24.16s
Final training  3267/4999 loss: 0.7596 time 24.10s
Final training  3268/4999 loss: 0.7597 time 24.05s
Final training  3269/4999 loss: 0.7639 time 24.42s
Final training  3270/4999 loss: 0.8103 time 24.57s
Final training  3271/4999 loss: 0.7918 time 24.45s
Final training  3272/4999 loss: 0.8071 time 24.52s
Final training  3273/4999 loss: 0.7759 time 24.37s
Final training  3274/4999 loss: 0.8080 time 24.27s
Final training  3275/4999 loss: 0.7867 time 24.14s
Final training  3276/4999 loss: 0.7819 time 24.00s
Final training  3277/4999 loss: 0.7922 time 23.82s
Final training  3278/4999 loss: 0.7927 time 24.07s
Final training  3279/4999 loss: 0.7875 time 24.04s
Final training  3280/4999 loss: 0.7829 time 24.19s
Final training  3281/4999 loss: 0.7944 time 24.53s
Final training  3282/4999 loss: 0.7845 time 24.41s
Final training  3283/4999 loss: 0.7827 time 24.38s
Final training  3284/4999 loss: 0.7643 time 24.19s
Final training  3285/4999 loss: 0.7717 time 24.01s
Final training  3286/4999 loss: 0.7823 time 23.98s
Final training  3287/4999 loss: 0.8031 time 24.38s
Final training  3288/4999 loss: 0.7795 time 24.28s
Final training  3289/4999 loss: 0.7722 time 24.13s
Final training  3290/4999 loss: 0.7695 time 23.94s
Final training  3291/4999 loss: 0.7875 time 24.21s
Final training  3292/4999 loss: 0.7968 time 23.98s
Final training  3293/4999 loss: 0.7841 time 23.94s
Final training  3294/4999 loss: 0.7873 time 23.93s
Final training  3295/4999 loss: 0.7884 time 24.02s
Final training  3296/4999 loss: 0.7946 time 23.91s
Final training  3297/4999 loss: 0.7927 time 24.12s
Final training  3298/4999 loss: 0.7991 time 23.98s
Final training  3299/4999 loss: 0.7623 time 24.11s
Dice accuracy for each class:  (tensor([0.9933, 0.9251, 0.9433, 0.9442, 0.7916, 0.7139, 0.8372, 0.7822, 0.9014,
        0.8551, 0.7445, 0.7775, 0.6667, 0.6209], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3299/4999 acc [ 0.821] time 120.90s
trigger times: 6
Final training  3300/4999 loss: 0.7984 time 24.10s
Final training  3301/4999 loss: 0.7649 time 23.88s
Final training  3302/4999 loss: 0.7844 time 24.18s
Final training  3303/4999 loss: 0.7818 time 24.10s
Final training  3304/4999 loss: 0.7562 time 23.87s
Final training  3305/4999 loss: 0.8018 time 23.91s
Final training  3306/4999 loss: 0.8004 time 24.04s
Final training  3307/4999 loss: 0.7717 time 23.97s
Final training  3308/4999 loss: 0.8095 time 24.01s
Final training  3309/4999 loss: 0.7585 time 24.01s
Final training  3310/4999 loss: 0.7795 time 24.19s
Final training  3311/4999 loss: 0.7865 time 24.02s
Final training  3312/4999 loss: 0.7860 time 24.02s
Final training  3313/4999 loss: 0.7730 time 23.97s
Final training  3314/4999 loss: 0.8171 time 24.08s
Final training  3315/4999 loss: 0.7954 time 23.80s
Final training  3316/4999 loss: 0.7681 time 24.04s
Final training  3317/4999 loss: 0.7884 time 24.18s
Final training  3318/4999 loss: 0.7901 time 24.23s
Final training  3319/4999 loss: 0.7930 time 23.98s
Final training  3320/4999 loss: 0.7782 time 23.96s
Final training  3321/4999 loss: 0.7819 time 24.07s
Final training  3322/4999 loss: 0.7872 time 23.98s
Final training  3323/4999 loss: 0.7765 time 24.12s
Final training  3324/4999 loss: 0.8055 time 23.93s
Final training  3325/4999 loss: 0.7778 time 23.90s
Final training  3326/4999 loss: 0.7898 time 23.86s
Final training  3327/4999 loss: 0.7867 time 24.06s
Final training  3328/4999 loss: 0.7956 time 24.00s
Final training  3329/4999 loss: 0.7900 time 24.04s
Final training  3330/4999 loss: 0.7822 time 24.04s
Final training  3331/4999 loss: 0.8010 time 24.00s
Final training  3332/4999 loss: 0.7816 time 24.21s
Final training  3333/4999 loss: 0.7747 time 24.02s
Final training  3334/4999 loss: 0.7812 time 23.95s
Final training  3335/4999 loss: 0.7966 time 23.95s
Final training  3336/4999 loss: 0.7657 time 24.05s
Final training  3337/4999 loss: 0.7776 time 24.23s
Final training  3338/4999 loss: 0.7900 time 24.01s
Final training  3339/4999 loss: 0.7980 time 23.87s
Final training  3340/4999 loss: 0.8004 time 24.19s
Final training  3341/4999 loss: 0.7867 time 24.02s
Final training  3342/4999 loss: 0.7838 time 24.05s
Final training  3343/4999 loss: 0.7865 time 24.45s
Final training  3344/4999 loss: 0.7687 time 24.33s
Final training  3345/4999 loss: 0.7904 time 23.82s
Final training  3346/4999 loss: 0.7981 time 24.12s
Final training  3347/4999 loss: 0.7798 time 24.03s
Final training  3348/4999 loss: 0.7656 time 24.13s
Final training  3349/4999 loss: 0.7871 time 24.58s
Final training  3350/4999 loss: 0.7843 time 24.54s
Final training  3351/4999 loss: 0.7729 time 24.35s
Final training  3352/4999 loss: 0.7759 time 24.52s
Final training  3353/4999 loss: 0.7679 time 24.16s
Final training  3354/4999 loss: 0.7795 time 23.96s
Final training  3355/4999 loss: 0.8072 time 24.15s
Final training  3356/4999 loss: 0.8127 time 24.09s
Final training  3357/4999 loss: 0.7981 time 24.02s
Final training  3358/4999 loss: 0.8056 time 24.07s
Final training  3359/4999 loss: 0.7796 time 24.12s
Final training  3360/4999 loss: 0.7908 time 24.17s
Final training  3361/4999 loss: 0.7844 time 24.05s
Final training  3362/4999 loss: 0.7981 time 23.90s
Final training  3363/4999 loss: 0.8112 time 24.00s
Final training  3364/4999 loss: 0.7802 time 24.17s
Final training  3365/4999 loss: 0.7937 time 24.18s
Final training  3366/4999 loss: 0.7799 time 24.15s
Final training  3367/4999 loss: 0.7774 time 23.97s
Final training  3368/4999 loss: 0.8049 time 24.10s
Final training  3369/4999 loss: 0.7773 time 24.13s
Final training  3370/4999 loss: 0.7852 time 24.14s
Final training  3371/4999 loss: 0.7780 time 24.23s
Final training  3372/4999 loss: 0.7863 time 24.42s
Final training  3373/4999 loss: 0.7578 time 24.29s
Final training  3374/4999 loss: 0.8062 time 24.50s
Final training  3375/4999 loss: 0.7694 time 23.86s
Final training  3376/4999 loss: 0.7986 time 24.22s
Final training  3377/4999 loss: 0.7720 time 24.32s
Final training  3378/4999 loss: 0.7881 time 24.43s
Final training  3379/4999 loss: 0.7900 time 24.50s
Final training  3380/4999 loss: 0.7711 time 24.36s
Final training  3381/4999 loss: 0.7793 time 23.98s
Final training  3382/4999 loss: 0.7851 time 24.47s
Final training  3383/4999 loss: 0.7929 time 24.19s
Final training  3384/4999 loss: 0.7983 time 24.14s
Final training  3385/4999 loss: 0.7970 time 24.16s
Final training  3386/4999 loss: 0.7865 time 24.21s
Final training  3387/4999 loss: 0.7805 time 23.29s
Final training  3388/4999 loss: 0.7682 time 24.16s
Final training  3389/4999 loss: 0.7806 time 23.98s
Final training  3390/4999 loss: 0.7749 time 23.94s
Final training  3391/4999 loss: 0.7895 time 24.12s
Final training  3392/4999 loss: 0.8213 time 24.15s
Final training  3393/4999 loss: 0.7776 time 23.88s
Final training  3394/4999 loss: 0.7862 time 24.03s
Final training  3395/4999 loss: 0.7739 time 23.96s
Final training  3396/4999 loss: 0.8023 time 24.02s
Final training  3397/4999 loss: 0.7910 time 23.80s
Final training  3398/4999 loss: 0.7845 time 24.18s
Final training  3399/4999 loss: 0.7594 time 24.15s
Dice accuracy for each class:  (tensor([0.9930, 0.9240, 0.9416, 0.9437, 0.8084, 0.7222, 0.8266, 0.7616, 0.9075,
        0.8376, 0.7428, 0.7756, 0.6579, 0.5808], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3399/4999 acc [ 0.816] time 121.01s
trigger times: 7
Final training  3400/4999 loss: 0.8105 time 24.43s
Final training  3401/4999 loss: 0.7996 time 24.55s
Final training  3402/4999 loss: 0.8088 time 24.60s
Final training  3403/4999 loss: 0.8074 time 24.61s
Final training  3404/4999 loss: 0.7681 time 24.22s
Final training  3405/4999 loss: 0.7823 time 24.27s
Final training  3406/4999 loss: 0.7619 time 24.53s
Final training  3407/4999 loss: 0.7874 time 24.20s
Final training  3408/4999 loss: 0.7703 time 24.33s
Final training  3409/4999 loss: 0.7728 time 24.22s
Final training  3410/4999 loss: 0.7699 time 24.08s
Final training  3411/4999 loss: 0.7904 time 24.03s
Final training  3412/4999 loss: 0.7908 time 24.16s
Final training  3413/4999 loss: 0.7577 time 24.05s
Final training  3414/4999 loss: 0.8209 time 24.32s
Final training  3415/4999 loss: 0.7912 time 24.09s
Final training  3416/4999 loss: 0.7868 time 24.04s
Final training  3417/4999 loss: 0.7974 time 24.21s
Final training  3418/4999 loss: 0.7965 time 24.15s
Final training  3419/4999 loss: 0.7991 time 24.21s
Final training  3420/4999 loss: 0.7707 time 24.13s
Final training  3421/4999 loss: 0.7981 time 24.19s
Final training  3422/4999 loss: 0.7977 time 24.10s
Final training  3423/4999 loss: 0.7736 time 24.12s
Final training  3424/4999 loss: 0.7852 time 24.02s
Final training  3425/4999 loss: 0.7918 time 24.03s
Final training  3426/4999 loss: 0.7720 time 24.18s
Final training  3427/4999 loss: 0.7909 time 24.22s
Final training  3428/4999 loss: 0.7763 time 24.14s
Final training  3429/4999 loss: 0.7717 time 23.98s
Final training  3430/4999 loss: 0.7973 time 23.77s
Final training  3431/4999 loss: 0.7574 time 23.79s
Final training  3432/4999 loss: 0.7738 time 23.85s
Final training  3433/4999 loss: 0.7651 time 24.27s
Final training  3434/4999 loss: 0.7737 time 23.98s
Final training  3435/4999 loss: 0.7937 time 23.97s
Final training  3436/4999 loss: 0.7782 time 24.20s
Final training  3437/4999 loss: 0.8030 time 24.10s
Final training  3438/4999 loss: 0.7862 time 24.08s
Final training  3439/4999 loss: 0.7893 time 23.96s
Final training  3440/4999 loss: 0.7801 time 23.93s
Final training  3441/4999 loss: 0.7827 time 24.11s
Final training  3442/4999 loss: 0.8049 time 24.08s
Final training  3443/4999 loss: 0.7757 time 24.13s
Final training  3444/4999 loss: 0.7975 time 24.08s
Final training  3445/4999 loss: 0.7861 time 23.94s
Final training  3446/4999 loss: 0.8010 time 24.22s
Final training  3447/4999 loss: 0.7686 time 24.26s
Final training  3448/4999 loss: 0.7662 time 24.18s
Final training  3449/4999 loss: 0.7896 time 23.94s
Final training  3450/4999 loss: 0.7741 time 23.93s
Final training  3451/4999 loss: 0.7790 time 23.92s
Final training  3452/4999 loss: 0.7946 time 24.15s
Final training  3453/4999 loss: 0.7670 time 24.27s
Final training  3454/4999 loss: 0.7776 time 24.08s
Final training  3455/4999 loss: 0.7846 time 23.65s
Final training  3456/4999 loss: 0.7748 time 24.13s
Final training  3457/4999 loss: 0.7840 time 23.96s
Final training  3458/4999 loss: 0.7747 time 23.93s
Final training  3459/4999 loss: 0.7759 time 23.81s
Final training  3460/4999 loss: 0.7721 time 23.78s
Final training  3461/4999 loss: 0.7799 time 24.45s
Final training  3462/4999 loss: 0.7885 time 24.43s
Final training  3463/4999 loss: 0.8002 time 24.62s
Final training  3464/4999 loss: 0.7553 time 24.64s
Final training  3465/4999 loss: 0.7652 time 24.53s
Final training  3466/4999 loss: 0.7926 time 24.45s
Final training  3467/4999 loss: 0.7840 time 25.13s
Final training  3468/4999 loss: 0.7724 time 24.75s
Final training  3469/4999 loss: 0.7958 time 24.65s
Final training  3470/4999 loss: 0.7878 time 24.54s
Final training  3471/4999 loss: 0.7780 time 24.74s
Final training  3472/4999 loss: 0.7599 time 24.62s
Final training  3473/4999 loss: 0.7933 time 24.29s
Final training  3474/4999 loss: 0.7896 time 24.35s
Final training  3475/4999 loss: 0.7697 time 24.23s
Final training  3476/4999 loss: 0.7796 time 24.31s
Final training  3477/4999 loss: 0.7649 time 24.39s
Final training  3478/4999 loss: 0.7882 time 24.65s
Final training  3479/4999 loss: 0.7866 time 24.39s
Final training  3480/4999 loss: 0.7718 time 24.41s
Final training  3481/4999 loss: 0.7845 time 24.31s
Final training  3482/4999 loss: 0.7569 time 24.21s
Final training  3483/4999 loss: 0.7829 time 24.00s
Final training  3484/4999 loss: 0.7743 time 24.15s
Final training  3485/4999 loss: 0.7955 time 24.14s
Final training  3486/4999 loss: 0.7865 time 24.16s
Final training  3487/4999 loss: 0.7645 time 24.08s
Final training  3488/4999 loss: 0.7870 time 24.34s
Final training  3489/4999 loss: 0.8035 time 24.05s
Final training  3490/4999 loss: 0.7843 time 24.20s
Final training  3491/4999 loss: 0.7858 time 24.20s
Final training  3492/4999 loss: 0.7935 time 24.37s
Final training  3493/4999 loss: 0.7927 time 24.30s
Final training  3494/4999 loss: 0.7878 time 24.40s
Final training  3495/4999 loss: 0.7882 time 24.08s
Final training  3496/4999 loss: 0.8062 time 24.46s
Final training  3497/4999 loss: 0.7794 time 24.20s
Final training  3498/4999 loss: 0.8035 time 24.73s
Final training  3499/4999 loss: 0.7957 time 24.53s
Dice accuracy for each class:  (tensor([0.9933, 0.9353, 0.9428, 0.9450, 0.7701, 0.7386, 0.8326, 0.8277, 0.9079,
        0.8524, 0.7460, 0.7798, 0.6668, 0.6187], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3499/4999 acc [ 0.826] time 121.65s
trigger times: 8
Final training  3500/4999 loss: 0.8023 time 24.22s
Final training  3501/4999 loss: 0.7712 time 24.05s
Final training  3502/4999 loss: 0.7816 time 24.11s
Final training  3503/4999 loss: 0.7615 time 24.14s
Final training  3504/4999 loss: 0.7849 time 24.23s
Final training  3505/4999 loss: 0.7781 time 24.32s
Final training  3506/4999 loss: 0.7785 time 24.14s
Final training  3507/4999 loss: 0.7830 time 24.05s
Final training  3508/4999 loss: 0.7846 time 24.04s
Final training  3509/4999 loss: 0.7744 time 24.40s
Final training  3510/4999 loss: 0.7759 time 24.45s
Final training  3511/4999 loss: 0.8262 time 24.28s
Final training  3512/4999 loss: 0.7846 time 24.08s
Final training  3513/4999 loss: 0.8021 time 23.73s
Final training  3514/4999 loss: 0.7812 time 24.16s
Final training  3515/4999 loss: 0.7664 time 24.18s
Final training  3516/4999 loss: 0.7740 time 24.36s
Final training  3517/4999 loss: 0.7815 time 24.04s
Final training  3518/4999 loss: 0.7915 time 24.18s
Final training  3519/4999 loss: 0.7700 time 23.86s
Final training  3520/4999 loss: 0.7820 time 23.91s
Final training  3521/4999 loss: 0.7787 time 24.22s
Final training  3522/4999 loss: 0.8215 time 24.17s
Final training  3523/4999 loss: 0.7950 time 24.24s
Final training  3524/4999 loss: 0.7994 time 24.23s
Final training  3525/4999 loss: 0.7838 time 24.54s
Final training  3526/4999 loss: 0.8101 time 24.64s
Final training  3527/4999 loss: 0.7741 time 24.46s
Final training  3528/4999 loss: 0.7746 time 24.79s
Final training  3529/4999 loss: 0.7928 time 24.60s
Final training  3530/4999 loss: 0.8047 time 24.45s
Final training  3531/4999 loss: 0.7978 time 23.73s
Final training  3532/4999 loss: 0.7842 time 23.86s
Final training  3533/4999 loss: 0.7957 time 24.71s
Final training  3534/4999 loss: 0.7924 time 24.12s
Final training  3535/4999 loss: 0.7845 time 24.36s
Final training  3536/4999 loss: 0.7722 time 24.01s
Final training  3537/4999 loss: 0.7773 time 24.56s
Final training  3538/4999 loss: 0.7892 time 24.32s
Final training  3539/4999 loss: 0.7648 time 24.47s
Final training  3540/4999 loss: 0.7904 time 24.43s
Final training  3541/4999 loss: 0.7756 time 24.64s
Final training  3542/4999 loss: 0.7863 time 24.39s
Final training  3543/4999 loss: 0.7792 time 24.65s
Final training  3544/4999 loss: 0.7738 time 24.45s
Final training  3545/4999 loss: 0.8060 time 24.44s
Final training  3546/4999 loss: 0.7934 time 24.24s
Final training  3547/4999 loss: 0.7666 time 24.19s
Final training  3548/4999 loss: 0.7865 time 24.13s
Final training  3549/4999 loss: 0.8166 time 24.28s
Final training  3550/4999 loss: 0.7846 time 24.05s
Final training  3551/4999 loss: 0.7987 time 24.01s
Final training  3552/4999 loss: 0.7919 time 23.96s
Final training  3553/4999 loss: 0.7898 time 24.12s
Final training  3554/4999 loss: 0.8028 time 24.19s
Final training  3555/4999 loss: 0.7779 time 24.19s
Final training  3556/4999 loss: 0.7800 time 24.15s
Final training  3557/4999 loss: 0.7702 time 24.11s
Final training  3558/4999 loss: 0.7821 time 24.20s
Final training  3559/4999 loss: 0.7796 time 24.13s
Final training  3560/4999 loss: 0.7888 time 24.07s
Final training  3561/4999 loss: 0.7885 time 24.13s
Final training  3562/4999 loss: 0.7820 time 24.03s
Final training  3563/4999 loss: 0.7814 time 23.73s
Final training  3564/4999 loss: 0.7807 time 23.97s
Final training  3565/4999 loss: 0.7825 time 23.85s
Final training  3566/4999 loss: 0.7714 time 24.21s
Final training  3567/4999 loss: 0.7777 time 24.66s
Final training  3568/4999 loss: 0.7898 time 24.06s
Final training  3569/4999 loss: 0.7688 time 24.20s
Final training  3570/4999 loss: 0.7822 time 24.19s
Final training  3571/4999 loss: 0.7458 time 24.03s
Final training  3572/4999 loss: 0.7692 time 23.96s
Final training  3573/4999 loss: 0.8143 time 23.97s
Final training  3574/4999 loss: 0.7765 time 23.94s
Final training  3575/4999 loss: 0.8043 time 24.00s
Final training  3576/4999 loss: 0.7882 time 24.12s
Final training  3577/4999 loss: 0.7847 time 23.71s
Final training  3578/4999 loss: 0.7761 time 24.07s
Final training  3579/4999 loss: 0.7434 time 24.17s
Final training  3580/4999 loss: 0.7642 time 24.02s
Final training  3581/4999 loss: 0.7807 time 24.34s
Final training  3582/4999 loss: 0.7623 time 23.93s
Final training  3583/4999 loss: 0.7845 time 24.02s
Final training  3584/4999 loss: 0.7807 time 24.12s
Final training  3585/4999 loss: 0.7597 time 24.17s
Final training  3586/4999 loss: 0.7773 time 23.90s
Final training  3587/4999 loss: 0.7762 time 24.04s
Final training  3588/4999 loss: 0.7714 time 24.18s
Final training  3589/4999 loss: 0.7666 time 24.35s
Final training  3590/4999 loss: 0.7731 time 24.34s
Final training  3591/4999 loss: 0.7988 time 24.58s
Final training  3592/4999 loss: 0.7862 time 24.40s
Final training  3593/4999 loss: 0.7673 time 23.89s
Final training  3594/4999 loss: 0.7981 time 24.09s
Final training  3595/4999 loss: 0.7763 time 24.41s
Final training  3596/4999 loss: 0.7672 time 24.37s
Final training  3597/4999 loss: 0.8137 time 24.47s
Final training  3598/4999 loss: 0.7790 time 24.36s
Final training  3599/4999 loss: 0.7678 time 24.19s
Dice accuracy for each class:  (tensor([0.9928, 0.9345, 0.9434, 0.9451, 0.7828, 0.7320, 0.8228, 0.7991, 0.9079,
        0.8485, 0.7505, 0.7719, 0.6730, 0.6408], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3599/4999 acc [ 0.825] time 120.78s
trigger times: 9
Final training  3600/4999 loss: 0.7747 time 24.14s
Final training  3601/4999 loss: 0.7884 time 24.46s
Final training  3602/4999 loss: 0.8063 time 24.53s
Final training  3603/4999 loss: 0.7878 time 24.33s
Final training  3604/4999 loss: 0.7808 time 24.15s
Final training  3605/4999 loss: 0.7870 time 24.17s
Final training  3606/4999 loss: 0.8009 time 24.22s
Final training  3607/4999 loss: 0.7794 time 24.13s
Final training  3608/4999 loss: 0.7911 time 23.95s
Final training  3609/4999 loss: 0.7609 time 24.01s
Final training  3610/4999 loss: 0.7846 time 23.86s
Final training  3611/4999 loss: 0.7958 time 24.17s
Final training  3612/4999 loss: 0.7738 time 23.78s
Final training  3613/4999 loss: 0.7711 time 23.57s
Final training  3614/4999 loss: 0.7732 time 24.09s
Final training  3615/4999 loss: 0.7732 time 24.08s
Final training  3616/4999 loss: 0.7824 time 24.16s
Final training  3617/4999 loss: 0.7644 time 24.28s
Final training  3618/4999 loss: 0.7743 time 23.98s
Final training  3619/4999 loss: 0.7864 time 24.28s
Final training  3620/4999 loss: 0.7761 time 24.56s
Final training  3621/4999 loss: 0.8249 time 24.11s
Final training  3622/4999 loss: 0.7826 time 24.13s
Final training  3623/4999 loss: 0.7845 time 24.23s
Final training  3624/4999 loss: 0.7594 time 24.25s
Final training  3625/4999 loss: 0.7681 time 24.58s
Final training  3626/4999 loss: 0.7770 time 24.54s
Final training  3627/4999 loss: 0.8010 time 24.21s
Final training  3628/4999 loss: 0.7645 time 24.37s
Final training  3629/4999 loss: 0.7895 time 24.44s
Final training  3630/4999 loss: 0.7656 time 24.52s
Final training  3631/4999 loss: 0.7753 time 24.47s
Final training  3632/4999 loss: 0.7614 time 24.47s
Final training  3633/4999 loss: 0.7617 time 24.14s
Final training  3634/4999 loss: 0.7900 time 24.44s
Final training  3635/4999 loss: 0.7902 time 24.66s
Final training  3636/4999 loss: 0.7804 time 24.21s
Final training  3637/4999 loss: 0.7836 time 24.46s
Final training  3638/4999 loss: 0.7698 time 24.22s
Final training  3639/4999 loss: 0.7945 time 23.96s
Final training  3640/4999 loss: 0.7825 time 24.07s
Final training  3641/4999 loss: 0.7885 time 24.14s
Final training  3642/4999 loss: 0.7944 time 24.11s
Final training  3643/4999 loss: 0.7855 time 23.90s
Final training  3644/4999 loss: 0.7832 time 24.46s
Final training  3645/4999 loss: 0.7641 time 24.18s
Final training  3646/4999 loss: 0.7846 time 24.27s
Final training  3647/4999 loss: 0.7692 time 24.53s
Final training  3648/4999 loss: 0.7615 time 24.23s
Final training  3649/4999 loss: 0.8162 time 23.43s
Final training  3650/4999 loss: 0.7940 time 24.11s
Final training  3651/4999 loss: 0.7650 time 24.11s
Final training  3652/4999 loss: 0.7920 time 24.10s
Final training  3653/4999 loss: 0.7719 time 24.33s
Final training  3654/4999 loss: 0.7761 time 24.45s
Final training  3655/4999 loss: 0.7655 time 24.22s
Final training  3656/4999 loss: 0.7926 time 24.01s
Final training  3657/4999 loss: 0.7523 time 24.19s
Final training  3658/4999 loss: 0.7802 time 24.13s
Final training  3659/4999 loss: 0.7532 time 23.94s
Final training  3660/4999 loss: 0.7735 time 24.12s
Final training  3661/4999 loss: 0.7846 time 23.98s
Final training  3662/4999 loss: 0.7660 time 24.14s
Final training  3663/4999 loss: 0.7851 time 24.23s
Final training  3664/4999 loss: 0.7847 time 24.16s
Final training  3665/4999 loss: 0.7876 time 24.10s
Final training  3666/4999 loss: 0.7724 time 24.01s
Final training  3667/4999 loss: 0.8049 time 24.06s
Final training  3668/4999 loss: 0.7929 time 24.22s
Final training  3669/4999 loss: 0.7671 time 24.42s
Final training  3670/4999 loss: 0.7902 time 24.25s
Final training  3671/4999 loss: 0.7853 time 24.04s
Final training  3672/4999 loss: 0.7896 time 24.17s
Final training  3673/4999 loss: 0.7808 time 24.27s
Final training  3674/4999 loss: 0.7615 time 24.22s
Final training  3675/4999 loss: 0.8052 time 24.00s
Final training  3676/4999 loss: 0.7763 time 24.02s
Final training  3677/4999 loss: 0.7817 time 23.80s
Final training  3678/4999 loss: 0.7926 time 23.96s
Final training  3679/4999 loss: 0.7856 time 24.11s
Final training  3680/4999 loss: 0.7675 time 24.09s
Final training  3681/4999 loss: 0.7934 time 24.29s
Final training  3682/4999 loss: 0.7931 time 24.25s
Final training  3683/4999 loss: 0.7664 time 24.39s
Final training  3684/4999 loss: 0.8261 time 24.34s
Final training  3685/4999 loss: 0.7978 time 24.16s
Final training  3686/4999 loss: 0.7584 time 24.04s
Final training  3687/4999 loss: 0.7711 time 24.11s
Final training  3688/4999 loss: 0.7762 time 24.04s
Final training  3689/4999 loss: 0.7413 time 24.12s
Final training  3690/4999 loss: 0.7780 time 24.15s
Final training  3691/4999 loss: 0.7921 time 24.14s
Final training  3692/4999 loss: 0.7995 time 24.14s
Final training  3693/4999 loss: 0.7861 time 24.13s
Final training  3694/4999 loss: 0.7699 time 24.21s
Final training  3695/4999 loss: 0.7645 time 24.15s
Final training  3696/4999 loss: 0.8047 time 24.05s
Final training  3697/4999 loss: 0.8065 time 23.80s
Final training  3698/4999 loss: 0.7821 time 24.19s
Final training  3699/4999 loss: 0.7818 time 24.33s
Dice accuracy for each class:  (tensor([0.9933, 0.9317, 0.9416, 0.9424, 0.7780, 0.7437, 0.8312, 0.7871, 0.9064,
        0.8553, 0.7477, 0.7850, 0.6616, 0.5820], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3699/4999 acc [ 0.821] time 121.11s
trigger times: 10
Final training  3700/4999 loss: 0.7668 time 23.73s
Final training  3701/4999 loss: 0.8096 time 24.13s
Final training  3702/4999 loss: 0.7688 time 24.05s
Final training  3703/4999 loss: 0.7803 time 23.22s
Final training  3704/4999 loss: 0.7644 time 24.06s
Final training  3705/4999 loss: 0.7774 time 24.09s
Final training  3706/4999 loss: 0.7932 time 23.99s
Final training  3707/4999 loss: 0.7835 time 24.32s
Final training  3708/4999 loss: 0.7644 time 24.01s
Final training  3709/4999 loss: 0.7744 time 24.19s
Final training  3710/4999 loss: 0.7622 time 24.02s
Final training  3711/4999 loss: 0.7770 time 24.16s
Final training  3712/4999 loss: 0.7955 time 24.13s
Final training  3713/4999 loss: 0.7748 time 24.42s
Final training  3714/4999 loss: 0.7839 time 24.36s
Final training  3715/4999 loss: 0.7789 time 24.10s
Final training  3716/4999 loss: 0.7922 time 23.98s
Final training  3717/4999 loss: 0.7425 time 24.18s
Final training  3718/4999 loss: 0.7833 time 24.31s
Final training  3719/4999 loss: 0.7805 time 24.35s
Final training  3720/4999 loss: 0.7630 time 24.22s
Final training  3721/4999 loss: 0.7954 time 24.41s
Final training  3722/4999 loss: 0.7749 time 24.48s
Final training  3723/4999 loss: 0.7575 time 24.24s
Final training  3724/4999 loss: 0.7766 time 24.20s
Final training  3725/4999 loss: 0.7984 time 24.10s
Final training  3726/4999 loss: 0.7801 time 24.15s
Final training  3727/4999 loss: 0.7841 time 24.30s
Final training  3728/4999 loss: 0.7837 time 24.13s
Final training  3729/4999 loss: 0.7647 time 24.17s
Final training  3730/4999 loss: 0.7814 time 24.01s
Final training  3731/4999 loss: 0.7881 time 23.97s
Final training  3732/4999 loss: 0.7696 time 23.94s
Final training  3733/4999 loss: 0.7881 time 24.17s
Final training  3734/4999 loss: 0.7606 time 24.02s
Final training  3735/4999 loss: 0.7818 time 24.03s
Final training  3736/4999 loss: 0.7689 time 23.77s
Final training  3737/4999 loss: 0.7677 time 24.11s
Final training  3738/4999 loss: 0.7601 time 24.09s
Final training  3739/4999 loss: 0.7961 time 24.02s
Final training  3740/4999 loss: 0.7837 time 23.93s
Final training  3741/4999 loss: 0.7688 time 23.93s
Final training  3742/4999 loss: 0.7781 time 24.14s
Final training  3743/4999 loss: 0.7616 time 24.13s
Final training  3744/4999 loss: 0.8139 time 23.89s
Final training  3745/4999 loss: 0.7630 time 23.89s
Final training  3746/4999 loss: 0.7753 time 24.43s
Final training  3747/4999 loss: 0.7915 time 24.11s
Final training  3748/4999 loss: 0.7610 time 24.32s
Final training  3749/4999 loss: 0.7940 time 24.46s
Final training  3750/4999 loss: 0.7747 time 24.15s
Final training  3751/4999 loss: 0.7972 time 24.43s
Final training  3752/4999 loss: 0.7853 time 24.66s
Final training  3753/4999 loss: 0.7830 time 24.46s
Final training  3754/4999 loss: 0.7968 time 24.39s
Final training  3755/4999 loss: 0.7798 time 24.51s
Final training  3756/4999 loss: 0.7909 time 24.15s
Final training  3757/4999 loss: 0.8051 time 24.38s
Final training  3758/4999 loss: 0.7970 time 24.15s
Final training  3759/4999 loss: 0.7674 time 24.28s
Final training  3760/4999 loss: 0.7695 time 24.30s
Final training  3761/4999 loss: 0.7925 time 24.20s
Final training  3762/4999 loss: 0.7771 time 24.10s
Final training  3763/4999 loss: 0.7707 time 24.08s
Final training  3764/4999 loss: 0.8027 time 24.19s
Final training  3765/4999 loss: 0.7894 time 24.17s
Final training  3766/4999 loss: 0.7718 time 24.18s
Final training  3767/4999 loss: 0.7748 time 23.90s
Final training  3768/4999 loss: 0.7533 time 23.78s
Final training  3769/4999 loss: 0.7833 time 24.16s
Final training  3770/4999 loss: 0.7696 time 24.08s
Final training  3771/4999 loss: 0.7675 time 23.97s
Final training  3772/4999 loss: 0.7771 time 24.08s
Final training  3773/4999 loss: 0.7791 time 24.35s
Final training  3774/4999 loss: 0.7977 time 24.02s
Final training  3775/4999 loss: 0.7688 time 23.70s
Final training  3776/4999 loss: 0.7931 time 24.18s
Final training  3777/4999 loss: 0.7886 time 24.33s
Final training  3778/4999 loss: 0.7692 time 23.83s
Final training  3779/4999 loss: 0.7627 time 24.00s
Final training  3780/4999 loss: 0.7890 time 24.09s
Final training  3781/4999 loss: 0.8061 time 24.20s
Final training  3782/4999 loss: 0.7731 time 23.92s
Final training  3783/4999 loss: 0.7656 time 24.26s
Final training  3784/4999 loss: 0.7777 time 23.94s
Final training  3785/4999 loss: 0.7795 time 24.13s
Final training  3786/4999 loss: 0.7726 time 23.98s
Final training  3787/4999 loss: 0.7752 time 24.17s
Final training  3788/4999 loss: 0.7644 time 24.54s
Final training  3789/4999 loss: 0.7876 time 24.05s
Final training  3790/4999 loss: 0.7919 time 24.23s
Final training  3791/4999 loss: 0.7859 time 24.21s
Final training  3792/4999 loss: 0.7964 time 24.07s
Final training  3793/4999 loss: 0.7826 time 24.11s
Final training  3794/4999 loss: 0.7750 time 24.09s
Final training  3795/4999 loss: 0.7948 time 24.21s
Final training  3796/4999 loss: 0.7875 time 24.42s
Final training  3797/4999 loss: 0.7840 time 24.20s
Final training  3798/4999 loss: 0.7996 time 24.20s
Final training  3799/4999 loss: 0.7685 time 24.20s
Dice accuracy for each class:  (tensor([0.9930, 0.9387, 0.9436, 0.9458, 0.7705, 0.7402, 0.8285, 0.7901, 0.9059,
        0.8377, 0.7489, 0.7778, 0.6756, 0.6186], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3799/4999 acc [ 0.823] time 120.70s
trigger times: 11
Final training  3800/4999 loss: 0.7796 time 24.03s
Final training  3801/4999 loss: 0.7593 time 24.15s
Final training  3802/4999 loss: 0.7591 time 24.08s
Final training  3803/4999 loss: 0.7798 time 24.23s
Final training  3804/4999 loss: 0.7919 time 24.04s
Final training  3805/4999 loss: 0.7740 time 23.73s
Final training  3806/4999 loss: 0.7702 time 24.11s
Final training  3807/4999 loss: 0.7851 time 24.18s
Final training  3808/4999 loss: 0.7613 time 23.80s
Final training  3809/4999 loss: 0.7826 time 23.94s
Final training  3810/4999 loss: 0.7675 time 24.18s
Final training  3811/4999 loss: 0.7578 time 24.08s
Final training  3812/4999 loss: 0.7695 time 24.04s
Final training  3813/4999 loss: 0.8003 time 24.10s
Final training  3814/4999 loss: 0.7634 time 24.10s
Final training  3815/4999 loss: 0.7851 time 24.10s
Final training  3816/4999 loss: 0.7618 time 24.24s
Final training  3817/4999 loss: 0.7891 time 24.11s
Final training  3818/4999 loss: 0.7905 time 24.46s
Final training  3819/4999 loss: 0.7789 time 24.03s
Final training  3820/4999 loss: 0.7921 time 24.54s
Final training  3821/4999 loss: 0.7787 time 24.41s
Final training  3822/4999 loss: 0.7800 time 24.30s
Final training  3823/4999 loss: 0.7796 time 23.98s
Final training  3824/4999 loss: 0.7836 time 24.01s
Final training  3825/4999 loss: 0.7713 time 23.92s
Final training  3826/4999 loss: 0.7972 time 24.08s
Final training  3827/4999 loss: 0.7835 time 24.29s
Final training  3828/4999 loss: 0.7724 time 24.64s
Final training  3829/4999 loss: 0.7815 time 24.12s
Final training  3830/4999 loss: 0.7655 time 24.11s
Final training  3831/4999 loss: 0.7856 time 23.95s
Final training  3832/4999 loss: 0.7572 time 24.04s
Final training  3833/4999 loss: 0.7721 time 24.14s
Final training  3834/4999 loss: 0.7847 time 24.10s
Final training  3835/4999 loss: 0.7890 time 24.18s
Final training  3836/4999 loss: 0.7909 time 24.18s
Final training  3837/4999 loss: 0.7847 time 24.05s
Final training  3838/4999 loss: 0.7955 time 24.28s
Final training  3839/4999 loss: 0.7684 time 24.84s
Final training  3840/4999 loss: 0.7671 time 24.72s
Final training  3841/4999 loss: 0.7784 time 24.33s
Final training  3842/4999 loss: 0.7828 time 24.04s
Final training  3843/4999 loss: 0.8082 time 24.16s
Final training  3844/4999 loss: 0.7595 time 23.92s
Final training  3845/4999 loss: 0.7740 time 24.05s
Final training  3846/4999 loss: 0.7579 time 23.90s
Final training  3847/4999 loss: 0.7685 time 24.20s
Final training  3848/4999 loss: 0.7709 time 23.87s
Final training  3849/4999 loss: 0.7911 time 23.96s
Final training  3850/4999 loss: 0.7914 time 24.21s
Final training  3851/4999 loss: 0.7836 time 24.08s
Final training  3852/4999 loss: 0.7905 time 24.13s
Final training  3853/4999 loss: 0.7786 time 24.05s
Final training  3854/4999 loss: 0.7697 time 23.91s
Final training  3855/4999 loss: 0.7901 time 24.14s
Final training  3856/4999 loss: 0.7521 time 24.30s
Final training  3857/4999 loss: 0.7720 time 24.01s
Final training  3858/4999 loss: 0.7892 time 24.03s
Final training  3859/4999 loss: 0.8002 time 24.11s
Final training  3860/4999 loss: 0.7954 time 24.10s
Final training  3861/4999 loss: 0.7904 time 23.99s
Final training  3862/4999 loss: 0.7758 time 24.11s
Final training  3863/4999 loss: 0.7874 time 24.08s
Final training  3864/4999 loss: 0.7984 time 24.14s
Final training  3865/4999 loss: 0.7826 time 24.02s
Final training  3866/4999 loss: 0.7975 time 24.02s
Final training  3867/4999 loss: 0.8045 time 24.19s
Final training  3868/4999 loss: 0.7778 time 24.43s
Final training  3869/4999 loss: 0.7852 time 24.24s
Final training  3870/4999 loss: 0.7882 time 24.09s
Final training  3871/4999 loss: 0.7726 time 24.25s
Final training  3872/4999 loss: 0.7725 time 23.91s
Final training  3873/4999 loss: 0.7754 time 24.13s
Final training  3874/4999 loss: 0.7926 time 24.20s
Final training  3875/4999 loss: 0.8050 time 24.49s
Final training  3876/4999 loss: 0.7739 time 24.27s
Final training  3877/4999 loss: 0.7972 time 24.45s
Final training  3878/4999 loss: 0.7515 time 24.38s
Final training  3879/4999 loss: 0.7711 time 24.85s
Final training  3880/4999 loss: 0.7658 time 24.54s
Final training  3881/4999 loss: 0.7774 time 24.43s
Final training  3882/4999 loss: 0.7930 time 24.34s
Final training  3883/4999 loss: 0.7492 time 24.48s
Final training  3884/4999 loss: 0.7711 time 24.56s
Final training  3885/4999 loss: 0.7569 time 24.30s
Final training  3886/4999 loss: 0.8005 time 24.34s
Final training  3887/4999 loss: 0.7777 time 24.64s
Final training  3888/4999 loss: 0.7672 time 24.77s
Final training  3889/4999 loss: 0.7809 time 24.62s
Final training  3890/4999 loss: 0.8003 time 24.60s
Final training  3891/4999 loss: 0.7910 time 24.92s
Final training  3892/4999 loss: 0.8098 time 24.31s
Final training  3893/4999 loss: 0.7774 time 24.73s
Final training  3894/4999 loss: 0.7776 time 24.36s
Final training  3895/4999 loss: 0.7781 time 24.50s
Final training  3896/4999 loss: 0.7701 time 24.23s
Final training  3897/4999 loss: 0.7754 time 24.03s
Final training  3898/4999 loss: 0.7751 time 24.15s
Final training  3899/4999 loss: 0.7712 time 24.48s
Dice accuracy for each class:  (tensor([0.9937, 0.9372, 0.9442, 0.9455, 0.7775, 0.7314, 0.8434, 0.7898, 0.9058,
        0.8436, 0.7486, 0.7774, 0.6648, 0.6188], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3899/4999 acc [ 0.823] time 121.52s
trigger times: 12
Final training  3900/4999 loss: 0.7762 time 24.08s
Final training  3901/4999 loss: 0.7926 time 24.32s
Final training  3902/4999 loss: 0.7844 time 24.48s
Final training  3903/4999 loss: 0.7945 time 24.34s
Final training  3904/4999 loss: 0.7452 time 24.10s
Final training  3905/4999 loss: 0.7887 time 24.28s
Final training  3906/4999 loss: 0.7976 time 24.16s
Final training  3907/4999 loss: 0.7892 time 24.45s
Final training  3908/4999 loss: 0.7763 time 24.41s
Final training  3909/4999 loss: 0.7628 time 24.51s
Final training  3910/4999 loss: 0.7741 time 24.68s
Final training  3911/4999 loss: 0.7734 time 24.65s
Final training  3912/4999 loss: 0.7889 time 24.38s
Final training  3913/4999 loss: 0.7878 time 24.48s
Final training  3914/4999 loss: 0.7764 time 24.36s
Final training  3915/4999 loss: 0.7837 time 24.06s
Final training  3916/4999 loss: 0.7827 time 23.82s
Final training  3917/4999 loss: 0.7676 time 24.19s
Final training  3918/4999 loss: 0.7856 time 23.73s
Final training  3919/4999 loss: 0.7457 time 24.09s
Final training  3920/4999 loss: 0.7917 time 24.03s
Final training  3921/4999 loss: 0.7841 time 24.09s
Final training  3922/4999 loss: 0.7493 time 23.81s
Final training  3923/4999 loss: 0.7643 time 24.19s
Final training  3924/4999 loss: 0.7431 time 24.18s
Final training  3925/4999 loss: 0.7892 time 24.31s
Final training  3926/4999 loss: 0.7519 time 24.08s
Final training  3927/4999 loss: 0.7856 time 24.02s
Final training  3928/4999 loss: 0.8151 time 24.15s
Final training  3929/4999 loss: 0.7904 time 23.94s
Final training  3930/4999 loss: 0.7709 time 24.07s
Final training  3931/4999 loss: 0.8000 time 23.86s
Final training  3932/4999 loss: 0.7886 time 23.76s
Final training  3933/4999 loss: 0.7890 time 23.95s
Final training  3934/4999 loss: 0.7495 time 24.01s
Final training  3935/4999 loss: 0.7920 time 24.19s
Final training  3936/4999 loss: 0.7638 time 24.17s
Final training  3937/4999 loss: 0.7681 time 24.07s
Final training  3938/4999 loss: 0.7827 time 24.27s
Final training  3939/4999 loss: 0.7822 time 24.58s
Final training  3940/4999 loss: 0.7759 time 24.65s
Final training  3941/4999 loss: 0.7864 time 24.43s
Final training  3942/4999 loss: 0.7672 time 24.42s
Final training  3943/4999 loss: 0.7732 time 24.18s
Final training  3944/4999 loss: 0.7830 time 24.46s
Final training  3945/4999 loss: 0.8046 time 24.39s
Final training  3946/4999 loss: 0.7786 time 24.21s
Final training  3947/4999 loss: 0.7766 time 24.28s
Final training  3948/4999 loss: 0.7687 time 24.25s
Final training  3949/4999 loss: 0.7837 time 24.42s
Final training  3950/4999 loss: 0.7806 time 24.31s
Final training  3951/4999 loss: 0.7725 time 24.32s
Final training  3952/4999 loss: 0.7794 time 24.72s
Final training  3953/4999 loss: 0.7846 time 24.24s
Final training  3954/4999 loss: 0.7763 time 23.85s
Final training  3955/4999 loss: 0.7716 time 23.67s
Final training  3956/4999 loss: 0.7461 time 24.33s
Final training  3957/4999 loss: 0.7829 time 24.49s
Final training  3958/4999 loss: 0.7713 time 24.29s
Final training  3959/4999 loss: 0.7797 time 24.51s
Final training  3960/4999 loss: 0.7996 time 24.77s
Final training  3961/4999 loss: 0.7913 time 24.97s
Final training  3962/4999 loss: 0.7714 time 25.07s
Final training  3963/4999 loss: 0.7900 time 24.71s
Final training  3964/4999 loss: 0.7741 time 24.65s
Final training  3965/4999 loss: 0.7853 time 24.26s
Final training  3966/4999 loss: 0.7580 time 24.02s
Final training  3967/4999 loss: 0.7813 time 24.20s
Final training  3968/4999 loss: 0.7822 time 24.11s
Final training  3969/4999 loss: 0.7401 time 24.21s
Final training  3970/4999 loss: 0.7830 time 23.89s
Final training  3971/4999 loss: 0.7737 time 24.06s
Final training  3972/4999 loss: 0.7709 time 24.28s
Final training  3973/4999 loss: 0.7476 time 24.02s
Final training  3974/4999 loss: 0.7607 time 23.96s
Final training  3975/4999 loss: 0.7793 time 24.39s
Final training  3976/4999 loss: 0.7828 time 23.86s
Final training  3977/4999 loss: 0.7520 time 24.10s
Final training  3978/4999 loss: 0.7773 time 24.02s
Final training  3979/4999 loss: 0.7790 time 24.07s
Final training  3980/4999 loss: 0.7943 time 24.06s
Final training  3981/4999 loss: 0.7838 time 24.04s
Final training  3982/4999 loss: 0.7708 time 24.22s
Final training  3983/4999 loss: 0.7846 time 24.19s
Final training  3984/4999 loss: 0.7889 time 24.04s
Final training  3985/4999 loss: 0.7703 time 24.51s
Final training  3986/4999 loss: 0.7582 time 24.24s
Final training  3987/4999 loss: 0.7721 time 24.39s
Final training  3988/4999 loss: 0.7905 time 24.40s
Final training  3989/4999 loss: 0.7844 time 24.25s
Final training  3990/4999 loss: 0.7664 time 24.68s
Final training  3991/4999 loss: 0.7731 time 24.28s
Final training  3992/4999 loss: 0.7890 time 24.22s
Final training  3993/4999 loss: 0.7737 time 24.35s
Final training  3994/4999 loss: 0.7576 time 24.79s
Final training  3995/4999 loss: 0.7504 time 24.45s
Final training  3996/4999 loss: 0.7586 time 24.59s
Final training  3997/4999 loss: 0.7714 time 24.60s
Final training  3998/4999 loss: 0.7619 time 24.50s
Final training  3999/4999 loss: 0.7601 time 24.66s
Dice accuracy for each class:  (tensor([0.9931, 0.9177, 0.9438, 0.9448, 0.7857, 0.7315, 0.8310, 0.8079, 0.9064,
        0.8488, 0.7430, 0.7827, 0.6563, 0.6435], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  3999/4999 acc [ 0.824] time 122.02s
trigger times: 13
Final training  4000/4999 loss: 0.8064 time 24.00s
Final training  4001/4999 loss: 0.7655 time 24.09s
Final training  4002/4999 loss: 0.7752 time 24.23s
Final training  4003/4999 loss: 0.7565 time 24.49s
Final training  4004/4999 loss: 0.7831 time 24.35s
Final training  4005/4999 loss: 0.7755 time 24.31s
Final training  4006/4999 loss: 0.7878 time 23.97s
Final training  4007/4999 loss: 0.7864 time 24.51s
Final training  4008/4999 loss: 0.7905 time 24.54s
Final training  4009/4999 loss: 0.7635 time 24.43s
Final training  4010/4999 loss: 0.7967 time 24.42s
Final training  4011/4999 loss: 0.7941 time 24.66s
Final training  4012/4999 loss: 0.7813 time 24.05s
Final training  4013/4999 loss: 0.7820 time 24.26s
Final training  4014/4999 loss: 0.7854 time 24.39s
Final training  4015/4999 loss: 0.7853 time 24.27s
Final training  4016/4999 loss: 0.7796 time 24.21s
Final training  4017/4999 loss: 0.7761 time 23.90s
Final training  4018/4999 loss: 0.7872 time 24.10s
Final training  4019/4999 loss: 0.7744 time 23.99s
Final training  4020/4999 loss: 0.7674 time 24.38s
Final training  4021/4999 loss: 0.7473 time 24.02s
Final training  4022/4999 loss: 0.7746 time 24.67s
Final training  4023/4999 loss: 0.7989 time 24.22s
Final training  4024/4999 loss: 0.7850 time 23.91s
Final training  4025/4999 loss: 0.7930 time 24.02s
Final training  4026/4999 loss: 0.7792 time 24.13s
Final training  4027/4999 loss: 0.7933 time 23.92s
Final training  4028/4999 loss: 0.7683 time 24.16s
Final training  4029/4999 loss: 0.7601 time 24.10s
Final training  4030/4999 loss: 0.7526 time 24.46s
Final training  4031/4999 loss: 0.7935 time 24.44s
Final training  4032/4999 loss: 0.7630 time 24.13s
Final training  4033/4999 loss: 0.7983 time 24.15s
Final training  4034/4999 loss: 0.7933 time 24.20s
Final training  4035/4999 loss: 0.7781 time 24.10s
Final training  4036/4999 loss: 0.7799 time 24.62s
Final training  4037/4999 loss: 0.7795 time 24.35s
Final training  4038/4999 loss: 0.7506 time 24.13s
Final training  4039/4999 loss: 0.7691 time 24.05s
Final training  4040/4999 loss: 0.7660 time 24.05s
Final training  4041/4999 loss: 0.7725 time 24.52s
Final training  4042/4999 loss: 0.7731 time 24.54s
Final training  4043/4999 loss: 0.7869 time 24.59s
Final training  4044/4999 loss: 0.7825 time 24.46s
Final training  4045/4999 loss: 0.7888 time 24.43s
Final training  4046/4999 loss: 0.7711 time 24.62s
Final training  4047/4999 loss: 0.7968 time 24.58s
Final training  4048/4999 loss: 0.7729 time 24.52s
Final training  4049/4999 loss: 0.7650 time 24.41s
Final training  4050/4999 loss: 0.7614 time 24.50s
Final training  4051/4999 loss: 0.7877 time 24.20s
Final training  4052/4999 loss: 0.7806 time 24.01s
Final training  4053/4999 loss: 0.7920 time 24.09s
Final training  4054/4999 loss: 0.7721 time 24.30s
Final training  4055/4999 loss: 0.7425 time 24.06s
Final training  4056/4999 loss: 0.7703 time 24.24s
Final training  4057/4999 loss: 0.7645 time 24.19s
Final training  4058/4999 loss: 0.7701 time 23.82s
Final training  4059/4999 loss: 0.7739 time 23.77s
Final training  4060/4999 loss: 0.7854 time 23.96s
Final training  4061/4999 loss: 0.7907 time 24.03s
Final training  4062/4999 loss: 0.7923 time 24.12s
Final training  4063/4999 loss: 0.7701 time 24.04s
Final training  4064/4999 loss: 0.7901 time 23.96s
Final training  4065/4999 loss: 0.7679 time 24.13s
Final training  4066/4999 loss: 0.7791 time 24.33s
Final training  4067/4999 loss: 0.7742 time 24.16s
Final training  4068/4999 loss: 0.7734 time 23.90s
Final training  4069/4999 loss: 0.7914 time 23.85s
Final training  4070/4999 loss: 0.7767 time 23.90s
Final training  4071/4999 loss: 0.7495 time 24.14s
Final training  4072/4999 loss: 0.7743 time 24.23s
Final training  4073/4999 loss: 0.7881 time 24.41s
Final training  4074/4999 loss: 0.7565 time 24.43s
Final training  4075/4999 loss: 0.7757 time 24.03s
Final training  4076/4999 loss: 0.7732 time 24.10s
Final training  4077/4999 loss: 0.7728 time 24.34s
Final training  4078/4999 loss: 0.7953 time 24.37s
Final training  4079/4999 loss: 0.7833 time 24.59s
Final training  4080/4999 loss: 0.7515 time 24.28s
Final training  4081/4999 loss: 0.7778 time 24.15s
Final training  4082/4999 loss: 0.7740 time 24.12s
Final training  4083/4999 loss: 0.8072 time 24.59s
Final training  4084/4999 loss: 0.7758 time 24.53s
Final training  4085/4999 loss: 0.7745 time 24.45s
Final training  4086/4999 loss: 0.7700 time 24.76s
Final training  4087/4999 loss: 0.7801 time 24.77s
Final training  4088/4999 loss: 0.7970 time 24.24s
Final training  4089/4999 loss: 0.7860 time 24.49s
Final training  4090/4999 loss: 0.8102 time 24.59s
Final training  4091/4999 loss: 0.7774 time 24.20s
Final training  4092/4999 loss: 0.7845 time 24.13s
Final training  4093/4999 loss: 0.7885 time 23.93s
Final training  4094/4999 loss: 0.7910 time 24.46s
Final training  4095/4999 loss: 0.7824 time 24.00s
Final training  4096/4999 loss: 0.7867 time 23.96s
Final training  4097/4999 loss: 0.7938 time 24.17s
Final training  4098/4999 loss: 0.7662 time 24.08s
Final training  4099/4999 loss: 0.7956 time 24.10s
Dice accuracy for each class:  (tensor([0.9935, 0.9180, 0.9428, 0.9453, 0.7815, 0.7364, 0.8411, 0.7628, 0.9063,
        0.8367, 0.7501, 0.7682, 0.6719, 0.6127], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4099/4999 acc [ 0.819] time 121.39s
trigger times: 14
Final training  4100/4999 loss: 0.8034 time 23.99s
Final training  4101/4999 loss: 0.7717 time 24.12s
Final training  4102/4999 loss: 0.7658 time 24.11s
Final training  4103/4999 loss: 0.7816 time 23.96s
Final training  4104/4999 loss: 0.7491 time 23.96s
Final training  4105/4999 loss: 0.7495 time 24.10s
Final training  4106/4999 loss: 0.7908 time 23.92s
Final training  4107/4999 loss: 0.7670 time 24.23s
Final training  4108/4999 loss: 0.7885 time 24.51s
Final training  4109/4999 loss: 0.7813 time 24.49s
Final training  4110/4999 loss: 0.7829 time 24.33s
Final training  4111/4999 loss: 0.7860 time 24.13s
Final training  4112/4999 loss: 0.7819 time 23.97s
Final training  4113/4999 loss: 0.7707 time 23.86s
Final training  4114/4999 loss: 0.7601 time 23.83s
Final training  4115/4999 loss: 0.7846 time 24.19s
Final training  4116/4999 loss: 0.7673 time 23.90s
Final training  4117/4999 loss: 0.7756 time 24.10s
Final training  4118/4999 loss: 0.7958 time 24.01s
Final training  4119/4999 loss: 0.7561 time 24.04s
Final training  4120/4999 loss: 0.7746 time 24.03s
Final training  4121/4999 loss: 0.8017 time 24.08s
Final training  4122/4999 loss: 0.7919 time 24.44s
Final training  4123/4999 loss: 0.7705 time 24.60s
Final training  4124/4999 loss: 0.7500 time 24.50s
Final training  4125/4999 loss: 0.7783 time 24.42s
Final training  4126/4999 loss: 0.7777 time 24.43s
Final training  4127/4999 loss: 0.7800 time 24.68s
Final training  4128/4999 loss: 0.7791 time 24.17s
Final training  4129/4999 loss: 0.7776 time 24.57s
Final training  4130/4999 loss: 0.7717 time 24.44s
Final training  4131/4999 loss: 0.7809 time 24.53s
Final training  4132/4999 loss: 0.7867 time 24.48s
Final training  4133/4999 loss: 0.7526 time 24.10s
Final training  4134/4999 loss: 0.7808 time 24.17s
Final training  4135/4999 loss: 0.7807 time 24.18s
Final training  4136/4999 loss: 0.7935 time 24.15s
Final training  4137/4999 loss: 0.7731 time 24.17s
Final training  4138/4999 loss: 0.7411 time 23.82s
Final training  4139/4999 loss: 0.7498 time 24.32s
Final training  4140/4999 loss: 0.8098 time 24.00s
Final training  4141/4999 loss: 0.7753 time 24.06s
Final training  4142/4999 loss: 0.7502 time 24.08s
Final training  4143/4999 loss: 0.7743 time 24.25s
Final training  4144/4999 loss: 0.7833 time 24.20s
Final training  4145/4999 loss: 0.7922 time 24.42s
Final training  4146/4999 loss: 0.7690 time 24.24s
Final training  4147/4999 loss: 0.7727 time 24.40s
Final training  4148/4999 loss: 0.7440 time 24.11s
Final training  4149/4999 loss: 0.7956 time 24.06s
Final training  4150/4999 loss: 0.7744 time 24.35s
Final training  4151/4999 loss: 0.7655 time 24.03s
Final training  4152/4999 loss: 0.7638 time 24.26s
Final training  4153/4999 loss: 0.7703 time 24.63s
Final training  4154/4999 loss: 0.7938 time 24.65s
Final training  4155/4999 loss: 0.7655 time 24.43s
Final training  4156/4999 loss: 0.7860 time 24.17s
Final training  4157/4999 loss: 0.7883 time 23.99s
Final training  4158/4999 loss: 0.7931 time 23.66s
Final training  4159/4999 loss: 0.7711 time 24.04s
Final training  4160/4999 loss: 0.7687 time 24.11s
Final training  4161/4999 loss: 0.7831 time 23.97s
Final training  4162/4999 loss: 0.7699 time 23.98s
Final training  4163/4999 loss: 0.7538 time 23.88s
Final training  4164/4999 loss: 0.7870 time 24.00s
Final training  4165/4999 loss: 0.7618 time 23.94s
Final training  4166/4999 loss: 0.7484 time 24.57s
Final training  4167/4999 loss: 0.7906 time 24.50s
Final training  4168/4999 loss: 0.7746 time 24.81s
Final training  4169/4999 loss: 0.7728 time 24.67s
Final training  4170/4999 loss: 0.7492 time 24.35s
Final training  4171/4999 loss: 0.7822 time 24.76s
Final training  4172/4999 loss: 0.7797 time 24.67s
Final training  4173/4999 loss: 0.7494 time 24.51s
Final training  4174/4999 loss: 0.8008 time 24.28s
Final training  4175/4999 loss: 0.7733 time 24.27s
Final training  4176/4999 loss: 0.7719 time 24.47s
Final training  4177/4999 loss: 0.7765 time 24.38s
Final training  4178/4999 loss: 0.7661 time 24.23s
Final training  4179/4999 loss: 0.7623 time 24.15s
Final training  4180/4999 loss: 0.7980 time 24.00s
Final training  4181/4999 loss: 0.7750 time 24.22s
Final training  4182/4999 loss: 0.7848 time 23.88s
Final training  4183/4999 loss: 0.7772 time 24.09s
Final training  4184/4999 loss: 0.7735 time 24.21s
Final training  4185/4999 loss: 0.7500 time 23.99s
Final training  4186/4999 loss: 0.7439 time 24.09s
Final training  4187/4999 loss: 0.7835 time 24.27s
Final training  4188/4999 loss: 0.7921 time 24.22s
Final training  4189/4999 loss: 0.7892 time 24.18s
Final training  4190/4999 loss: 0.7540 time 24.10s
Final training  4191/4999 loss: 0.7940 time 24.13s
Final training  4192/4999 loss: 0.7882 time 24.19s
Final training  4193/4999 loss: 0.7498 time 24.22s
Final training  4194/4999 loss: 0.7705 time 24.02s
Final training  4195/4999 loss: 0.7905 time 24.10s
Final training  4196/4999 loss: 0.7682 time 24.02s
Final training  4197/4999 loss: 0.7627 time 24.15s
Final training  4198/4999 loss: 0.7902 time 24.03s
Final training  4199/4999 loss: 0.7704 time 24.09s
Dice accuracy for each class:  (tensor([0.9932, 0.9102, 0.9426, 0.9449, 0.7811, 0.7306, 0.8366, 0.7837, 0.9054,
        0.8453, 0.7470, 0.7919, 0.6669, 0.6149], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4199/4999 acc [ 0.821] time 121.49s
trigger times: 15
Final training  4200/4999 loss: 0.7646 time 24.47s
Final training  4201/4999 loss: 0.7802 time 24.34s
Final training  4202/4999 loss: 0.7711 time 24.43s
Final training  4203/4999 loss: 0.7607 time 24.59s
Final training  4204/4999 loss: 0.7798 time 24.52s
Final training  4205/4999 loss: 0.7731 time 24.75s
Final training  4206/4999 loss: 0.7866 time 24.81s
Final training  4207/4999 loss: 0.7637 time 24.90s
Final training  4208/4999 loss: 0.7505 time 24.50s
Final training  4209/4999 loss: 0.7718 time 24.03s
Final training  4210/4999 loss: 0.7501 time 24.22s
Final training  4211/4999 loss: 0.7821 time 24.46s
Final training  4212/4999 loss: 0.7644 time 24.74s
Final training  4213/4999 loss: 0.7829 time 24.76s
Final training  4214/4999 loss: 0.7559 time 24.75s
Final training  4215/4999 loss: 0.7590 time 24.44s
Final training  4216/4999 loss: 0.7773 time 24.65s
Final training  4217/4999 loss: 0.7852 time 24.85s
Final training  4218/4999 loss: 0.7821 time 24.74s
Final training  4219/4999 loss: 0.7662 time 24.82s
Final training  4220/4999 loss: 0.7911 time 24.58s
Final training  4221/4999 loss: 0.7730 time 24.35s
Final training  4222/4999 loss: 0.7853 time 24.49s
Final training  4223/4999 loss: 0.7688 time 24.19s
Final training  4224/4999 loss: 0.7496 time 24.28s
Final training  4225/4999 loss: 0.7694 time 24.59s
Final training  4226/4999 loss: 0.7960 time 24.46s
Final training  4227/4999 loss: 0.7877 time 24.19s
Final training  4228/4999 loss: 0.7889 time 24.14s
Final training  4229/4999 loss: 0.7665 time 24.18s
Final training  4230/4999 loss: 0.7829 time 24.80s
Final training  4231/4999 loss: 0.7515 time 24.38s
Final training  4232/4999 loss: 0.7537 time 24.27s
Final training  4233/4999 loss: 0.7853 time 24.30s
Final training  4234/4999 loss: 0.7682 time 24.51s
Final training  4235/4999 loss: 0.8028 time 24.28s
Final training  4236/4999 loss: 0.7548 time 24.34s
Final training  4237/4999 loss: 0.7821 time 24.59s
Final training  4238/4999 loss: 0.7574 time 24.53s
Final training  4239/4999 loss: 0.8049 time 24.15s
Final training  4240/4999 loss: 0.7730 time 24.39s
Final training  4241/4999 loss: 0.8241 time 24.39s
Final training  4242/4999 loss: 0.8004 time 24.48s
Final training  4243/4999 loss: 0.7854 time 24.34s
Final training  4244/4999 loss: 0.7862 time 24.39s
Final training  4245/4999 loss: 0.7693 time 24.58s
Final training  4246/4999 loss: 0.7612 time 24.25s
Final training  4247/4999 loss: 0.7832 time 24.55s
Final training  4248/4999 loss: 0.8184 time 24.42s
Final training  4249/4999 loss: 0.7942 time 24.52s
Final training  4250/4999 loss: 0.7710 time 24.31s
Final training  4251/4999 loss: 0.7633 time 24.51s
Final training  4252/4999 loss: 0.7509 time 24.69s
Final training  4253/4999 loss: 0.7696 time 24.43s
Final training  4254/4999 loss: 0.7787 time 24.69s
Final training  4255/4999 loss: 0.7594 time 24.64s
Final training  4256/4999 loss: 0.7922 time 24.74s
Final training  4257/4999 loss: 0.7863 time 24.04s
Final training  4258/4999 loss: 0.7717 time 24.43s
Final training  4259/4999 loss: 0.7825 time 24.40s
Final training  4260/4999 loss: 0.7845 time 24.56s
Final training  4261/4999 loss: 0.7803 time 24.49s
Final training  4262/4999 loss: 0.7791 time 24.40s
Final training  4263/4999 loss: 0.7800 time 24.29s
Final training  4264/4999 loss: 0.7767 time 24.73s
Final training  4265/4999 loss: 0.7641 time 23.63s
Final training  4266/4999 loss: 0.7508 time 24.39s
Final training  4267/4999 loss: 0.7847 time 24.53s
Final training  4268/4999 loss: 0.7645 time 24.10s
Final training  4269/4999 loss: 0.7690 time 24.00s
Final training  4270/4999 loss: 0.7856 time 23.97s
Final training  4271/4999 loss: 0.7711 time 24.34s
Final training  4272/4999 loss: 0.7775 time 24.34s
Final training  4273/4999 loss: 0.7676 time 23.99s
Final training  4274/4999 loss: 0.7746 time 24.03s
Final training  4275/4999 loss: 0.8012 time 24.12s
Final training  4276/4999 loss: 0.7871 time 24.17s
Final training  4277/4999 loss: 0.7834 time 23.99s
Final training  4278/4999 loss: 0.7969 time 24.12s
Final training  4279/4999 loss: 0.7717 time 24.13s
Final training  4280/4999 loss: 0.7756 time 24.25s
Final training  4281/4999 loss: 0.7781 time 24.22s
Final training  4282/4999 loss: 0.7748 time 24.73s
Final training  4283/4999 loss: 0.7664 time 24.55s
Final training  4284/4999 loss: 0.7768 time 24.64s
Final training  4285/4999 loss: 0.7754 time 24.86s
Final training  4286/4999 loss: 0.7610 time 24.62s
Final training  4287/4999 loss: 0.7469 time 24.56s
Final training  4288/4999 loss: 0.7760 time 24.48s
Final training  4289/4999 loss: 0.7885 time 24.56s
Final training  4290/4999 loss: 0.7594 time 24.29s
Final training  4291/4999 loss: 0.7690 time 24.12s
Final training  4292/4999 loss: 0.7593 time 24.51s
Final training  4293/4999 loss: 0.7729 time 24.37s
Final training  4294/4999 loss: 0.7703 time 24.56s
Final training  4295/4999 loss: 0.7986 time 24.35s
Final training  4296/4999 loss: 0.7676 time 24.06s
Final training  4297/4999 loss: 0.7758 time 24.14s
Final training  4298/4999 loss: 0.7695 time 24.28s
Final training  4299/4999 loss: 0.7795 time 24.37s
Dice accuracy for each class:  (tensor([0.9935, 0.9110, 0.9442, 0.9446, 0.7769, 0.7425, 0.8407, 0.7972, 0.9086,
        0.8468, 0.7462, 0.7859, 0.6734, 0.6133], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4299/4999 acc [ 0.824] time 118.63s
trigger times: 16
Final training  4300/4999 loss: 0.7870 time 24.37s
Final training  4301/4999 loss: 0.8151 time 24.04s
Final training  4302/4999 loss: 0.7620 time 24.02s
Final training  4303/4999 loss: 0.7582 time 24.21s
Final training  4304/4999 loss: 0.7672 time 24.39s
Final training  4305/4999 loss: 0.7677 time 24.36s
Final training  4306/4999 loss: 0.7674 time 24.32s
Final training  4307/4999 loss: 0.7582 time 24.21s
Final training  4308/4999 loss: 0.7703 time 23.83s
Final training  4309/4999 loss: 0.8023 time 24.14s
Final training  4310/4999 loss: 0.7684 time 23.94s
Final training  4311/4999 loss: 0.7813 time 24.07s
Final training  4312/4999 loss: 0.7759 time 24.02s
Final training  4313/4999 loss: 0.7877 time 24.17s
Final training  4314/4999 loss: 0.7634 time 24.31s
Final training  4315/4999 loss: 0.7661 time 24.18s
Final training  4316/4999 loss: 0.7750 time 24.00s
Final training  4317/4999 loss: 0.7763 time 24.00s
Final training  4318/4999 loss: 0.7583 time 24.00s
Final training  4319/4999 loss: 0.7763 time 24.19s
Final training  4320/4999 loss: 0.8015 time 24.14s
Final training  4321/4999 loss: 0.7825 time 23.89s
Final training  4322/4999 loss: 0.7883 time 23.88s
Final training  4323/4999 loss: 0.7779 time 23.97s
Final training  4324/4999 loss: 0.7695 time 24.05s
Final training  4325/4999 loss: 0.7829 time 24.02s
Final training  4326/4999 loss: 0.7911 time 23.96s
Final training  4327/4999 loss: 0.7809 time 24.15s
Final training  4328/4999 loss: 0.7854 time 24.14s
Final training  4329/4999 loss: 0.7897 time 24.30s
Final training  4330/4999 loss: 0.7706 time 23.94s
Final training  4331/4999 loss: 0.7721 time 23.94s
Final training  4332/4999 loss: 0.7918 time 24.55s
Final training  4333/4999 loss: 0.7663 time 24.25s
Final training  4334/4999 loss: 0.7800 time 24.04s
Final training  4335/4999 loss: 0.7803 time 24.01s
Final training  4336/4999 loss: 0.7681 time 24.52s
Final training  4337/4999 loss: 0.7903 time 24.28s
Final training  4338/4999 loss: 0.7945 time 24.39s
Final training  4339/4999 loss: 0.7759 time 24.51s
Final training  4340/4999 loss: 0.7781 time 24.13s
Final training  4341/4999 loss: 0.7843 time 24.43s
Final training  4342/4999 loss: 0.7759 time 24.20s
Final training  4343/4999 loss: 0.7785 time 24.11s
Final training  4344/4999 loss: 0.7950 time 24.71s
Final training  4345/4999 loss: 0.7672 time 24.45s
Final training  4346/4999 loss: 0.7653 time 24.04s
Final training  4347/4999 loss: 0.7903 time 23.94s
Final training  4348/4999 loss: 0.7849 time 24.24s
Final training  4349/4999 loss: 0.7538 time 24.24s
Final training  4350/4999 loss: 0.7699 time 24.19s
Final training  4351/4999 loss: 0.7591 time 24.39s
Final training  4352/4999 loss: 0.7904 time 23.96s
Final training  4353/4999 loss: 0.7677 time 24.37s
Final training  4354/4999 loss: 0.7939 time 24.13s
Final training  4355/4999 loss: 0.7785 time 24.27s
Final training  4356/4999 loss: 0.7712 time 24.14s
Final training  4357/4999 loss: 0.7713 time 24.11s
Final training  4358/4999 loss: 0.7809 time 24.09s
Final training  4359/4999 loss: 0.7793 time 24.18s
Final training  4360/4999 loss: 0.7673 time 23.82s
Final training  4361/4999 loss: 0.7798 time 23.86s
Final training  4362/4999 loss: 0.7900 time 24.24s
Final training  4363/4999 loss: 0.7667 time 24.35s
Final training  4364/4999 loss: 0.7566 time 24.03s
Final training  4365/4999 loss: 0.7907 time 24.06s
Final training  4366/4999 loss: 0.7894 time 24.23s
Final training  4367/4999 loss: 0.7763 time 23.83s
Final training  4368/4999 loss: 0.7650 time 24.13s
Final training  4369/4999 loss: 0.7701 time 24.15s
Final training  4370/4999 loss: 0.7923 time 23.95s
Final training  4371/4999 loss: 0.7815 time 24.17s
Final training  4372/4999 loss: 0.7921 time 23.81s
Final training  4373/4999 loss: 0.7833 time 23.78s
Final training  4374/4999 loss: 0.8099 time 23.87s
Final training  4375/4999 loss: 0.7695 time 24.14s
Final training  4376/4999 loss: 0.7645 time 24.19s
Final training  4377/4999 loss: 0.7773 time 24.16s
Final training  4378/4999 loss: 0.8022 time 24.03s
Final training  4379/4999 loss: 0.7656 time 24.30s
Final training  4380/4999 loss: 0.7318 time 24.15s
Final training  4381/4999 loss: 0.7772 time 24.16s
Final training  4382/4999 loss: 0.7914 time 24.08s
Final training  4383/4999 loss: 0.7876 time 23.89s
Final training  4384/4999 loss: 0.7615 time 24.21s
Final training  4385/4999 loss: 0.7628 time 24.31s
Final training  4386/4999 loss: 0.7619 time 24.27s
Final training  4387/4999 loss: 0.7636 time 24.34s
Final training  4388/4999 loss: 0.7688 time 24.06s
Final training  4389/4999 loss: 0.7925 time 24.54s
Final training  4390/4999 loss: 0.7620 time 24.29s
Final training  4391/4999 loss: 0.7433 time 24.69s
Final training  4392/4999 loss: 0.7840 time 24.71s
Final training  4393/4999 loss: 0.7746 time 24.58s
Final training  4394/4999 loss: 0.7805 time 24.07s
Final training  4395/4999 loss: 0.7769 time 24.87s
Final training  4396/4999 loss: 0.7785 time 24.73s
Final training  4397/4999 loss: 0.7783 time 24.98s
Final training  4398/4999 loss: 0.7855 time 24.23s
Final training  4399/4999 loss: 0.8019 time 24.16s
Dice accuracy for each class:  (tensor([0.9933, 0.9067, 0.9434, 0.9455, 0.7930, 0.7322, 0.8377, 0.7906, 0.9076,
        0.8445, 0.7520, 0.7887, 0.6687, 0.6169], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4399/4999 acc [ 0.823] time 119.45s
trigger times: 17
Final training  4400/4999 loss: 0.7853 time 24.67s
Final training  4401/4999 loss: 0.7683 time 24.59s
Final training  4402/4999 loss: 0.7871 time 24.77s
Final training  4403/4999 loss: 0.7538 time 24.62s
Final training  4404/4999 loss: 0.7944 time 24.58s
Final training  4405/4999 loss: 0.7612 time 24.44s
Final training  4406/4999 loss: 0.7702 time 24.80s
Final training  4407/4999 loss: 0.7650 time 24.45s
Final training  4408/4999 loss: 0.7774 time 24.53s
Final training  4409/4999 loss: 0.7978 time 23.97s
Final training  4410/4999 loss: 0.7874 time 24.29s
Final training  4411/4999 loss: 0.7729 time 24.21s
Final training  4412/4999 loss: 0.7740 time 24.27s
Final training  4413/4999 loss: 0.7817 time 24.08s
Final training  4414/4999 loss: 0.7482 time 24.00s
Final training  4415/4999 loss: 0.7712 time 24.12s
Final training  4416/4999 loss: 0.7828 time 24.18s
Final training  4417/4999 loss: 0.7677 time 24.05s
Final training  4418/4999 loss: 0.7755 time 23.70s
Final training  4419/4999 loss: 0.7712 time 24.21s
Final training  4420/4999 loss: 0.7661 time 24.20s
Final training  4421/4999 loss: 0.7785 time 24.24s
Final training  4422/4999 loss: 0.7829 time 23.98s
Final training  4423/4999 loss: 0.7741 time 24.23s
Final training  4424/4999 loss: 0.7670 time 24.00s
Final training  4425/4999 loss: 0.7795 time 24.04s
Final training  4426/4999 loss: 0.7789 time 24.25s
Final training  4427/4999 loss: 0.7628 time 24.15s
Final training  4428/4999 loss: 0.7444 time 24.25s
Final training  4429/4999 loss: 0.7908 time 23.90s
Final training  4430/4999 loss: 0.7943 time 24.25s
Final training  4431/4999 loss: 0.7736 time 24.09s
Final training  4432/4999 loss: 0.7722 time 24.26s
Final training  4433/4999 loss: 0.7679 time 24.12s
Final training  4434/4999 loss: 0.7820 time 24.07s
Final training  4435/4999 loss: 0.7823 time 24.04s
Final training  4436/4999 loss: 0.7880 time 23.77s
Final training  4437/4999 loss: 0.7675 time 24.22s
Final training  4438/4999 loss: 0.7491 time 24.09s
Final training  4439/4999 loss: 0.7830 time 24.26s
Final training  4440/4999 loss: 0.7540 time 24.09s
Final training  4441/4999 loss: 0.7841 time 24.22s
Final training  4442/4999 loss: 0.7969 time 24.02s
Final training  4443/4999 loss: 0.7546 time 24.09s
Final training  4444/4999 loss: 0.7776 time 24.18s
Final training  4445/4999 loss: 0.7672 time 24.02s
Final training  4446/4999 loss: 0.7551 time 24.11s
Final training  4447/4999 loss: 0.7675 time 24.29s
Final training  4448/4999 loss: 0.8068 time 24.15s
Final training  4449/4999 loss: 0.7834 time 24.36s
Final training  4450/4999 loss: 0.7592 time 24.27s
Final training  4451/4999 loss: 0.8040 time 24.20s
Final training  4452/4999 loss: 0.7767 time 24.09s
Final training  4453/4999 loss: 0.7835 time 24.29s
Final training  4454/4999 loss: 0.7820 time 24.21s
Final training  4455/4999 loss: 0.7826 time 24.11s
Final training  4456/4999 loss: 0.7731 time 24.68s
Final training  4457/4999 loss: 0.7745 time 24.75s
Final training  4458/4999 loss: 0.7834 time 24.59s
Final training  4459/4999 loss: 0.7846 time 24.10s
Final training  4460/4999 loss: 0.7684 time 24.02s
Final training  4461/4999 loss: 0.7681 time 24.03s
Final training  4462/4999 loss: 0.8019 time 24.10s
Final training  4463/4999 loss: 0.7663 time 24.07s
Final training  4464/4999 loss: 0.7646 time 24.03s
Final training  4465/4999 loss: 0.7753 time 24.12s
Final training  4466/4999 loss: 0.7774 time 23.97s
Final training  4467/4999 loss: 0.7650 time 24.32s
Final training  4468/4999 loss: 0.7923 time 23.83s
Final training  4469/4999 loss: 0.7645 time 24.04s
Final training  4470/4999 loss: 0.7760 time 24.24s
Final training  4471/4999 loss: 0.7909 time 23.95s
Final training  4472/4999 loss: 0.7648 time 24.35s
Final training  4473/4999 loss: 0.7609 time 24.03s
Final training  4474/4999 loss: 0.7888 time 24.22s
Final training  4475/4999 loss: 0.7867 time 24.11s
Final training  4476/4999 loss: 0.7889 time 24.19s
Final training  4477/4999 loss: 0.7691 time 23.87s
Final training  4478/4999 loss: 0.7451 time 23.99s
Final training  4479/4999 loss: 0.7596 time 23.52s
Final training  4480/4999 loss: 0.7766 time 23.86s
Final training  4481/4999 loss: 0.7896 time 24.04s
Final training  4482/4999 loss: 0.7470 time 24.29s
Final training  4483/4999 loss: 0.7669 time 24.19s
Final training  4484/4999 loss: 0.7606 time 24.02s
Final training  4485/4999 loss: 0.7632 time 24.15s
Final training  4486/4999 loss: 0.7858 time 24.11s
Final training  4487/4999 loss: 0.7667 time 24.28s
Final training  4488/4999 loss: 0.7399 time 24.20s
Final training  4489/4999 loss: 0.8024 time 24.11s
Final training  4490/4999 loss: 0.7665 time 24.14s
Final training  4491/4999 loss: 0.7996 time 23.98s
Final training  4492/4999 loss: 0.7643 time 24.41s
Final training  4493/4999 loss: 0.7717 time 24.50s
Final training  4494/4999 loss: 0.7914 time 24.27s
Final training  4495/4999 loss: 0.8007 time 24.33s
Final training  4496/4999 loss: 0.7912 time 24.10s
Final training  4497/4999 loss: 0.7749 time 24.41s
Final training  4498/4999 loss: 0.7856 time 24.26s
Final training  4499/4999 loss: 0.7719 time 23.95s
Dice accuracy for each class:  (tensor([0.9932, 0.9207, 0.9434, 0.9447, 0.7833, 0.7414, 0.8343, 0.7844, 0.9089,
        0.8462, 0.7480, 0.7860, 0.6686, 0.6170], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4499/4999 acc [ 0.823] time 118.59s
trigger times: 18
Final training  4500/4999 loss: 0.7972 time 24.00s
Final training  4501/4999 loss: 0.7810 time 24.27s
Final training  4502/4999 loss: 0.7918 time 24.22s
Final training  4503/4999 loss: 0.7952 time 23.76s
Final training  4504/4999 loss: 0.7635 time 24.02s
Final training  4505/4999 loss: 0.8011 time 24.12s
Final training  4506/4999 loss: 0.7704 time 23.92s
Final training  4507/4999 loss: 0.7762 time 24.08s
Final training  4508/4999 loss: 0.7824 time 23.93s
Final training  4509/4999 loss: 0.7700 time 24.61s
Final training  4510/4999 loss: 0.7704 time 24.63s
Final training  4511/4999 loss: 0.7831 time 24.37s
Final training  4512/4999 loss: 0.7849 time 24.30s
Final training  4513/4999 loss: 0.7806 time 24.31s
Final training  4514/4999 loss: 0.7710 time 24.45s
Final training  4515/4999 loss: 0.7830 time 24.52s
Final training  4516/4999 loss: 0.7938 time 24.03s
Final training  4517/4999 loss: 0.7762 time 24.42s
Final training  4518/4999 loss: 0.7746 time 24.67s
Final training  4519/4999 loss: 0.7728 time 23.98s
Final training  4520/4999 loss: 0.7612 time 24.04s
Final training  4521/4999 loss: 0.7585 time 24.08s
Final training  4522/4999 loss: 0.7633 time 24.16s
Final training  4523/4999 loss: 0.7528 time 23.83s
Final training  4524/4999 loss: 0.7764 time 23.94s
Final training  4525/4999 loss: 0.7563 time 24.03s
Final training  4526/4999 loss: 0.7761 time 24.10s
Final training  4527/4999 loss: 0.7790 time 24.17s
Final training  4528/4999 loss: 0.7679 time 23.98s
Final training  4529/4999 loss: 0.7743 time 23.85s
Final training  4530/4999 loss: 0.7611 time 24.19s
Final training  4531/4999 loss: 0.7772 time 24.37s
Final training  4532/4999 loss: 0.7873 time 24.29s
Final training  4533/4999 loss: 0.7716 time 24.18s
Final training  4534/4999 loss: 0.7673 time 24.28s
Final training  4535/4999 loss: 0.8073 time 24.25s
Final training  4536/4999 loss: 0.7700 time 24.24s
Final training  4537/4999 loss: 0.7692 time 24.21s
Final training  4538/4999 loss: 0.7880 time 23.83s
Final training  4539/4999 loss: 0.7687 time 24.19s
Final training  4540/4999 loss: 0.7760 time 24.36s
Final training  4541/4999 loss: 0.7736 time 24.02s
Final training  4542/4999 loss: 0.7899 time 23.92s
Final training  4543/4999 loss: 0.7568 time 24.22s
Final training  4544/4999 loss: 0.8076 time 24.17s
Final training  4545/4999 loss: 0.7795 time 23.90s
Final training  4546/4999 loss: 0.8006 time 24.27s
Final training  4547/4999 loss: 0.7459 time 23.92s
Final training  4548/4999 loss: 0.7670 time 23.99s
Final training  4549/4999 loss: 0.7673 time 24.37s
Final training  4550/4999 loss: 0.7676 time 24.01s
Final training  4551/4999 loss: 0.7932 time 23.91s
Final training  4552/4999 loss: 0.7853 time 24.12s
Final training  4553/4999 loss: 0.7733 time 23.97s
Final training  4554/4999 loss: 0.7544 time 24.08s
Final training  4555/4999 loss: 0.7865 time 23.96s
Final training  4556/4999 loss: 0.7747 time 23.97s
Final training  4557/4999 loss: 0.7764 time 24.15s
Final training  4558/4999 loss: 0.7540 time 24.12s
Final training  4559/4999 loss: 0.7649 time 24.21s
Final training  4560/4999 loss: 0.7347 time 24.49s
Final training  4561/4999 loss: 0.7710 time 24.12s
Final training  4562/4999 loss: 0.7617 time 24.36s
Final training  4563/4999 loss: 0.7801 time 24.43s
Final training  4564/4999 loss: 0.7837 time 24.46s
Final training  4565/4999 loss: 0.7750 time 24.43s
Final training  4566/4999 loss: 0.7804 time 24.58s
Final training  4567/4999 loss: 0.7563 time 24.62s
Final training  4568/4999 loss: 0.7897 time 24.31s
Final training  4569/4999 loss: 0.7908 time 24.43s
Final training  4570/4999 loss: 0.7841 time 24.29s
Final training  4571/4999 loss: 0.7515 time 24.21s
Final training  4572/4999 loss: 0.7805 time 24.40s
Final training  4573/4999 loss: 0.7678 time 23.93s
Final training  4574/4999 loss: 0.7871 time 24.18s
Final training  4575/4999 loss: 0.7692 time 24.29s
Final training  4576/4999 loss: 0.7463 time 24.31s
Final training  4577/4999 loss: 0.7816 time 24.22s
Final training  4578/4999 loss: 0.7547 time 24.26s
Final training  4579/4999 loss: 0.7775 time 24.01s
Final training  4580/4999 loss: 0.7676 time 24.02s
Final training  4581/4999 loss: 0.7880 time 24.34s
Final training  4582/4999 loss: 0.7551 time 24.64s
Final training  4583/4999 loss: 0.7777 time 23.88s
Final training  4584/4999 loss: 0.7973 time 24.24s
Final training  4585/4999 loss: 0.7760 time 24.29s
Final training  4586/4999 loss: 0.7802 time 24.55s
Final training  4587/4999 loss: 0.7814 time 24.44s
Final training  4588/4999 loss: 0.7757 time 23.53s
Final training  4589/4999 loss: 0.7974 time 24.32s
Final training  4590/4999 loss: 0.7989 time 24.07s
Final training  4591/4999 loss: 0.7799 time 24.03s
Final training  4592/4999 loss: 0.7647 time 24.12s
Final training  4593/4999 loss: 0.7778 time 23.98s
Final training  4594/4999 loss: 0.7873 time 24.12s
Final training  4595/4999 loss: 0.7577 time 24.10s
Final training  4596/4999 loss: 0.7691 time 24.25s
Final training  4597/4999 loss: 0.7718 time 24.07s
Final training  4598/4999 loss: 0.7909 time 24.31s
Final training  4599/4999 loss: 0.7747 time 24.10s
Dice accuracy for each class:  (tensor([0.9932, 0.9216, 0.9436, 0.9449, 0.7802, 0.7327, 0.8349, 0.7813, 0.9057,
        0.8457, 0.7457, 0.7813, 0.6699, 0.6091], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4599/4999 acc [ 0.821] time 120.95s
trigger times: 19
Final training  4600/4999 loss: 0.7886 time 24.16s
Final training  4601/4999 loss: 0.7840 time 24.47s
Final training  4602/4999 loss: 0.7779 time 24.25s
Final training  4603/4999 loss: 0.7492 time 24.31s
Final training  4604/4999 loss: 0.7696 time 24.54s
Final training  4605/4999 loss: 0.7793 time 24.39s
Final training  4606/4999 loss: 0.7866 time 24.23s
Final training  4607/4999 loss: 0.7845 time 24.22s
Final training  4608/4999 loss: 0.7731 time 24.16s
Final training  4609/4999 loss: 0.7941 time 24.16s
Final training  4610/4999 loss: 0.7917 time 24.24s
Final training  4611/4999 loss: 0.7768 time 24.22s
Final training  4612/4999 loss: 0.7853 time 24.21s
Final training  4613/4999 loss: 0.7554 time 24.03s
Final training  4614/4999 loss: 0.7926 time 24.00s
Final training  4615/4999 loss: 0.7751 time 24.10s
Final training  4616/4999 loss: 0.7570 time 23.94s
Final training  4617/4999 loss: 0.7786 time 24.10s
Final training  4618/4999 loss: 0.7651 time 24.33s
Final training  4619/4999 loss: 0.7603 time 24.34s
Final training  4620/4999 loss: 0.7827 time 23.57s
Final training  4621/4999 loss: 0.7644 time 24.56s
Final training  4622/4999 loss: 0.7494 time 24.65s
Final training  4623/4999 loss: 0.7820 time 24.33s
Final training  4624/4999 loss: 0.7452 time 24.43s
Final training  4625/4999 loss: 0.7901 time 24.65s
Final training  4626/4999 loss: 0.8211 time 24.36s
Final training  4627/4999 loss: 0.7969 time 24.54s
Final training  4628/4999 loss: 0.7906 time 24.60s
Final training  4629/4999 loss: 0.7870 time 24.15s
Final training  4630/4999 loss: 0.7776 time 24.69s
Final training  4631/4999 loss: 0.7962 time 24.69s
Final training  4632/4999 loss: 0.7534 time 24.80s
Final training  4633/4999 loss: 0.7753 time 24.31s
Final training  4634/4999 loss: 0.7684 time 24.14s
Final training  4635/4999 loss: 0.7525 time 24.28s
Final training  4636/4999 loss: 0.7810 time 24.13s
Final training  4637/4999 loss: 0.7485 time 24.46s
Final training  4638/4999 loss: 0.8007 time 24.11s
Final training  4639/4999 loss: 0.7652 time 24.34s
Final training  4640/4999 loss: 0.7532 time 24.28s
Final training  4641/4999 loss: 0.7844 time 24.01s
Final training  4642/4999 loss: 0.7681 time 24.11s
Final training  4643/4999 loss: 0.7600 time 23.90s
Final training  4644/4999 loss: 0.7711 time 24.35s
Final training  4645/4999 loss: 0.7844 time 24.29s
Final training  4646/4999 loss: 0.7534 time 24.35s
Final training  4647/4999 loss: 0.7672 time 24.07s
Final training  4648/4999 loss: 0.7946 time 24.12s
Final training  4649/4999 loss: 0.7880 time 24.67s
Final training  4650/4999 loss: 0.7751 time 24.59s
Final training  4651/4999 loss: 0.7717 time 24.68s
Final training  4652/4999 loss: 0.7538 time 24.43s
Final training  4653/4999 loss: 0.7668 time 24.18s
Final training  4654/4999 loss: 0.7572 time 24.59s
Final training  4655/4999 loss: 0.7815 time 24.63s
Final training  4656/4999 loss: 0.7627 time 24.47s
Final training  4657/4999 loss: 0.7841 time 24.51s
Final training  4658/4999 loss: 0.7817 time 24.37s
Final training  4659/4999 loss: 0.8148 time 24.25s
Final training  4660/4999 loss: 0.7640 time 24.31s
Final training  4661/4999 loss: 0.7608 time 24.39s
Final training  4662/4999 loss: 0.7792 time 24.54s
Final training  4663/4999 loss: 0.7771 time 24.40s
Final training  4664/4999 loss: 0.7724 time 24.46s
Final training  4665/4999 loss: 0.7611 time 24.45s
Final training  4666/4999 loss: 0.7922 time 24.38s
Final training  4667/4999 loss: 0.7717 time 24.35s
Final training  4668/4999 loss: 0.7437 time 24.63s
Final training  4669/4999 loss: 0.7809 time 24.46s
Final training  4670/4999 loss: 0.7467 time 24.47s
Final training  4671/4999 loss: 0.7911 time 24.18s
Final training  4672/4999 loss: 0.7643 time 24.31s
Final training  4673/4999 loss: 0.7836 time 24.41s
Final training  4674/4999 loss: 0.7852 time 24.29s
Final training  4675/4999 loss: 0.7719 time 24.16s
Final training  4676/4999 loss: 0.7791 time 24.16s
Final training  4677/4999 loss: 0.7870 time 24.04s
Final training  4678/4999 loss: 0.7990 time 24.38s
Final training  4679/4999 loss: 0.7744 time 24.43s
Final training  4680/4999 loss: 0.7769 time 24.62s
Final training  4681/4999 loss: 0.7769 time 24.30s
Final training  4682/4999 loss: 0.7447 time 24.14s
Final training  4683/4999 loss: 0.7822 time 24.37s
Final training  4684/4999 loss: 0.8013 time 23.95s
Final training  4685/4999 loss: 0.7847 time 24.17s
Final training  4686/4999 loss: 0.7704 time 24.09s
Final training  4687/4999 loss: 0.7766 time 23.71s
Final training  4688/4999 loss: 0.7924 time 23.97s
Final training  4689/4999 loss: 0.7717 time 24.11s
Final training  4690/4999 loss: 0.7525 time 24.05s
Final training  4691/4999 loss: 0.7687 time 24.11s
Final training  4692/4999 loss: 0.7812 time 24.30s
Final training  4693/4999 loss: 0.8064 time 24.32s
Final training  4694/4999 loss: 0.7912 time 24.37s
Final training  4695/4999 loss: 0.7817 time 24.24s
Final training  4696/4999 loss: 0.7512 time 24.09s
Final training  4697/4999 loss: 0.7682 time 24.31s
Final training  4698/4999 loss: 0.7634 time 24.40s
Final training  4699/4999 loss: 0.7709 time 24.44s
Dice accuracy for each class:  (tensor([0.9934, 0.9164, 0.9439, 0.9453, 0.7858, 0.7360, 0.8380, 0.7871, 0.9083,
        0.8469, 0.7487, 0.7852, 0.6658, 0.6122], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4699/4999 acc [ 0.823] time 121.52s
trigger times: 20
Final training  4700/4999 loss: 0.7749 time 24.40s
Final training  4701/4999 loss: 0.7918 time 24.09s
Final training  4702/4999 loss: 0.7701 time 24.16s
Final training  4703/4999 loss: 0.7656 time 23.92s
Final training  4704/4999 loss: 0.7590 time 24.63s
Final training  4705/4999 loss: 0.7421 time 24.31s
Final training  4706/4999 loss: 0.7465 time 24.19s
Final training  4707/4999 loss: 0.7497 time 24.55s
Final training  4708/4999 loss: 0.7608 time 24.58s
Final training  4709/4999 loss: 0.7627 time 24.34s
Final training  4710/4999 loss: 0.7886 time 24.36s
Final training  4711/4999 loss: 0.7560 time 24.19s
Final training  4712/4999 loss: 0.7650 time 24.23s
Final training  4713/4999 loss: 0.7878 time 23.98s
Final training  4714/4999 loss: 0.7487 time 24.33s
Final training  4715/4999 loss: 0.7390 time 24.94s
Final training  4716/4999 loss: 0.7878 time 24.55s
Final training  4717/4999 loss: 0.7586 time 24.79s
Final training  4718/4999 loss: 0.7910 time 24.58s
Final training  4719/4999 loss: 0.7654 time 24.47s
Final training  4720/4999 loss: 0.7788 time 24.75s
Final training  4721/4999 loss: 0.7553 time 24.25s
Final training  4722/4999 loss: 0.7969 time 24.24s
Final training  4723/4999 loss: 0.7857 time 24.32s
Final training  4724/4999 loss: 0.8004 time 24.22s
Final training  4725/4999 loss: 0.7832 time 24.35s
Final training  4726/4999 loss: 0.7559 time 24.64s
Final training  4727/4999 loss: 0.7790 time 24.54s
Final training  4728/4999 loss: 0.7646 time 24.74s
Final training  4729/4999 loss: 0.7644 time 24.67s
Final training  4730/4999 loss: 0.7908 time 24.43s
Final training  4731/4999 loss: 0.7767 time 24.04s
Final training  4732/4999 loss: 0.7735 time 24.37s
Final training  4733/4999 loss: 0.7914 time 24.41s
Final training  4734/4999 loss: 0.7835 time 24.50s
Final training  4735/4999 loss: 0.7598 time 24.67s
Final training  4736/4999 loss: 0.7611 time 24.48s
Final training  4737/4999 loss: 0.7691 time 23.83s
Final training  4738/4999 loss: 0.7787 time 24.31s
Final training  4739/4999 loss: 0.7740 time 24.34s
Final training  4740/4999 loss: 0.7692 time 24.55s
Final training  4741/4999 loss: 0.7810 time 24.61s
Final training  4742/4999 loss: 0.7731 time 24.82s
Final training  4743/4999 loss: 0.7702 time 24.25s
Final training  4744/4999 loss: 0.7968 time 24.26s
Final training  4745/4999 loss: 0.7711 time 24.14s
Final training  4746/4999 loss: 0.8062 time 24.00s
Final training  4747/4999 loss: 0.7972 time 24.32s
Final training  4748/4999 loss: 0.7650 time 24.14s
Final training  4749/4999 loss: 0.7695 time 24.39s
Final training  4750/4999 loss: 0.7712 time 24.20s
Final training  4751/4999 loss: 0.7545 time 24.14s
Final training  4752/4999 loss: 0.7672 time 24.16s
Final training  4753/4999 loss: 0.7690 time 24.26s
Final training  4754/4999 loss: 0.7677 time 24.35s
Final training  4755/4999 loss: 0.7698 time 23.98s
Final training  4756/4999 loss: 0.7613 time 24.17s
Final training  4757/4999 loss: 0.7763 time 24.47s
Final training  4758/4999 loss: 0.7706 time 24.33s
Final training  4759/4999 loss: 0.7384 time 24.37s
Final training  4760/4999 loss: 0.7865 time 24.09s
Final training  4761/4999 loss: 0.7776 time 24.07s
Final training  4762/4999 loss: 0.7757 time 24.26s
Final training  4763/4999 loss: 0.7830 time 24.04s
Final training  4764/4999 loss: 0.7871 time 23.95s
Final training  4765/4999 loss: 0.7842 time 24.07s
Final training  4766/4999 loss: 0.7814 time 24.22s
Final training  4767/4999 loss: 0.7569 time 24.33s
Final training  4768/4999 loss: 0.7908 time 24.45s
Final training  4769/4999 loss: 0.8024 time 24.38s
Final training  4770/4999 loss: 0.7763 time 23.92s
Final training  4771/4999 loss: 0.7547 time 24.07s
Final training  4772/4999 loss: 0.7911 time 24.81s
Final training  4773/4999 loss: 0.7685 time 24.33s
Final training  4774/4999 loss: 0.7939 time 24.63s
Final training  4775/4999 loss: 0.7871 time 24.12s
Final training  4776/4999 loss: 0.7626 time 24.31s
Final training  4777/4999 loss: 0.7638 time 24.27s
Final training  4778/4999 loss: 0.7878 time 24.16s
Final training  4779/4999 loss: 0.7897 time 24.32s
Final training  4780/4999 loss: 0.7806 time 24.27s
Final training  4781/4999 loss: 0.7812 time 24.33s
Final training  4782/4999 loss: 0.7933 time 24.66s
Final training  4783/4999 loss: 0.7725 time 24.38s
Final training  4784/4999 loss: 0.7836 time 24.40s
Final training  4785/4999 loss: 0.7732 time 24.26s
Final training  4786/4999 loss: 0.7617 time 24.12s
Final training  4787/4999 loss: 0.7789 time 24.17s
Final training  4788/4999 loss: 0.7774 time 24.13s
Final training  4789/4999 loss: 0.7488 time 23.67s
Final training  4790/4999 loss: 0.7599 time 24.02s
Final training  4791/4999 loss: 0.7832 time 24.05s
Final training  4792/4999 loss: 0.7964 time 23.88s
Final training  4793/4999 loss: 0.7916 time 23.77s
Final training  4794/4999 loss: 0.7856 time 24.08s
Final training  4795/4999 loss: 0.7557 time 24.16s
Final training  4796/4999 loss: 0.7365 time 24.17s
Final training  4797/4999 loss: 0.7778 time 24.36s
Final training  4798/4999 loss: 0.7706 time 24.20s
Final training  4799/4999 loss: 0.7623 time 24.08s
Dice accuracy for each class:  (tensor([0.9933, 0.9184, 0.9438, 0.9452, 0.7842, 0.7297, 0.8353, 0.7864, 0.9069,
        0.8456, 0.7480, 0.7837, 0.6680, 0.6136], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4799/4999 acc [ 0.822] time 121.29s
trigger times: 21
Final training  4800/4999 loss: 0.7862 time 24.22s
Final training  4801/4999 loss: 0.8005 time 24.06s
Final training  4802/4999 loss: 0.7770 time 23.97s
Final training  4803/4999 loss: 0.7877 time 23.79s
Final training  4804/4999 loss: 0.7547 time 24.00s
Final training  4805/4999 loss: 0.7745 time 24.16s
Final training  4806/4999 loss: 0.7745 time 24.02s
Final training  4807/4999 loss: 0.7757 time 24.36s
Final training  4808/4999 loss: 0.7362 time 24.45s
Final training  4809/4999 loss: 0.7619 time 24.52s
Final training  4810/4999 loss: 0.7754 time 24.19s
Final training  4811/4999 loss: 0.7782 time 23.95s
Final training  4812/4999 loss: 0.7694 time 24.11s
Final training  4813/4999 loss: 0.7900 time 24.09s
Final training  4814/4999 loss: 0.7773 time 24.16s
Final training  4815/4999 loss: 0.7801 time 23.96s
Final training  4816/4999 loss: 0.7625 time 24.00s
Final training  4817/4999 loss: 0.7816 time 24.02s
Final training  4818/4999 loss: 0.7853 time 24.02s
Final training  4819/4999 loss: 0.7696 time 24.17s
Final training  4820/4999 loss: 0.7881 time 24.06s
Final training  4821/4999 loss: 0.7542 time 24.01s
Final training  4822/4999 loss: 0.7714 time 24.20s
Final training  4823/4999 loss: 0.7961 time 24.09s
Final training  4824/4999 loss: 0.7662 time 24.24s
Final training  4825/4999 loss: 0.7826 time 23.87s
Final training  4826/4999 loss: 0.7897 time 24.16s
Final training  4827/4999 loss: 0.7879 time 24.07s
Final training  4828/4999 loss: 0.7766 time 24.40s
Final training  4829/4999 loss: 0.7751 time 24.18s
Final training  4830/4999 loss: 0.7668 time 24.06s
Final training  4831/4999 loss: 0.7967 time 23.99s
Final training  4832/4999 loss: 0.7777 time 24.13s
Final training  4833/4999 loss: 0.7447 time 24.00s
Final training  4834/4999 loss: 0.8152 time 24.15s
Final training  4835/4999 loss: 0.7808 time 24.10s
Final training  4836/4999 loss: 0.7476 time 24.50s
Final training  4837/4999 loss: 0.7585 time 24.32s
Final training  4838/4999 loss: 0.7596 time 24.13s
Final training  4839/4999 loss: 0.7422 time 24.11s
Final training  4840/4999 loss: 0.7556 time 24.19s
Final training  4841/4999 loss: 0.7520 time 24.09s
Final training  4842/4999 loss: 0.7765 time 24.43s
Final training  4843/4999 loss: 0.7879 time 24.03s
Final training  4844/4999 loss: 0.7946 time 23.99s
Final training  4845/4999 loss: 0.7627 time 23.83s
Final training  4846/4999 loss: 0.7847 time 24.09s
Final training  4847/4999 loss: 0.7891 time 24.03s
Final training  4848/4999 loss: 0.7976 time 24.22s
Final training  4849/4999 loss: 0.7674 time 24.14s
Final training  4850/4999 loss: 0.7768 time 24.24s
Final training  4851/4999 loss: 0.7968 time 24.26s
Final training  4852/4999 loss: 0.7870 time 24.43s
Final training  4853/4999 loss: 0.7806 time 24.20s
Final training  4854/4999 loss: 0.7642 time 24.26s
Final training  4855/4999 loss: 0.7962 time 24.03s
Final training  4856/4999 loss: 0.8093 time 24.21s
Final training  4857/4999 loss: 0.8051 time 24.17s
Final training  4858/4999 loss: 0.7541 time 24.13s
Final training  4859/4999 loss: 0.7648 time 24.19s
Final training  4860/4999 loss: 0.7720 time 24.20s
Final training  4861/4999 loss: 0.7945 time 24.23s
Final training  4862/4999 loss: 0.7827 time 24.26s
Final training  4863/4999 loss: 0.7728 time 24.21s
Final training  4864/4999 loss: 0.7616 time 24.15s
Final training  4865/4999 loss: 0.8100 time 24.12s
Final training  4866/4999 loss: 0.7801 time 24.23s
Final training  4867/4999 loss: 0.7941 time 24.03s
Final training  4868/4999 loss: 0.7905 time 24.30s
Final training  4869/4999 loss: 0.7793 time 24.31s
Final training  4870/4999 loss: 0.7767 time 24.14s
Final training  4871/4999 loss: 0.7906 time 24.41s
Final training  4872/4999 loss: 0.7748 time 24.23s
Final training  4873/4999 loss: 0.7939 time 23.79s
Final training  4874/4999 loss: 0.7790 time 23.96s
Final training  4875/4999 loss: 0.8154 time 24.36s
Final training  4876/4999 loss: 0.7986 time 24.41s
Final training  4877/4999 loss: 0.7705 time 24.20s
Final training  4878/4999 loss: 0.7945 time 24.26s
Final training  4879/4999 loss: 0.7675 time 24.07s
Final training  4880/4999 loss: 0.7977 time 23.87s
Final training  4881/4999 loss: 0.7776 time 24.09s
Final training  4882/4999 loss: 0.7835 time 24.27s
Final training  4883/4999 loss: 0.7599 time 23.99s
Final training  4884/4999 loss: 0.8019 time 23.95s
Final training  4885/4999 loss: 0.7910 time 24.46s
Final training  4886/4999 loss: 0.7739 time 24.49s
Final training  4887/4999 loss: 0.7732 time 24.36s
Final training  4888/4999 loss: 0.7951 time 24.24s
Final training  4889/4999 loss: 0.8043 time 24.56s
Final training  4890/4999 loss: 0.7677 time 24.24s
Final training  4891/4999 loss: 0.7824 time 23.71s
Final training  4892/4999 loss: 0.7859 time 24.22s
Final training  4893/4999 loss: 0.7954 time 24.19s
Final training  4894/4999 loss: 0.7620 time 24.17s
Final training  4895/4999 loss: 0.7341 time 24.04s
Final training  4896/4999 loss: 0.7681 time 24.09s
Final training  4897/4999 loss: 0.7855 time 23.87s
Final training  4898/4999 loss: 0.7882 time 24.13s
Final training  4899/4999 loss: 0.7590 time 24.10s
Dice accuracy for each class:  (tensor([0.9933, 0.9172, 0.9439, 0.9453, 0.7845, 0.7339, 0.8356, 0.7884, 0.9076,
        0.8467, 0.7483, 0.7855, 0.6667, 0.6140], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4899/4999 acc [ 0.822] time 120.84s
trigger times: 22
Final training  4900/4999 loss: 0.7787 time 24.01s
Final training  4901/4999 loss: 0.7781 time 23.91s
Final training  4902/4999 loss: 0.7646 time 24.04s
Final training  4903/4999 loss: 0.7790 time 24.14s
Final training  4904/4999 loss: 0.7853 time 24.33s
Final training  4905/4999 loss: 0.7645 time 23.95s
Final training  4906/4999 loss: 0.7594 time 24.40s
Final training  4907/4999 loss: 0.7897 time 24.28s
Final training  4908/4999 loss: 0.7496 time 24.45s
Final training  4909/4999 loss: 0.7822 time 24.66s
Final training  4910/4999 loss: 0.7938 time 24.43s
Final training  4911/4999 loss: 0.7606 time 24.61s
Final training  4912/4999 loss: 0.7859 time 24.44s
Final training  4913/4999 loss: 0.7534 time 24.56s
Final training  4914/4999 loss: 0.7693 time 24.69s
Final training  4915/4999 loss: 0.7940 time 24.61s
Final training  4916/4999 loss: 0.7930 time 24.16s
Final training  4917/4999 loss: 0.7826 time 24.26s
Final training  4918/4999 loss: 0.7714 time 24.22s
Final training  4919/4999 loss: 0.7576 time 23.94s
Final training  4920/4999 loss: 0.7682 time 24.10s
Final training  4921/4999 loss: 0.7848 time 24.44s
Final training  4922/4999 loss: 0.7886 time 24.34s
Final training  4923/4999 loss: 0.7988 time 24.53s
Final training  4924/4999 loss: 0.7892 time 24.33s
Final training  4925/4999 loss: 0.7806 time 24.32s
Final training  4926/4999 loss: 0.8054 time 24.23s
Final training  4927/4999 loss: 0.7639 time 24.11s
Final training  4928/4999 loss: 0.7786 time 24.09s
Final training  4929/4999 loss: 0.7630 time 24.31s
Final training  4930/4999 loss: 0.7457 time 24.16s
Final training  4931/4999 loss: 0.7804 time 24.25s
Final training  4932/4999 loss: 0.7627 time 24.47s
Final training  4933/4999 loss: 0.7641 time 24.41s
Final training  4934/4999 loss: 0.7986 time 24.47s
Final training  4935/4999 loss: 0.7832 time 24.16s
Final training  4936/4999 loss: 0.7606 time 24.07s
Final training  4937/4999 loss: 0.7696 time 24.16s
Final training  4938/4999 loss: 0.7922 time 24.01s
Final training  4939/4999 loss: 0.7782 time 24.45s
Final training  4940/4999 loss: 0.7679 time 24.38s
Final training  4941/4999 loss: 0.7850 time 24.37s
Final training  4942/4999 loss: 0.7539 time 24.14s
Final training  4943/4999 loss: 0.7735 time 24.27s
Final training  4944/4999 loss: 0.7718 time 24.58s
Final training  4945/4999 loss: 0.7730 time 24.08s
Final training  4946/4999 loss: 0.7801 time 24.26s
Final training  4947/4999 loss: 0.7693 time 24.27s
Final training  4948/4999 loss: 0.8037 time 24.31s
Final training  4949/4999 loss: 0.7613 time 24.27s
Final training  4950/4999 loss: 0.7655 time 24.42s
Final training  4951/4999 loss: 0.7933 time 24.34s
Final training  4952/4999 loss: 0.7939 time 24.56s
Final training  4953/4999 loss: 0.7879 time 24.63s
Final training  4954/4999 loss: 0.7891 time 24.38s
Final training  4955/4999 loss: 0.7851 time 24.54s
Final training  4956/4999 loss: 0.7940 time 24.41s
Final training  4957/4999 loss: 0.7647 time 24.36s
Final training  4958/4999 loss: 0.7441 time 24.07s
Final training  4959/4999 loss: 0.7797 time 24.05s
Final training  4960/4999 loss: 0.7782 time 24.16s
Final training  4961/4999 loss: 0.7649 time 24.02s
Final training  4962/4999 loss: 0.7770 time 24.31s
Final training  4963/4999 loss: 0.7794 time 24.12s
Final training  4964/4999 loss: 0.7677 time 24.10s
Final training  4965/4999 loss: 0.8013 time 24.21s
Final training  4966/4999 loss: 0.7594 time 24.14s
Final training  4967/4999 loss: 0.7826 time 24.19s
Final training  4968/4999 loss: 0.7739 time 24.16s
Final training  4969/4999 loss: 0.7664 time 24.24s
Final training  4970/4999 loss: 0.7859 time 24.41s
Final training  4971/4999 loss: 0.7478 time 24.75s
Final training  4972/4999 loss: 0.7920 time 24.50s
Final training  4973/4999 loss: 0.7647 time 24.49s
Final training  4974/4999 loss: 0.7942 time 24.17s
Final training  4975/4999 loss: 0.7784 time 24.01s
Final training  4976/4999 loss: 0.7889 time 24.13s
Final training  4977/4999 loss: 0.7360 time 24.06s
Final training  4978/4999 loss: 0.7879 time 24.14s
Final training  4979/4999 loss: 0.7543 time 24.31s
Final training  4980/4999 loss: 0.8077 time 24.07s
Final training  4981/4999 loss: 0.7869 time 24.18s
Final training  4982/4999 loss: 0.7730 time 24.21s
Final training  4983/4999 loss: 0.7712 time 24.33s
Final training  4984/4999 loss: 0.7902 time 24.19s
Final training  4985/4999 loss: 0.7678 time 24.11s
Final training  4986/4999 loss: 0.7784 time 23.96s
Final training  4987/4999 loss: 0.7831 time 24.13s
Final training  4988/4999 loss: 0.7915 time 24.07s
Final training  4989/4999 loss: 0.7568 time 24.05s
Final training  4990/4999 loss: 0.7817 time 24.14s
Final training  4991/4999 loss: 0.7831 time 24.20s
Final training  4992/4999 loss: 0.7719 time 24.31s
Final training  4993/4999 loss: 0.7631 time 24.28s
Final training  4994/4999 loss: 0.7992 time 24.23s
Final training  4995/4999 loss: 0.7531 time 24.05s
Final training  4996/4999 loss: 0.7488 time 24.19s
Final training  4997/4999 loss: 0.7992 time 23.74s
Final training  4998/4999 loss: 0.7682 time 24.20s
Final training  4999/4999 loss: 0.7880 time 24.10s
Dice accuracy for each class:  (tensor([0.9933, 0.9173, 0.9439, 0.9453, 0.7849, 0.7344, 0.8357, 0.7883, 0.9076,
        0.8468, 0.7484, 0.7850, 0.6667, 0.6128], device='cuda:0'), tensor([6., 6., 6., 6., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.],
       device='cuda:0'))
Final validation  4999/4999 acc [ 0.822] time 119.50s
trigger times: 23
Training Finished !, Best Accuracy:  0.826444149017334


Training Finished !, Best mean Validation Accuracy:  0.826444149017334
